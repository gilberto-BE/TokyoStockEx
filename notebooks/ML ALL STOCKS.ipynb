{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\tokyo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "# pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_train_data\n",
    ")\n",
    "from metrics import calc_spread_return_sharpe\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, True, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.version.cuda), torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the unique security codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique adjustment factor: [ 1.          0.5         5.          0.33333333  0.83333333  0.25\n",
      "  0.90909091  0.1        10.          0.2         0.95238095  2.\n",
      "  0.14285714  0.66666667  0.86956522  0.76923077  0.8         4.\n",
      " 20.        ]\n",
      "Date\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "             ... \n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "Name: AdjustmentFactor, Length: 2332531, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>1333</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>1376</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>1377</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RowId  SecuritiesCode    Open    High     Low   Close  \\\n",
       "Date                                                                        \n",
       "2017-01-04  20170104_1301            1301  2734.0  2755.0  2730.0  2742.0   \n",
       "2017-01-04  20170104_1332            1332   568.0   576.0   563.0   571.0   \n",
       "2017-01-04  20170104_1333            1333  3150.0  3210.0  3140.0  3210.0   \n",
       "2017-01-04  20170104_1376            1376  1510.0  1550.0  1510.0  1550.0   \n",
       "2017-01-04  20170104_1377            1377  3270.0  3350.0  3270.0  3330.0   \n",
       "\n",
       "             Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "Date                                                                       \n",
       "2017-01-04    31400               1.0               NaN            False   \n",
       "2017-01-04  2798500               1.0               NaN            False   \n",
       "2017-01-04   270800               1.0               NaN            False   \n",
       "2017-01-04    11300               1.0               NaN            False   \n",
       "2017-01-04   150800               1.0               NaN            False   \n",
       "\n",
       "              Target  \n",
       "Date                  \n",
       "2017-01-04  0.000730  \n",
       "2017-01-04  0.012324  \n",
       "2017-01-04  0.006154  \n",
       "2017-01-04  0.011053  \n",
       "2017-01-04  0.003026  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_train_data()\n",
    "print('Unique adjustment factor:', train_df['AdjustmentFactor'].unique())\n",
    "print(train_df['AdjustmentFactor'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_FEATURES: 4\n"
     ]
    }
   ],
   "source": [
    "CONT_COLS=['Close', 'Open', 'High', 'Low']\n",
    "TS_IN_FEATURES = len(CONT_COLS)\n",
    "CAT_FEATURES = 4 #cat.shape[1]\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 300\n",
    "NO_EMBEDDING = 2000 #2 * len(df_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (embedding): Embedding(2000, 300)\n",
      "  (embedding_to_hidden): Linear(in_features=300, out_features=512, bias=True)\n",
      "  (embedding_output): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=4, out_features=512, bias=True)\n",
      "  (hidden_layer): Linear(in_features=516, out_features=516, bias=True)\n",
      "  (output_layer): Linear(in_features=516, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (stacks): ModuleList(\n",
      "    (0): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (4): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (5): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (4): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (5): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (4): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (5): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (4): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (5): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (4): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (5): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (output): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (res_output): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (4): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (5): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=TS_IN_FEATURES, \n",
    "    units=512,\n",
    "    out_features=1, \n",
    "    categorical_dim=CAT_FEATURES,\n",
    "    no_embedding=NO_EMBEDDING, \n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    n_blocks=6,\n",
    "    n_stacks=3,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop throug each stock\n",
    "Create Trainer only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda-device\n",
      "Start training for stock: 1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat.loc[:, ['RowId']] = txt_transfom.transform()\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuos shape: (1202, 9)  categorical shape: (1202, 4)\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\tokyo\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:239.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 2.3815460205078125, 'mae': 1.5172436237335205}\n",
      "Validation metrics: {'mse': 0.1318303346633911, 'mae': 0.3328804671764374}\n",
      "Average train loss: 0.029018032550811767 | Average val loss: 0.28113657236099243\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 1.453399419784546, 'mae': 1.1696419715881348}\n",
      "Validation metrics: {'mse': 0.026692157611250877, 'mae': 0.13537077605724335}\n",
      "Average train loss: 0.015584518015384675 | Average val loss: 0.10932943224906921\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.8488809466362, 'mae': 0.8831595778465271}\n",
      "Validation metrics: {'mse': 0.038519784808158875, 'mae': 0.15388284623622894}\n",
      "Average train loss: 0.01247401386499405 | Average val loss: 0.07204832881689072\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.4900309145450592, 'mae': 0.6615096926689148}\n",
      "Validation metrics: {'mse': 0.09668254107236862, 'mae': 0.2787478268146515}\n",
      "Average train loss: 0.014051759243011474 | Average val loss: 0.09882479161024094\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.3383059501647949, 'mae': 0.5328905582427979}\n",
      "Validation metrics: {'mse': 0.14519274234771729, 'mae': 0.35441312193870544}\n",
      "Average train loss: 0.016129332780838012 | Average val loss: 0.13136234879493713\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.25302696228027344, 'mae': 0.4498649537563324}\n",
      "Validation metrics: {'mse': 0.15943461656570435, 'mae': 0.375545471906662}\n",
      "Average train loss: 0.016928708553314208 | Average val loss: 0.141126349568367\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 0.23327277600765228, 'mae': 0.4285919964313507}\n",
      "Validation metrics: {'mse': 0.14333732426166534, 'mae': 0.35535088181495667}\n",
      "Average train loss: 0.016504129767417906 | Average val loss: 0.12762847542762756\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 0.23598293960094452, 'mae': 0.43567538261413574}\n",
      "Validation metrics: {'mse': 0.11493739485740662, 'mae': 0.3150022625923157}\n",
      "Average train loss: 0.012591889500617981 | Average val loss: 0.10462884604930878\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.23704878985881805, 'mae': 0.4434438645839691}\n",
      "Validation metrics: {'mse': 0.08835885673761368, 'mae': 0.2719220817089081}\n",
      "Average train loss: 0.0092930406332016 | Average val loss: 0.08332870900630951\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.24291285872459412, 'mae': 0.44962701201438904}\n",
      "Validation metrics: {'mse': 0.06925328820943832, 'mae': 0.23752523958683014}\n",
      "Average train loss: 0.007154585421085357 | Average val loss: 0.06790100038051605\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.23020456731319427, 'mae': 0.4368647336959839}\n",
      "Validation metrics: {'mse': 0.058755651116371155, 'mae': 0.216854989528656}\n",
      "Average train loss: 0.005276768654584885 | Average val loss: 0.05880419909954071\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.20271775126457214, 'mae': 0.413540244102478}\n",
      "Validation metrics: {'mse': 0.05593923106789589, 'mae': 0.2118549942970276}\n",
      "Average train loss: 0.004133334755897522 | Average val loss: 0.055218182504177094\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "Train metrics: {'mse': 0.16148440539836884, 'mae': 0.36454319953918457}\n",
      "Validation metrics: {'mse': 0.05836600065231323, 'mae': 0.2183251827955246}\n",
      "Average train loss: 0.0037454143166542053 | Average val loss: 0.05566928908228874\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "Train metrics: {'mse': 0.12433165311813354, 'mae': 0.31404727697372437}\n",
      "Validation metrics: {'mse': 0.06316700577735901, 'mae': 0.23009032011032104}\n",
      "Average train loss: 0.003574196621775627 | Average val loss: 0.05834352970123291\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "Train metrics: {'mse': 0.09077336639165878, 'mae': 0.2665596306324005}\n",
      "Validation metrics: {'mse': 0.06769723445177078, 'mae': 0.2409006953239441}\n",
      "Average train loss: 0.0038418576121330263 | Average val loss: 0.06129508092999458\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "Train metrics: {'mse': 0.07149223238229752, 'mae': 0.22525933384895325}\n",
      "Validation metrics: {'mse': 0.0692874863743782, 'mae': 0.24527393281459808}\n",
      "Average train loss: 0.0035473931580781936 | Average val loss: 0.06219017878174782\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "Train metrics: {'mse': 0.057517897337675095, 'mae': 0.1978989541530609}\n",
      "Validation metrics: {'mse': 0.06609617918729782, 'mae': 0.23978453874588013}\n",
      "Average train loss: 0.00335879847407341 | Average val loss: 0.05925364047288895\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "Train metrics: {'mse': 0.042147014290094376, 'mae': 0.16900251805782318}\n",
      "Validation metrics: {'mse': 0.05881936848163605, 'mae': 0.225307896733284}\n",
      "Average train loss: 0.003232691064476967 | Average val loss: 0.05289141461253166\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "Train metrics: {'mse': 0.04579019546508789, 'mae': 0.1784665286540985}\n",
      "Validation metrics: {'mse': 0.050418052822351456, 'mae': 0.20709876716136932}\n",
      "Average train loss: 0.0030112773180007934 | Average val loss: 0.04557836055755615\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "Train metrics: {'mse': 0.03832215815782547, 'mae': 0.1606990247964859}\n",
      "Validation metrics: {'mse': 0.04288744553923607, 'mae': 0.18936438858509064}\n",
      "Average train loss: 0.0026145074516534805 | Average val loss: 0.0390109121799469\n",
      ".................... End of epoch 19 ....................\n",
      "Epoch: <<< 20 >>>\n",
      "Train metrics: {'mse': 0.03316023573279381, 'mae': 0.1460839807987213}\n",
      "Validation metrics: {'mse': 0.03636794909834862, 'mae': 0.172590970993042}\n",
      "Average train loss: 0.0022578164935112 | Average val loss: 0.033293433487415314\n",
      ".................... End of epoch 20 ....................\n",
      "Epoch: <<< 21 >>>\n",
      "Train metrics: {'mse': 0.03915783762931824, 'mae': 0.1640993356704712}\n",
      "Validation metrics: {'mse': 0.030943332239985466, 'mae': 0.15740294754505157}\n",
      "Average train loss: 0.002047809213399887 | Average val loss: 0.028496436774730682\n",
      ".................... End of epoch 21 ....................\n",
      "Epoch: <<< 22 >>>\n",
      "Train metrics: {'mse': 0.03028433956205845, 'mae': 0.14740510284900665}\n",
      "Validation metrics: {'mse': 0.027079354971647263, 'mae': 0.14592649042606354}\n",
      "Average train loss: 0.0016688508912920952 | Average val loss: 0.02502228133380413\n",
      ".................... End of epoch 22 ....................\n",
      "Epoch: <<< 23 >>>\n",
      "Train metrics: {'mse': 0.024272460490465164, 'mae': 0.12509772181510925}\n",
      "Validation metrics: {'mse': 0.023705119267106056, 'mae': 0.13520324230194092}\n",
      "Average train loss: 0.001647983118891716 | Average val loss: 0.021975047886371613\n",
      ".................... End of epoch 23 ....................\n",
      "Epoch: <<< 24 >>>\n",
      "Train metrics: {'mse': 0.020465223118662834, 'mae': 0.11278325319290161}\n",
      "Validation metrics: {'mse': 0.020035022869706154, 'mae': 0.12264677882194519}\n",
      "Average train loss: 0.0013614599592983723 | Average val loss: 0.01866353303194046\n",
      ".................... End of epoch 24 ....................\n",
      "Epoch: <<< 25 >>>\n",
      "Train metrics: {'mse': 0.01809527538716793, 'mae': 0.1050429418683052}\n",
      "Validation metrics: {'mse': 0.016228746622800827, 'mae': 0.10836019366979599}\n",
      "Average train loss: 0.0011237207800149918 | Average val loss: 0.015219698660075665\n",
      ".................... End of epoch 25 ....................\n",
      "Epoch: <<< 26 >>>\n",
      "Train metrics: {'mse': 0.015699269250035286, 'mae': 0.1058947890996933}\n",
      "Validation metrics: {'mse': 0.012956359423696995, 'mae': 0.09507668763399124}\n",
      "Average train loss: 0.0009789044037461282 | Average val loss: 0.012235352769494057\n",
      ".................... End of epoch 26 ....................\n",
      "Epoch: <<< 27 >>>\n",
      "Train metrics: {'mse': 0.017276635393500328, 'mae': 0.10827232152223587}\n",
      "Validation metrics: {'mse': 0.010640189982950687, 'mae': 0.08528213948011398}\n",
      "Average train loss: 0.000868283212184906 | Average val loss: 0.010080646723508835\n",
      ".................... End of epoch 27 ....................\n",
      "Epoch: <<< 28 >>>\n",
      "Train metrics: {'mse': 0.013566763140261173, 'mae': 0.09382554143667221}\n",
      "Validation metrics: {'mse': 0.009099569171667099, 'mae': 0.07876095175743103}\n",
      "Average train loss: 0.0007037271745502949 | Average val loss: 0.008611472323536873\n",
      ".................... End of epoch 28 ....................\n",
      "Epoch: <<< 29 >>>\n",
      "Train metrics: {'mse': 0.009575875476002693, 'mae': 0.07993052154779434}\n",
      "Validation metrics: {'mse': 0.007771655451506376, 'mae': 0.07258447259664536}\n",
      "Average train loss: 0.0005593877751380206 | Average val loss: 0.007339827716350555\n",
      ".................... End of epoch 29 ....................\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "\n",
      "Start training for stock: 1332\n",
      "continuos shape: (1202, 9)  categorical shape: (1202, 4)\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat.loc[:, ['RowId']] = txt_transfom.transform()\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 0.032505664974451065, 'mae': 0.1489557921886444}\n",
      "Validation metrics: {'mse': 0.006421881727874279, 'mae': 0.05959910526871681}\n",
      "Average train loss: 0.00047899237833917143 | Average val loss: 0.01474292017519474\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.021021688356995583, 'mae': 0.11416047811508179}\n",
      "Validation metrics: {'mse': 0.006059498991817236, 'mae': 0.057940974831581116}\n",
      "Average train loss: 0.0004530008416622877 | Average val loss: 0.009667365811765194\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.012724080123007298, 'mae': 0.09124357998371124}\n",
      "Validation metrics: {'mse': 0.005572488997131586, 'mae': 0.056304384022951126}\n",
      "Average train loss: 0.00042730765417218206 | Average val loss: 0.0067822858691215515\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.012035858817398548, 'mae': 0.08859439194202423}\n",
      "Validation metrics: {'mse': 0.004877256229519844, 'mae': 0.05501437187194824}\n",
      "Average train loss: 0.00046198572963476183 | Average val loss: 0.00550250755622983\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.011141382157802582, 'mae': 0.08327581733465195}\n",
      "Validation metrics: {'mse': 0.004398569464683533, 'mae': 0.055519744753837585}\n",
      "Average train loss: 0.00034554707817733286 | Average val loss: 0.004738499876111746\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.011293618939816952, 'mae': 0.08435053378343582}\n",
      "Validation metrics: {'mse': 0.0043527171947062016, 'mae': 0.05619795247912407}\n",
      "Average train loss: 0.0003155601676553488 | Average val loss: 0.00427714828401804\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 0.009047361090779305, 'mae': 0.07490228116512299}\n",
      "Validation metrics: {'mse': 0.004353262949734926, 'mae': 0.05631433427333832}\n",
      "Average train loss: 0.0002604094333946705 | Average val loss: 0.003995089791715145\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 0.008770555257797241, 'mae': 0.07405843585729599}\n",
      "Validation metrics: {'mse': 0.004125414416193962, 'mae': 0.05473201349377632}\n",
      "Average train loss: 0.0002395425457507372 | Average val loss: 0.003683747723698616\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.009590813890099525, 'mae': 0.07430197298526764}\n",
      "Validation metrics: {'mse': 0.0037557093892246485, 'mae': 0.05205358564853668}\n",
      "Average train loss: 0.00027079544961452486 | Average val loss: 0.0033431826159358025\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.008950460702180862, 'mae': 0.07316143065690994}\n",
      "Validation metrics: {'mse': 0.0034087374806404114, 'mae': 0.04939417913556099}\n",
      "Average train loss: 0.0002339551458135247 | Average val loss: 0.0030503941234201193\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.009248530492186546, 'mae': 0.07584894448518753}\n",
      "Validation metrics: {'mse': 0.003194162156432867, 'mae': 0.047450579702854156}\n",
      "Average train loss: 0.0002031834330409765 | Average val loss: 0.0028383678290992975\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.007230132818222046, 'mae': 0.06709624081850052}\n",
      "Validation metrics: {'mse': 0.003054671688005328, 'mae': 0.04620996490120888}\n",
      "Average train loss: 0.00015913067618384958 | Average val loss: 0.0026757027953863144\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "Train metrics: {'mse': 0.007079664152115583, 'mae': 0.06660845875740051}\n",
      "Validation metrics: {'mse': 0.002953208750113845, 'mae': 0.04544159024953842}\n",
      "Average train loss: 0.0001541883568279445 | Average val loss: 0.0025509276892989874\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "Train metrics: {'mse': 0.008873891085386276, 'mae': 0.07077483087778091}\n",
      "Validation metrics: {'mse': 0.002866785740479827, 'mae': 0.04486062750220299}\n",
      "Average train loss: 0.00016008359380066396 | Average val loss: 0.0024412181228399277\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "Train metrics: {'mse': 0.007647124584764242, 'mae': 0.06731583923101425}\n",
      "Validation metrics: {'mse': 0.002750277752056718, 'mae': 0.043943896889686584}\n",
      "Average train loss: 0.0001770538743585348 | Average val loss: 0.0023233455140143633\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "Train metrics: {'mse': 0.007720382418483496, 'mae': 0.06224356219172478}\n",
      "Validation metrics: {'mse': 0.002645048312842846, 'mae': 0.04307302460074425}\n",
      "Average train loss: 0.00015085753984749316 | Average val loss: 0.002266127383336425\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "Train metrics: {'mse': 0.006960970349609852, 'mae': 0.06686601042747498}\n",
      "Validation metrics: {'mse': 0.0025524767115712166, 'mae': 0.04224246367812157}\n",
      "Average train loss: 0.00016170144081115723 | Average val loss: 0.0022520485799759626\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "Train metrics: {'mse': 0.007247930858284235, 'mae': 0.0681869238615036}\n",
      "Validation metrics: {'mse': 0.002487522317096591, 'mae': 0.04172797128558159}\n",
      "Average train loss: 0.00011920271208509803 | Average val loss: 0.0021800370886921883\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "Train metrics: {'mse': 0.006669589318335056, 'mae': 0.06576129049062729}\n",
      "Validation metrics: {'mse': 0.0024266233667731285, 'mae': 0.0411762110888958}\n",
      "Average train loss: 0.00014072207268327474 | Average val loss: 0.0020648357458412647\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "Train metrics: {'mse': 0.007794068194925785, 'mae': 0.06707649677991867}\n",
      "Validation metrics: {'mse': 0.002343168016523123, 'mae': 0.04027542099356651}\n",
      "Average train loss: 0.00014432903844863176 | Average val loss: 0.0019800537265837193\n",
      ".................... End of epoch 19 ....................\n",
      "Epoch: <<< 20 >>>\n",
      "Train metrics: {'mse': 0.007971290498971939, 'mae': 0.0724603459239006}\n",
      "Validation metrics: {'mse': 0.002242638263851404, 'mae': 0.03896111622452736}\n",
      "Average train loss: 0.00012974600540474057 | Average val loss: 0.0019326928304508328\n",
      ".................... End of epoch 20 ....................\n",
      "Epoch: <<< 21 >>>\n",
      "Train metrics: {'mse': 0.006261458154767752, 'mae': 0.059553734958171844}\n",
      "Validation metrics: {'mse': 0.0021702793892472982, 'mae': 0.03752557933330536}\n",
      "Average train loss: 0.00012530098902061582 | Average val loss: 0.0019377246499061584\n",
      ".................... End of epoch 21 ....................\n",
      "Epoch: <<< 22 >>>\n",
      "Train metrics: {'mse': 0.00831679254770279, 'mae': 0.0711255744099617}\n",
      "Validation metrics: {'mse': 0.002118733711540699, 'mae': 0.03677064925432205}\n",
      "Average train loss: 0.0001243424601852894 | Average val loss: 0.0019211671315133572\n",
      ".................... End of epoch 22 ....................\n",
      "Epoch: <<< 23 >>>\n",
      "Train metrics: {'mse': 0.00574744725599885, 'mae': 0.05779628828167915}\n",
      "Validation metrics: {'mse': 0.002067013643682003, 'mae': 0.03631934896111488}\n",
      "Average train loss: 0.00013269216287881136 | Average val loss: 0.0018350443569943309\n",
      ".................... End of epoch 23 ....................\n",
      "Epoch: <<< 24 >>>\n",
      "Train metrics: {'mse': 0.005170375574380159, 'mae': 0.056269124150276184}\n",
      "Validation metrics: {'mse': 0.0020307665690779686, 'mae': 0.03608382120728493}\n",
      "Average train loss: 0.00011223492911085486 | Average val loss: 0.0017725818324834108\n",
      ".................... End of epoch 24 ....................\n",
      "Epoch: <<< 25 >>>\n",
      "Train metrics: {'mse': 0.006657841615378857, 'mae': 0.06249264255166054}\n",
      "Validation metrics: {'mse': 0.0019939346238970757, 'mae': 0.03554414585232735}\n",
      "Average train loss: 0.00010625699069350958 | Average val loss: 0.0017489218153059483\n",
      ".................... End of epoch 25 ....................\n",
      "Epoch: <<< 26 >>>\n",
      "Train metrics: {'mse': 0.007773105520755053, 'mae': 0.06711585819721222}\n",
      "Validation metrics: {'mse': 0.0019603108521550894, 'mae': 0.03502097353339195}\n",
      "Average train loss: 0.0001105447532609105 | Average val loss: 0.0017385301180183887\n",
      ".................... End of epoch 26 ....................\n",
      "Epoch: <<< 27 >>>\n",
      "Train metrics: {'mse': 0.007284900639206171, 'mae': 0.06862635910511017}\n",
      "Validation metrics: {'mse': 0.0019295745296403766, 'mae': 0.03446640819311142}\n",
      "Average train loss: 0.00010318933054804802 | Average val loss: 0.0017652574460953474\n",
      ".................... End of epoch 27 ....................\n",
      "Epoch: <<< 28 >>>\n",
      "Train metrics: {'mse': 0.0057077230885624886, 'mae': 0.06031937152147293}\n",
      "Validation metrics: {'mse': 0.0018955330597236753, 'mae': 0.0337555892765522}\n",
      "Average train loss: 0.00012091894168406725 | Average val loss: 0.001754620112478733\n",
      ".................... End of epoch 28 ....................\n",
      "Epoch: <<< 29 >>>\n",
      "Train metrics: {'mse': 0.009533089585602283, 'mae': 0.07790198922157288}\n",
      "Validation metrics: {'mse': 0.0018590997206047177, 'mae': 0.033159978687763214}\n",
      "Average train loss: 0.00012251099105924367 | Average val loss: 0.001676569925621152\n",
      ".................... End of epoch 29 ....................\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "\n",
      "Start training for stock: 1333\n",
      "continuos shape: (1202, 9)  categorical shape: (1202, 4)\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat.loc[:, ['RowId']] = txt_transfom.transform()\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n",
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Volume'] = df['Volume'].astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 0.008000321686267853, 'mae': 0.06985010206699371}\n",
      "Validation metrics: {'mse': 0.0012389605399221182, 'mae': 0.029917754232883453}\n",
      "Average train loss: 8.380474755540491e-05 | Average val loss: 0.00139359082095325\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.006359647028148174, 'mae': 0.062429871410131454}\n",
      "Validation metrics: {'mse': 0.0014239461161196232, 'mae': 0.032381877303123474}\n",
      "Average train loss: 7.73236621171236e-05 | Average val loss: 0.001599341630935669\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.008253008127212524, 'mae': 0.07529832422733307}\n",
      "Validation metrics: {'mse': 0.0018621314084157348, 'mae': 0.03764215484261513}\n",
      "Average train loss: 8.195480331778527e-05 | Average val loss: 0.002091847127303481\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.007388352416455746, 'mae': 0.06654489785432816}\n",
      "Validation metrics: {'mse': 0.001569128013215959, 'mae': 0.034252192825078964}\n",
      "Average train loss: 8.314335136674344e-05 | Average val loss: 0.0017685587517917156\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.00788569450378418, 'mae': 0.06949829310178757}\n",
      "Validation metrics: {'mse': 0.0017134733498096466, 'mae': 0.036062534898519516}\n",
      "Average train loss: 7.25029269233346e-05 | Average val loss: 0.001930826110765338\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.006563831120729446, 'mae': 0.0639413520693779}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks = train_df['SecuritiesCode'].unique()\n",
    "count = 0\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "trainer = Trainer(model, optimizer_name='adam', lr=1.3333e-5)\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "for s in stocks:\n",
    "    train_loader, val_dataloader = None, None\n",
    "    if count > 20:\n",
    "        break\n",
    "    print(f'Start training for stock: {s}')\n",
    "\n",
    "    train_dataloader, val_dataloader = dataloader_by_stock(\n",
    "        train_df, s, batch_size=BATCH_SIZE, continous_cols=CONT_COLS)\n",
    "\n",
    "    trainer.fit_epochs(\n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        use_cyclic_lr=True, \n",
    "        x_cat=True, \n",
    "        epochs=30\n",
    "    )\n",
    "    print('#' * 20)\n",
    "    print()\n",
    "    count += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
