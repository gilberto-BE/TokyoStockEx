{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split\n",
    ")\n",
    "from metrics import calc_spread_return_sharpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    RowId  SecuritiesCode    Open    High     Low   Close  \\\n",
      "Date                                                                        \n",
      "2017-01-04  20170104_1301            1301  2734.0  2755.0  2730.0  2742.0   \n",
      "2017-01-04  20170104_1332            1332   568.0   576.0   563.0   571.0   \n",
      "\n",
      "             Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
      "Date                                                                       \n",
      "2017-01-04    31400               1.0               NaN            False   \n",
      "2017-01-04  2798500               1.0               NaN            False   \n",
      "\n",
      "              Target  \n",
      "Date                  \n",
      "2017-01-04  0.000730  \n",
      "2017-01-04  0.012324  \n"
     ]
    }
   ],
   "source": [
    "computer_name1 = 'gilbe'\n",
    "computer_name2 = 'Gilberto-BE'\n",
    "\n",
    "ROOT_PATH = f'c:/Users/{computer_name1}/Documents/TokyoData'\n",
    "\n",
    "\n",
    "'/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv'\n",
    "'/train_files/trades.csv'\n",
    "\n",
    "train_df = pd.read_csv(f'{ROOT_PATH}/train_files/stock_prices.csv')\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date']) \n",
    "train_df.set_index('Date', inplace=True)\n",
    "# train_df = date_features(train_df)\n",
    "print(train_df.head(2))\n",
    "\n",
    "train_options = pd.read_csv(f'{ROOT_PATH}/train_files/options.csv', low_memory=False)\n",
    "train_financials = pd.read_csv(f'{ROOT_PATH}/train_files/financials.csv', low_memory=False)\n",
    "train_trades = pd.read_csv(f'{ROOT_PATH}/train_files/trades.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_stocks = train_df.SecuritiesCode.nunique()\n",
    "# n_stocks = train_df.SecuritiesCode.unique()\n",
    "# for n in n_stocks:\n",
    "#     print(train_df[train_df['SecuritiesCode'] == n].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Time Series data shape: (2332531, 11)\n",
      "No Unique Securities code: 2000\n",
      "df_1301.head()\n",
      "                    RowId    Open    High     Low   Close  AdjustmentFactor  \\\n",
      "Date                                                                          \n",
      "2017-01-04  20170104_1301  2734.0  2755.0  2730.0  2742.0               1.0   \n",
      "2017-01-05  20170105_1301  2743.0  2747.0  2735.0  2738.0               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag   Target  \n",
      "Date                                                    \n",
      "2017-01-04               NaN            False  0.00073  \n",
      "2017-01-05               NaN            False  0.00292  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1202 entries, 2017-01-04 to 2021-12-03\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   RowId             1202 non-null   object \n",
      " 1   Open              1201 non-null   float64\n",
      " 2   High              1201 non-null   float64\n",
      " 3   Low               1201 non-null   float64\n",
      " 4   Close             1201 non-null   float64\n",
      " 5   AdjustmentFactor  1202 non-null   float64\n",
      " 6   ExpectedDividend  5 non-null      float64\n",
      " 7   SupervisionFlag   1202 non-null   bool   \n",
      " 8   Target            1202 non-null   float64\n",
      "dtypes: bool(1), float64(7), object(1)\n",
      "memory usage: 85.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAFeCAYAAABQPMEmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAB35klEQVR4nO3dd3hUxfrA8e9syab3QOi9Qwi9F0UUFWmKYEe9lmtv2K9g4Ypee/+pKCoIKoqiWFARQZDeew+kkN777s7vj7NsEpNAAum8n+fJkz1z5pwzJ5Nk350zRWmtEUIIIYQQ1cdU2wUQQgghhGjoJOASQgghhKhmEnAJIYQQQlQzCbiEEEIIIaqZBFxCCCGEENVMAi4hhBBCiGpmqe0CnE5oaKhu3bp1bRdDCCGEEOK0Nm3alKS1Dvtnep0PuFq3bs3GjRtruxhCCCGEEKellIoqK10eKQohhBBCVDMJuIQQQgghqpkEXEIIIYQQ1UwCLiGEEEKIaiYBlxBCCCFENZOASwghhBCimknAJYQQQghRzSTgEkIIIYSoZhJwCSGEEEJUMwm4hBBCCCGqmQRcou5b/wFsmV/bpRBCCCHOWJ1fS1EIfnzI+N7rmtothxBCCHGGJOASdY/TCaaixtdjfwZj9nDS1OlEmaRRVgghRP0j716ibnE64JkgWP6cOyk7zpOMKG/ycrNrsWBCCCHEmZOAS9QtBVnG95X/K7UrOzO1hgsjhBBCVA0JuETdUphbctvpdL/MzUip4cIIIYQQVUMCLlG3FOYUvc5NQ382oWgzK73myyOEEEJUAQm4RJ2i87I4+msomTE2nAdWkLh4s3tfQUZyUcbDK2DuWLAX1HwhhRBCiEqSUYqiTnGkJJGb7EHM30E08Xqc5L1+7n3tf70JuveA0A7w6XgjMTMOglrVUmmFEEKIipEWLlGnONKSANB2E/F/OcixWvhotPFrmnjYB/vb55Oz6p2iAwpk5KIQQoi6T1q4RJ2SnZjgfu3IMTHzqiDCc41HiVlb/DmRmEuTgsdJPuRDYNscTPmZqNoqrBBCCFFB0sIl6pSM6P3u17dccSFHW6fSpklPd1pBpoUTB3xJ2BrAlk0hJCYnl3UaIYQQok6RgEvUKbnH97lfZ3f4G4C23Qa405waMrYb/bp8ojw4emQfQgghRF0nAZeoU+wxcTgVXPWwGTvGnFz9+17Gj/cOAyBGWQHIsRn50+Kia6WcQgghRGVIwCXqjsI8dHI28YHgMCt8rb4ABNgCmHjVo5wIhEauqbh+72n03HKmxNZOWYUQQohKkE7zou5IPoDONHEiSHF5u+toHdiIj3d9TIAtgBCvEPLTirKeCFKAxpSRWFulFUIIISpMAi5RZxQkHkRlmIlvbeLxQfdhNVm5pss1WEylf02zw3yBDLzSY0BrUDJWUQghRN0ljxRFnZG44g+shQpHeHM8zB4opbCaraXyRYXBhEsfBCB0JTiObKrpogohhBCVIgGXqDMythnL+Fj6DC9z/7YRnQCYfrOZRk3autNzfvmi+gsnhBBCnAV5pCjqjPzMbOw28OscWeb+Ls8+zXN/v8PloU3o2SiSA6705K3r8CvzCCGEEKJukIBL1BmOnELSvSHEy7/M/T0b9WT++P9zb/8WqbhgqyYxLo7WDjuY5ddZCCFE3SSPFEXdkeMgwwfCfAIrlP28t75kZ0uFTleQl1atRRNCCCHOhgRcos5QuZp0b0Uj78AK5e8e2p2kEAseaSaycnKqt3BCCCHEWZCAS9QZ5lzI8IFwv8AKH5MX7IMtX5GTnFR9BRNCCCHOkgRcovalHUfnZGDNgwwv8PXwqfCh3p7GbPSFabKItRBCiLqrwgGXUsqslNqilPrBtR2slPpVKXXA9T2oWN7HlFIHlVL7lFIXFUvvo5Ta4dr3hlIyW+U5b/On8Fp37Ks+RmlFmp+Vyvxa+LiW/7EtnlpdJRRCCCHOWmVauO4F9hTbfhT4XWvdAfjdtY1SqiswFegGjAHeUUqZXce8C9wKdHB9jTmr0ov6TWv08ucAyFo+F4BUP1ulTmHy8ADA7pTYXQghRN1VoYBLKdUcuBT4sFjyeOAT1+tPgAnF0hdqrfO11keAg0B/pVQTwF9r/bfWWgOfFjtGnIvSolBZ8cSuCyBrQxoAmS1CK3cOqwRcQggh6r6KTlz0GvAwlJhfsrHWOg5Aax2nlGrkSm8GrC2WL9qVVuh6/c90cY5yJkRx+PtGFGYbv4bxgeDdrH2lzmHyMFrE7E7pjiiEEKLuOu27lFJqLJCgta7ognVlNTXoU6SXdc1blVIblVIbExMTK3hZUd8UHN7rDrYAEv0V57UcWqlzmN0tXFVaNCGEEKJKVaRZYAgwTil1FFgInK+UmgfEux4T4vqe4MofDbQodnxzINaV3ryM9FK01u9rrftqrfuGhYVV4nZEfeKIOVxi+89B/lzW8YJKncPsYSxu/c8WrsLko6SvnXd2BRRCCCGqyGkDLq31Y1rr5lrr1hid4Zdrra8FlgA3uLLdAHzner0EmKqUsiml2mB0jl/vevyYqZQa6BqdeH2xY8S5Rmvs234B4P5bzEx51Mytd35AsGdwpU5jshi/wo7iLVwLrsbyRk8Cfr6Tguy0KiqwEEIIcebOpuPLbGC0UuoAMNq1jdZ6F/AlsBv4GbhTa+1wHfNvjI73B4FDwE9ncX1Rn23+hILYJLTSJPnD9P6PENGoR6VPo10DYB3a+FV25mWR/eev7P2qCZkxNhKP7YO8DNK+n83hycNwHN0OQM4PH7OncxfyN/9ZdfckhBBClKNSq/1qrVcAK1yvk4FR5eSbBcwqI30j0L2yhRT1VNpxCGgOZc2rtWsxealWUoI1Zls413W97owuoazGI0WHa5Ti4T2bKFxhjHSMXhWC88p9NM3eTcFHb5G/x4/YV56kxRtLSFv4GQA5y7/F1nvEGV1bCCGEqCgZ2iWqR2oUvB4Bh5aX3qc1OnY7WbGexPuaaO7V9Ywv07zHYABUvAUKcrBv/6vE/oLo3Rw7sp/sRGM0Y9ayA6Q8F4EzK80oikfl5v0SQgghzoQEXKJ6pB4B7YSMmNL7Dv1Oxr5cALpGQc+wvmd8GWtLYxyGbY8X5KZg3rKmxP7cxMNkbt9NXpKHOy1+XiGZe43rb0pNMxLt+bB7CegyB84aYjZBypEzLqsQQohzlwRconpkJVCQZUbnZ5XalXFsB5nRngA4FDwy9KozvozF4sH21sbjxML3R5O/b3eJ/bkZyXht2k+ODW65x1zq+Nh81+DaXx6HL6+D6I3lX+yD8+GNSApWvU5STLHAK/nQqQM1IYQQ5zwJuES1KDi8n0NLG5G9dX+pfRlL15B53AuAl2/phM1iPePraK3Z1tYIuExpceh4D/7qqrjvViO4KkhOITurkMPhinQfRcE/ei0GJ+3g+O616PUfop1AXlrZF9rzAwCZMTaO3fcWwe9Fkhq9DxL3kzNjALnfP3LG9yCEEKLhk4BLVIv8Q4dBK+xJKaX37TemX8uzgmenfmd1HYUi29UNKyvFiiXHxO6WirhgyPUAe1IWBTkW0n1NPNr/UR650UxhsYau4AQnfl9MIn6zP/u+Did+/17Iyyh1nby1P3Psz2CiV4VQmG3hyC9hnPhqOtl//kbUb2HkLpgHMwPg2DrYJ4NvhRBClCQBl6gWhXHxAJyILx1wOSzGLCGruyrGdx58VtfpFtoNb/+WAGS4OsYfbKK4t8/9ZHorQmJN+GQp0kKDuabLNVx2/h382Ldo1GTwXg/yt5pJPeCLdpiw/Pgy9hmtIKNoTt78dd9x4ucVZMd5utMKMqx4Hz5AQfRxAJL3+ZCT6EHCfZeTMvNmdEbcWd2XEEKIhkUCLlEtChOMQOtEfGqpfbkmOwB7rr+IC9ue/ZQMzdsMAyA/zXg06enZnpt73Eyel4mgZONXPLZbBwDsupAvh5l4/PqiZq6Ufb7u1wm/e3Hgu3COHzDm68rfuJzDNzxK7jYjSIwNgtVdjFa1pAOF6IJs47w5FqJ+DyV5tx/xWwJI/fZhtNOBEEIIARJwiWpSmGx0lrc5Ckvvy7NzLAzGtJuMSZ39r2C7vl2M86YYAZefvzFyMd+rKKhq0SISgP7h/Sm0Kg42U7xwRfnXDl5yA9k/fMTRm+5wp21to7jvdguvTzCzq5UiO9NCfnx0mcfvWPYX69+97azuSwghRMNRqYlPhaiowrQCwISHvXTA5Siwk+sBzf2qZp3MgOBwkvwgNNMIsBqFGK1Zhd5Fjw7P7zUEgEFNB7H26rUkZCcx7ttL3fs/vNDEv5YVrQ+UvdNK/p63cTrhoZssRIdpTK7da69ay5LfxuB1PAnTwQ1AUQsZGK1gzhhPQjIOVMn9CSGEqP+khUtUPXsBhZnGNAlWh/H4EKeTrc/fxr51v6ALneRZFc38K7duYnm6hnQlOtQIrpxA+yZGwJXSqLHx3RdaN2nnzu9j9aFNYCu+GreIxEDjTyAl0JvD4RAdYuRJ3uWHPTqNND+IbuzBexd+TKBvE9674D18PHxwNg7HNxfSj3qVKEuaL6zpqmgaB+aM9Cq5PyGEEPWfBFzi7OVnQU5R53hHQhSOAqO1yWo3+jFlzHsd2ycryXrzMVShJs8DQr39q+TyAbYAMpr6AVBghe7hbQDQowayo5XijVsaEWALKHVc5+DO/HVBBABeTYeycda1PHN3GLNdjxrzUjyI9leManYZg5r1448pvzKkmdFSZr50pHGv+WY2dFC8c6lxzKZ2ilXdTJiA1JjsKrk/IYQQ9Z8EXOKsFbx/AbzYBj4dD3HbKdxUNC2C2eGAvAxyvn4NAEuuHVOhpsAKVvOZz7/1T+a2RpDlWQjtQ4yWrfy2oTx7tZkuPc4r97gtEa257kEzBeHhzBjyBKumruSJBxa79//ZzcxDA24tddzFg69lRxsjqPx8pImAiy5hRQ/FghEm/nXp08QHQtB6C87Df1fZPQohhKi/JOASZ8fpIP7bE5zYFACHV8CWeWQt+gCAQivkaQd6zRsUZhmP/CzJ2dhywW6t2l+9kM49ATgUDoGeRstZc1+j8/yE9hPKPS7Xnku+h8LXw9ud1jG4IwtGmFjRQ2G5eDJN/ZqWOi7AFkCPt+aw6oXL8WjXlruGPMg7Y81k+Cgmd5xE4zQjX9zbr1TNDQohhKjXpNO8OHNOByTsJivG6Mfk2yyPxIRs8tYZ/bb2NVGYtJUOUVHuPKYTHpiATGvVLhrdZvBFfHzBPNZ0VYw1Gb/W49uPZ0CTATT1LR0wnTSibQc+3fc7ozt2KZHe48GZRKVH8Vq/h8o9tku7AXRpN4Di7V8Xt74YpYo662ccjaHZmd2SEEKIBkQCLnHmfnkC/fe7gBHQHF8Rgp9lBXmu3flWCMqG7N1RpQ5N8vIqlXY22gS346d+JVvNTMp0ymAL4L7+t9K7aWfOb3F+ifTJHSdXugwbr92IRRl/UnYzWBwQXZBGm59nkBN5E8HhrSp9TiGEEA2DPFIUZyx5wZfs/bJkQGM5ZiyL8+DNFmyF0PYEONKSSh3rwKNKy1JWp/iKsJqsjGo5qkSr1JmymW2YTUa/rjfubAGAKceB7e/XCH4v4qzPL4QQov6SgEtUXl4GzJ9Mwvqix4JvXmbCqSB1vy8pvnC8EXQ/ZkwNkbXHmB7hvZs6smSQ0QKU2KrqZ2F/e9TbLB63+PQZa8BT187ht0hF0xgTe79oSn66hYSYI6Uz2vMpWD+XvFRZCkgIIRoyCbhE5cVuIW3ZqhJJG9srdrcwWomONja+f3y90Wm9IMlozQrqcTFXvb6Uax8yE9VOV3mxhjcfTvug9lV+3jPRwr8Fub07u7ez420cXftd6Yxv9cXjx3vJen1gDZZOCCFETZOAS1SaPTWVuHVBJdJyPRWJgcbrqEZwR8T9DLz8bp6dWvQr5uMTSEv/ljwy7Cnev/D9Gixx7fAdPMj9OivORv8dMyDtWIk8OuUYCTt98U7JJjNFWrmEEKKhkoBLVFrB0WOl0tp5DyXIpy0AGd6KTiGtGd/hUkxtO7jzBHkZ/ayu7HQlnYM7lzpHQ3Nht4l8O1BRaIbsOE9i1gTh3P59UYbCPHJSrSTv9CdqWRgez3ansCCv/BMKIYSotyTgEpVWkJYKwOrORgfxz843ERHWA2tIKAAOsxfDmw/HbDLz7uUfu48L9KqameXri/ZB7Vk8KpSPRxt/ZhnHvEjbsNe9X/84nT1RRT+Tw0d9Obx/Z42XUwghRPWTaSFEpeWnGZ3gvxwOr0+00DmoM6/1Hc/P3vBV6nps48Zicc2F5esd6D6ukc+ZjSSsz3KdqRxtVDQCcmdcIsNdr5P++hmf/TZ2tlKEp2jytAdtHbm1U1AhhBDVSlq4RKXlpxlTP+R4GtsLxy6kmW8zxnWfTPzV5/HA0HvceZVS/NRH8cFFJvo2b1sbxa1VUzpN4Vijou30VKN1UG9dQNZfTgBig0zkWU04CxX2nMzaKKYQQohqJgGXqLQCV9DgH9CCT8Z84p57Ksw7jLdHvU2wZ3CJ/D9OaMqvvU14W71Lnauhe3zA46yetpEc1wwaHoVGC1bS0pfJS/XgRCB82T8Eu5cFVagozE0/sws5nRC3HXTVj/4UQghx9iTgEpWWG3uIDC+Y2O0aejfufdr8X4/7mh8n/VgDJat7TMqEp8WTOY8OAKA1h9n90R0c2pcIwGejPJg18TUcnlbMBQpH3pm1cNmXPEnu8+dDzOYqK7sQQoiqIwGXqDR7agGxIdArvGIjDQNsAbTwa1HNparb7hpyFwDO9X4ELFyKbY8n0SFw193zGNmmF3YfGz5ZoLNSzuj8US98z9FlYZBeegSpEEKI2icBl6i8PCfpPoogz6DT5xUAtGrUyf0645g3Htkm3r3YTM9GXQFI69mOgCyFOrb/jM5fkGosGK4zEs6+sEIIIaqcBFyi0kwFkGM78/ULz0U+nn4lto+3MHGgqa+7/1ujHsaj2bQTZSz/UwnO7x+BI6tOn1EIIUSNkoBLVI7TURRweUjAVRm7iz1VPeavaRdQ9Ei2W7cRAKRmpp7VNZyFJuxH/jqrcwghhKh6EnAJt4L0BA5vXXnKPDorCUuhwmm1YjVba6hkDcPT15j5u7MxJ1eKN8waMd29z9fXGNnZ6HgWmc9fecbXiMkNJu7wjrMrqBBCiConAZdwi/30bhq9cwUbl31ebh77ntXGd+9za9b4qnBHr7socE01nGMLpltoN/c+i82Y1CzosJXoT3ZAXsYZXSN+nRVHWvRZl1UIIUTVkoDrXJabCguvgeiNABR8s5fjK0NovPI1SDlclO/YOuMLyFm9HIC4Vs1qurT13u09b6d1jwsAiAop2TroYfvHHGXZiRU+ry7IIdfTmH/LPxMOHo4/u4IKIYSochJwncP07qXkrf0ZNs0FoDC10Pi+MYHDP79lZMo8AR9daHwBmVu2k2+BnHZtaqPI9V63ux9m1pUmzIMGlUi3eHjiLLZ9/ETFgiadl0HSezfhlaf45AIf0nzAcdwJsVurrtBCCCHOmgRc57D0FRs58nMjUn7dgnY4SPM1WklSUj1JSTLe8HPev4e4jQGkHfHCabeTdziRA80UzUPDarPo9VaL4OY88+D3vHvpjBLpFpMFe7GVTfOy0ip0vqPfzcK89k8AdrYKIqa5P15JZtIP/n3mhXQUwv5lMmu9EEJUIQm4zmH2DKOfUPxvKST+eyQeBUa6T7rCkpYMQOwX20k76EPSXl9SYw9QmOHkeCh0DpNHimeqbUBbbGZbiTSlFIXmou3wpbdVaHqH7F82E785kDyrIjHEj9zI7oSlKgq+eQqW/eeMyuf8613Snrue9E1fndHxQgghSpOA6xyWnZ3lfl1w+DgeuZqDTYxtZ5wRcDkLjFaO9Fwrjg1zodBEtieMbj2qpovb4NnNyv3aIzsbPhkLuWmnPMa015joNNHPgtXkSdj4yTgUHIvypWDZ22dUjrhPfyZufRCrPvv6jI4XQtSC3Uvg0PLaLoU4BQm4zkUOo69WaqaxUPL21orMaC88ChUrIjywm+BEahYU5KCNCczxLgA9bz4ANmsQoV6htVL0hqz4I8XDSxtz9NdQ8h9vR/yEFuictDKPOeFv9Px6bZITX2sAQ7sN52BThfceTw790PiMHgvmHzM67Dvycit9rBCiFmgNX14Hn02kcO/PaHt+bZdIlEECrnON1qQ8NJDYh4aTk5ttdIAv9nRrb+dIsrzAWWCH/zbB6VDEulbwSdljzJbezrNpLRS84bNbSv455iZ7cPinRqTs9WXrog/KPMaSZWdzO8XxMMWsUbfja/MmvmuTYiet/D9eZ2YOAD52CbiEqBfSoynMNpEZ7Yl14RTWvHlzbZdIlEECrnOMM3ob8T/lkP5DImTGk+cBTU3B7v3+YS0JzIZ2uy3kZppBK+JCVIlz5DeTGearg8VR/r6Az96BmQElHjE6s1IJTtEcD4PW/q3pE94TgMBhw9x5dG4l5/PKz8SZY7SA2gol4BKiXojZyOFfGhH9VzDpR73ISzn35uJzxB2lYNfa2i7GKUnAdY7JWTrP/dqSrMj1AM/zjDfoP54Yz+sXP+jef3RpYwBiQoqO39xOETb5zGdCF+X7+rJg5ow2MeMac6l9+cc9cTrA8e5Q2G50Zs//+0fMTsXhcMWXl33pzttt+AT3a2dGcqXKkP37SzgKjH8LCfZ49+NnIUTd5dz3O07X323s2iAaeThPc0TDc+iSMRy6/MbaLsYpScBVn2lNzLzbOfH3ggofkrm6aLoAvwQz6b6KYXfNInT5D9xx3Wwa+QTy7qVB2Iv9ZhQfPbciMozRrS+sitKLf9jf1Z9f+prYGdqCZb0UM64x8+g0M0v7GS2Mv25pjCntOIXzbwUgb70xHURMWCO8LF7u83Rp1IPVXYxjnOlJlSpDanQiYBzbdbOFA+/fc7a3JYSoRs7jO9j3+O8l0tLjs2upNLXHkatOn6mWScBVlbRm60Mj2PXBLfDb05CXXq2XcxzfgsfiH/D67oEKH5MXm8me5vDuJUbVW5QHJpOJsKbt3HlWdfPl6kcs5HgY26HpJnZ2sPFLb0XweZOq9B5EkUCb8ai2qS2SvTePYE9LxeEmirWTurO9taLlQTOHl4dy8LtwdGYSebt3k2eDxCC/Eucxm8wkdGoJQNaRzZUqQ/7Oko8i9Hd/nsUdCSGqW8ayxaXS0mPzaqEkdYSz7rbuWU6fRVRU5tJ52H5IgB8SONEhi8aBbVB9r6+26yUt+pyUXX6Y8p1UtFeVM9+B3d/EHz2NgCu9tT9j/5Fnep8neGXjK9i/uJ/D//43v/WN4NU7XyA6K5rejXtX6T2IIi+PfJn10XsY2qIfgV7efLb7Mya0n0CALYDvnS/AE3MpSDKi4CMbV6CPJnK8kQWzspU6V2BIVyCK1JXv4TXyBjx9AytUhrTUFKxmcJjAsxA8nbnYC/KxeJS+hhCi9iVu3IJDwVfDTExdaQQbOufcnbRYF2ShPOvmWr/SwlVF9I5F5H31jHs79YAvO77//qzO6cxKY//Fvdj05mNl7k/dvgaAw5Tu81PuOQud5FshIqS/EXR1KL1Ez9U9R7Dx5u8Y0GUkXb75lY8fmEML/xYMajqo1ISdouqE+4QzrtN5BHv7YlImbuh2AwGuVq9ePS8qkTd27xby0xQHGysCbKX/uXh37gSAPT6T7I8vB2cZPfIz4mDeFZBd1M8rKSeTTC/Y1dJonldaE31we1XdohCiiuiUYxT+OYe0uBgSAyCkQ9GHYYv93A24yE6r7RKUSwKuKpL50XSSNpb8cUYfP2wsDH2GS6Tk/jwXx5E8fBZ8U8YF40lNMia9zC52/p3/HcbfX71S7jmdBZosD03HoHZ8ddlXvDKy/LwAbYOb42fzOmUeUf2Cm5YMjJse+BblUGQGWHn7ksdL5e/Wpy9p3pCd5EFI8kZY8wZs/7JEnvwvHmf/i9sp/HOukeAoxDM9jywvWHJ9e+wmSLZbyM2oXD8wIcTZs694kdR508rdH/fvKzl420tYT6QTH6i48KYZZL/yCAdambHYa66cdY0zPaG2i1AuCbiqQsIeYn7yNJ7DuKR7gzk1Az4cBbu/O6PTHn7zE+P0ttLVVPDne3jGGE+EA3OcZERtY//KL+icsZOef/6XE3eNdwd6eZkpOJ5uRuGq13DYjXm3ejXuTufgzoR4hZQ6t6h7vL0DyPQq6hRamGBM9xAS0p52ge1K5e8Y0p59LRSeh2zsWdiUqCfeYP/1Txo7840VBlKW78ZRYCZzRywAztQ4QmMVMY2svDH2fdZ1UhTmmCnISqnmuxPiHOR0ED33dnKXvwgzA9i/5H+sm1/0lCT7k1dw/rCMAzvWl3l4+jajj7AtzcSBZtA6oDl9L5mG3WrCXI8Drqwv3qRw/9bKHVSs39axv5cAkJ+ZjNNxirl2aoH04aoCzugt7teb2it+76m47zsnAXssJNh88M9KxbOS59R5OVjijY6PmV7FWsiyk2HHV6T834dY832JDgGvHEXmijdwLlzDgSPhroz7yVjzI0G/fkfG0j8oyPTH8t3bqEIL+VboHtr97G5a1LjDPYLpud615NJGX+N7aNmT0AbYAsjp2hr2HQEgJ971G5iTAi+2gb43Y09JBxQWbyOgt0cfwuRUHG3pQ7hPOCosFNv+BAozKze1RIORm2r8vdn8wCcMTPL5VFSdxM9eI3P2n4Re9BUEQcfNz7n2PIVOjyX2b2PG6ZxFz0KPkt1TdEHJOfIONrXhaTH+xh1WE9Z6+kgx+7evOD7jHeAdbHddTtu7njvtMQA6u+hDode+pTi/TiT7m2/Z2+cCBj/wWTWVtvLkP0gVOP79UgDeHGvihclmNnY0cbilNwDJWwPY8FflJ2PL+eET92uvPE3KsT3Gxv/aEv/8LFIP+LKzpeKPCBMh6YqM59egj5Q8R9bab0n7eSUFmUZcbc8xvufaTLTyb1XpMona5XHNFaXSVLPSrVsn9b649ICNghVvcujHMLKXfoY905hjS+dnQ/xu8o/sBMAa0AgAvxbtsDoUHdbNhMT9VXAH9cuJGZeR8fAQkm7uTf68+2q7OKKBSf9zJQBZsUagZM81kZ9uQTud5PxcNNVPs92byUk6VvLYt54ssX2kaSP3a7vVgsUOzsQD1VX0apP45stFGz/PIz0ptkJdcpwpJ9yvLVEx7HtiBfGbAgldX3brYG2RgKsKpO3aR44HrOmq+GTMJ7w28jXav/0OX97aB4CUpLjKn3PptxRaNBs6KGzZisQ/3iE7PZnkvT6k7DNaNw438mDYtJId6t+9xMRx1zKH9l2/UJAOJwKN7SQ/iA2GlT3bYzZVvKO9qBuGD7+Wu243c89tRXXXulPXcvN3HziWO/9t5pdeRY8iT7wwl4IMK/FbArDnuUaqJibCu4NI/2I2AKZmXQBo3MY4d0y0D851/1fl91PXpS5JJmZNMInb/Tnx8dI6Pdxc1D/2TKNv5G5sFOaYOPBdOId/akTSsX0kLVtGgRkSAmBPug/eb/WAna7F5POzSFq0lNhiy9n6B3Ryvy709MFqh5zonTV5O2dHa47eOpjcfUVTKUVn2Ti25L/wdCD8XLqfanFpxR67Ht9bNIgo1uJd5UU9G/JIsQqo2CwONjVxc/cnSkybYB0D+v1pOHKyKn6ytGM4dy4lY3MUm9qZiA+CXocUoZsW4rF7Hse2Go8MN7dVtL13BmN6T2Avs9yH/9HTxNoIG/97N5dGa3wA+OJ8L7a2LCA4KBIPq+Y/ve6omhsXNSrUK5TFd6zhlmW38MR1uwjK1sxqU/6jYV8PXxIDFZ+fZ+KiLUZfhpwUY1qJfKsV0ox8yccOoeKDyYr1ZEtbhamjsUSQT3CYkWGjL1GD4yg9nrXhSVqzDFunCPzyS35IijGZaJWdAH7h5RwpROUUJKdhBY4V2Gi6q2hin6yrx5LhbSY2xMy+5orzt5mJP+RN0JKH8Oh+OQXrf6QwRfHzaBPRoZAQoPjP4Ovcxxf6eGHLV2QnHce3Fu7rTDhiDpC7MhWADy4y0feAJuKoibabviAl1Qf//HexXPgsFGsoWPfe7ZjCu9Fvwt0kvPGuO90zvShPtrluLeItLVxnyZkSgyUFDodD/yYl56gKCDY+gqjciq9JZ//hIXLmzYB8xR8Rim63P0yGNyQsMya8PGnuJf5M7TMRpRQzHzDSY4PhvsgnWHfDJtJumOjO22HIdaz410Z+nDKPbyfN54I2Q87mlkUt8vfwZ+GlC7l03P1kD+5BI+9Gp8z/7fhvWXrtH+5tXej6k08slqkwzf1Y4/ORJpr5G4GWd1DRR2h9sPo/LefvWc3xDx+A/cvgla6Qn1nt1ywu97NHSbzpXlImDiZnVsnVFLwSLGTGHqzR8ogGzFGITjd6tvfZB4WHikaC56V4QJKJqEYmBj/xGntaKFI2BLJnuYmYF8aT98ndABxuYiHyolto3nEII1r1dR+f3zgYs4b43XuNBK2NvohzLoK179XcPZbHXgDHNwCgHXZyfviYlLfuc+9e3VVx8PwOmJ0Q9Xso8ZsDSNjhh85NhcJcDq5cSObHT9Bj5yL6bn4Sx9Yl6NhMEgLgh35FrfkFFnDmFaKfawxbP6/puyzTaQMupZSnUmq9UmqbUmqXUuppV3qwUupXpdQB1/egYsc8ppQ6qJTap5S6qFh6H6XUDte+N5RSdX8u/tPIXf09yqk4FG6iXXCTEvu8A4xFoVVevjEyrAKPJA6siCZ2bSAOk2Z3Mz8uGziN7GDj00+OawqsbBtYmxYtOD247wReH2fi5UlmLmgzCKUU4/49i3n39eW9CX7cesG/3B0qRf2nlOLmHjezcOxCTOrUf8LtAtsR5h12yjz5WUXniGpk4ry23QDwDWrsTo89kIOjoApnr7YXQMJeOGQEgwW7fuDI5TeT9dJPpD59A8nr0kmL2Vd11zuNYy/exNFZxmjinAQbUb8bweaWtorXxpvwLITMD+4HRz0e/iXqDGfsbjyyy//b9chTHGsdSv9uFzLn+i5sbqfwiPYged4+Yv4y/ve3aj+eRwbexyeX/B/F30qtrY2/93Z7voIXWpP5x6vwv7ZwfC2Za+eWX6j0GJgZAPt/qZJ7dMvPJPaD60ncsJishCj0z4/CnAvIOLqZpEeuIeqhF0n69giHw+H+W8w4VR9uv6bkdEWJ6TayTxzi6D0jKbz1aaJf+Iao38JI2u1LzidPoeyKd8Z60G3ABPcxB5tA+20WDnznT9RfX1TtPZ2hirRw5QPna617ApHAGKXUQOBR4HetdQfgd9c2SqmuwFSgGzAGeEcpdbKN713gVqCD62tM1d1K7djznTG3kWo/kFCfkhNQenv4kusBPrnp8Hwz7L89ffoT/pWKI8/MlrYm8r1c62F5GcHSM1eZmXa/mbdnD+CGrje4D7kr8i7WdvfgeJiipZ+xpItSiudu+5Tnn12Bn83vn1cR55i4q88rMz3DCwKOWgFY1VXRv/FwWgQYHxwCQ5u784UcsHJ4zbKzL4jTAWnH4ZOxOF4bSPKT15Dy65s43puGdhpvGic2BZKwzZ+UjJyzv14FpB/ZS/bcNWXum32lia1tjXJlxJ7g8K/nXl82UfWyt64GwHmKJgdza+OJyfdTPufgzefz9qUmrIXGAZvbKqZfXPY6p76tjYE0UWuCSVhnx77kv6xb1YhjGd4k5vzjQ7/DDus/gL1LyV/+BvnpFtLXflLGWc9c/BMTSX95A7b3bif5ivPI//UT7Hkm8h8cR9IPRZMqPzvVTEyoYlqPq2nUpGgw0G+RCnuGGZ9PLyT3z5LL5cWleWJPiAegoHF7Wrm6Q2xup1g3PtK4xUwL9sO7q/SeztRp+3BprTVwshOS1fWlgfHASFf6J8AK4BFX+kKtdT5wRCl1EOivlDoK+Gut/wZQSn0KTAB+qppbqR2Fu08QEwKPXl66U5/VbCXXA5rstnLgYGN8UhfR9MIKBF3Ad4NMTGg/AYD11w9j3Y9fo5pNZt11M0rlNZvM/Db5VzLyM0p80lFK4W2tW50GRe1ofecDrNi8gkF7NdtaK3oe1exobaFpshNwsrc5vHWZifd7Xus+xj+0CUf+7zn2bFpOz/eXE7V1GR1Gjjurcji/vgu9ZQGZiR7ErXK1CL/0CkSVboUz5VbvWqQnJa/6FpyK5yebONixCW0PxvHEF06iwqBzcA8ubTeGlA9m45HhgY49TNvqLpDWxB/YSFhgIKZGHar7aqIWpG43HqnNHR9AUHwGvQ9qdg5tRvrwHrR79xd88uG8i4xRyTazjfsunUXMiBhYejkAnw0L4hq/0DLPPabfNZzgXVSBieTdfrDbD3/gWEYgTcaUnMQ46fHLyN+6m+AO2cQfbkzu4UYctcRwcRXdZ+H2P0n5IQaAxJ1+FKRbOfJL6W4QW9soXrnsIwY17cc/H3wdD1V45yuiNwaWiFC3t1ZEHPXgRLTRL7VJeE+6jr6Sj5/cCD268Uy3qbzTahYXT19E0m5Ny7hdWJt0q6I7OzMV6jTvaqHaBLQH3tZar1NKNdZaxwForeOUUid/is2A4vMgRLvSCl2v/5le1vVuxWgJo2XLlhW/mxqmC/PxTXeyuZeNC4LK/jecZ1MEZ4E918yu45qyZ00yZP46D4A0Xwv7msOCgU8BMG74ZB5zHuaN828p99hQr1BCvcr+AxSibUh71k2ZBE9/zYEmZrJfeIzm/o34YfHb9P5lH2+MM6FNiv5N+pc4rueIyyl0aGA5WSfObmoIXZhH1KvLyE9vjC42STBRJR9372kOXaIhKeYArc/qihWTfnAHnoBXiy4sv2oeny14HPiJfCt8PvYzCp2FfN34BTolW2hx8A8cUTsxt6qmeeycDgpmtUdtKWTfbj/slzenx6xfq+daolZop5OMJeswAx0vvY2AoNasTtjLUyP/hUVZeLfJu+zPjObZdgPdxwTYAgiwBfDrg5M5+tuPhHcu/+FQkE8IJ/6R9t0Axdj1mj37TbRzOsBkRu9fRsIvh1F53hyzWPFPKcCEhROJcdhjtmFp1rNyN5aTAitmw5B7wOZH4eIniP9sCWAM3ipIt5Y65LPzTKztrLig12Sualbyf8+RqUPYl3aC9MapQApZh0o2HuTdejUF/5mPh2tu077N+6KU4qZr/+fOc9+lT/Pni98Rdgxynh9JYuNLaXLXm/gE1M5TnwoFXFprBxCplAoEFiulTvXfpqxGUn2K9LKu9z7wPkDfvn3r7Axujs3fYHEo8vzLXzo6z2bBiDUh1qkh+RCElJ47yRG1g+i7jdGG80Y6ARNWs/ELGhEWwdLJ86u8/OLcMmnyf7j68LcE9BrEf3peDUD/O/owvft00uPW0djWscw+YS1bdyEZcKQmltpXGbmfTzc6BLvMH+VFl+MF9N5v/Mf88LqmdDWHE60z6PLJQfKSa2aJjsLYODwU9O95HZ4WTwb3Ggf8ROKwrlhMFiwmC0mtAuh1OJW0b3LJXDqJjlv2VstEqHrfbxya7wmuqZKbHKgbj0JEFSnIxhF3DHO65lA4DOzcnx5h3biSokf+d0SWP4p89C3PwC3PUP5H77LtmjCerok/4xejyU2Lx8uZQ/abt6LyjM76hakW7MqBB9Akykzsb2/jF++JjttL8FPvw6Hl0OdGOEW365yvXyV36TxCUo+Sk5fP4bf3Ys7xKZEn0R9+Ht2UXhviiA+Clb1tLJv2V5lPYi6Z+SGXADHpx/ll3UUM2muEAo9fb6Zrhi/PTXyCz7I98Pn0Y74d6M/7EaW7TZhMJrxnPYn51hkc3BiEd8o6MsZuxafnsEr+BKtGpaaF0FqnKaVWYPS9ildKNXG1bjUBTv53jAZaFDusORDrSm9eRnr9pDVp37wKgL1Fl3KzmTBzMuAKzNXkrH4X73Evuffnr/sJov4m7pOv3Wk7Wtf7sQSiDrJZbLx+z88EebrHtxDkGcSHF35IWl4agZ6BZR4X2rITB33BL/osOs07Hexf8itmk+I/15kZvMfJ8Ltmkj7rZSCBTE/49+2f0j6kGQs/mQUcxJGReubXq4zENBICINQ1OrNrtxF88/ljXNltgjuLR/cumJb/DYAj30zW2gX4Dr6myouSNve1Etsnsm2EntgBjbuf8s2uTDkpUJAFfk1IOLiJuNhoug+5FLOHrI1ak3RBHqnH9uN5aBvR05/DM8wOePDlMBNzgjtWyzVTgq0EpxjvO4sHevLaRQ/z85J1tDqWR8EHF+GZc4ykbeEk+SlWdYeJf8PJcKBVHBRs/5MTS40PFIE+keSlWUj/6QNUj8sJH/9gmb+LUc9/Dc4ACj1XkXnQG3OO8eHq2akmOgwdy6D//caOvo2Y9dyPHEk/QjO/Ztxltp32XpoFtGDAQ7PhX48QHwgfPbDK/T/s+useZkHEEN7r0hcvS9nn6jNkEn8FPU3jFHAoMLernp95RZw24FJKhQGFrmDLC7gAeAFYAtwAzHZ9P7lg4BLgc6XUK0BTjM7x67XWDqVUpqvD/TrgeuDNqr6hmpL7xbMkfmcMW289cEC5+cLSikY1dYxSpK36Eu9LZ4PZQl5GMkdueMC9f+FwE4XXXM2LHUaTba/ZIfHi3NDcr3mZ6eUFWwAmi4WkIDM+eYXGEPOT/2wzT8DLneDCWTD4rlNet/Drx7DugeURitn/+hl/LxNNfZuyJOBDIIG9LRRXBRq9EkzBrt4JqTWzhqM5JY8TQYouQca6okopLu9dcpb+Zn1HAn+7t6Pnvkbn0wRcxy4bgG+/HgQ/9WHZGXJSwFFgzO1lzyf3pZ4k/+ag+L/l5GQbiXdeTPz542k64Hw8N32A99QPIaDseiwu68NrMO/fQGaelSMx3ngmmdky/nP6PvnNaY8VVSN19ybir7oGk3JiD3GgCjzIjvEg3Rt6DLjB/RSjqnl+9jYHUqMY0vVi/uV0EuIdBM1a4fF3HBw5QUaeF7kJJr4Zo0j1NQHG+9RfXRVDd2sKlxa13u5bdHL0fRowh6TcXMJG3kDj0DAwe7jnxrKbNRYnpK4NJN+q+XKUlc63PcD7na/A18MXLigaJdc2sHI9IZt16kUcUHDVpSU+MAJc1fPU0xxZzBYSItrS+M+DZHpDN59TT6VTnSrSwtUE+MTVj8sEfKm1/kEp9TfwpVLqZuAYMBlAa71LKfUlsBujFu90PZIE+DcwF/DC6CxfbzvMx75jLL3w+jgzM/tfUm6+ozeNotFny1h6YRjTvkog5i8vGsVuw2I2E/XBTHe+Y6HgdcM0Zg5+qFSnQSFqm8PDjDnDTmF+NlZP13SKX15PdrwHlq9mYBt4R/mP2JwOUhd/i8lpZunAptwdVhQs+KUVALC2dwDXu958zCFGT8eU6GOlz1XFtL0QjzQn8S1MjA9pUW6+yM4jyOF597bXoWSchQWYrB5l5i/ct5HsAxlkH1gNE34iuPtFpX8+b/WFnGSYmU7W17OI+c6OM9vKxvYW+h403gAbpUFSmh926w/k/byE+EM+NM+8DL/718Np3qyjfjqE6YjRandy/PTxLbtKZrLnw0+PQJ8boGmvU55PVF7sq89gylc4MKNizCzrpfhxiDfJtjw+GXRptV23T7th9KHkY7PAtkaX6dgVRl/fJD/Fn939mNJ0FCz6hgIzbB81hKG7/zrluQuX/x/+q18nNd2KqbkVj0FXcoJQ1xI8xntXtk0x+L7XGNvh/Cq5n8CwFvju2kEX85nN1W5t1hw4SL7VVKvvrxUZpbgdKPWXqLVOBkaVc8wsKDb9eVH6RqBBrJqck6E52FzRc8pjhPuUP/v0FXe9BnfBcODFwrFc9u0hDsx/lvapf+L8vjGgmDXFRF5kd76SYEvUUYU2C9bCfPJidmNd9Qxc+jIcX8exP4zgqPN/olDBZc9Fb9/xK8f3mohuChcPnVxi35bxnSmwHKPHhKLRkV6+RodWD8cZPMLUGn56GMI6Qb9/nTZ7/sZfsRQq4sO9Tzmit6VfSwbeb+by1U4Cc80M2a3JPrQev85Dy8yftaRowdz4Kx/g+IBAen7iaiFzFIIykbo9F/Am4IlAYn8Jw5llBFB/RDjpexDmjzTRLk4zcJ/GttWbk2M2j/+STvil6wnqNJCjm5bRpu+YUo94dHYyOcnKPdP485NNXLnWjC2lgKT96wjtOAByUsh662Ycu/4mLzmFxtM+Pe3PS1SO49ihEnMvfd/fRLxfPr5WPzoFdSr3uOpgHxTJhxcu5l/LjKkhtrVV/O/8t+nZpBU/fNyUCb2u4Q1bAAs3nkfk3/Hu4+aMNnH+diebu3tz8V85eK/y4yiuTucbwPTbdzTqnEWePZCvBysuX6PxLKDKgq2TLGcYbAH4hRhzlyX61u58lLK0zxlwZqViyVPsbeXBI72uqvBx/a64C769H+bu4yBGkLa+o+K/D/5ES/+6OxpTCIenBWsBsOkj8rf9jUfKpBJDXuJXziF8/LNGi4m15D+1zMUf452j+PpSEy90LjmtxOjzbmZBE2/ujygKjjy9jDAhxJkOK1+C4Q9VuJwFn/0b56av8Ayynzrg+v0ZSI8mbZfx5pPU5tSP6JRS5HgqPhtl5oJDAQzbkUze/Ifwe3Qp+ISUyp+9Zl2Jbe8dSdizU7H4BMGzodjzTJzYaPwPSI/zpDDLzNa2inYnNFvbKa6ebmbVdWs5kn4Ehl1ZsizHbeTNmYDDWkhrD83mI4/S+0rXmqp56RC9kfzdu/HNMPHdME82tC6k1cBxFCRso9maw+QsmQ4PrCDr2aEcX6yBIBLCj9EYUZXyln2KNcrB1jaKlX39ifLP55pRD3N+68Hk2fOwmGr27Xdgy2F8dH571h09wID9GkurToxqa6z3O23Qne587W+6A/42ph/6aqiNF9/YjEmZuARY9uWLWJ75mCONjVas3oc1zkwLJzYEAmC6+Fq+a/0XrbsOpE+N3t2pNenZH/gG21WTT5u3OknAdQbsh4xlTmz+IZgqMVKpd49BbAiGZsW6prw7zsa1vmXOjiFEneHwtGErUGSt3kHaL43wb5mFf++iNctC172FIz8KDi5HXf0lppPLRzkKydu+lTyriaweQ2jiW3I1hh5hPegR1qNEmrfNm0IzOB0Klj9LatfrCAptDPt+Qv/5IurGH8FaRsdvrYl6dTn23EZYJhqdR8u19l0ozMG5PoBsTx9MbU/fkTYyLBKLyUpb757w5XukrEnA64OH8L3vY5yp8ZCXiCmgKdriTfbBVNZ0MTN4jxGVJnub8NmzmqZ9LuX4qiByEoo6+ObGePLxaBMJl/RhS8IWWvq1ZOmkpe6fz+TrzIzY7qTtozOI3r6GYc8vI/2HUNIBv4FpNDXNQTumo+x5ZDx1ESmrE7F4OwAv9vdow4e3zsHX6svqmJfx/PMwqd/EEdzlf+z/047VZMbihEbfxaMfi0cFSthVVaKeMwZVBWdq3n127WlyV7/GPo35bsJ3/LxgJBBPy/Zlt7A169Db3Zq6qUPXEiOXR0+ezh89e9AnLIJjsdv4efl8MrZv5cq/nJwIhGkXT6Pp5FMvNF0bug0dT9a6IXQJqN2pk2QtxTOQsnklAPlNy+/zUZYAWwBHQ41P/3lWWDxIcdvAezAXW5BTiDrJ04aHHfKPpwGQccyb478V/fM6tscftn1P+i4nfHgp+vgGYxbrZ0PJi7dzuDE08a3Y8tceZhuFFgja7snxlcHEHt4JWhN3/20cmxdF1pH1ZR+Yn4k91/hbshzLNDr1lyNuWyOiVweRlebBwXBFZAUmRPzsks/4eMxHhLcx8jpjbBx/by3a4WDfoJHsO28yJ567gtzNf+AsNGao/3r6eWyI9CMgyUTimu/RmfFkxXjhdK1p+WNfxYxrzHS/bTrvXfAel7S5hLdHvV3iutNv+oi0+6/m4sgrGT/81hL7MtcGcmCFiV8eGknGshdI+D2ZzDRPMo97YTdBVGAqQZ5BWM1WBl/9AKsibXikWNgxew5eKWY+Hl0U+CXe25fo/VtP+3NocLTG+c2d6P0Vn+8sf+PvFB7ajtNeSNRPr5Lzv+4URhX9XuqsVBzJxhq63w+tW0Hs3nHdSfQHzwH9y9zfuFEbNrVX/NRHcf1lJX/flFKc3+liWgQ3Y0j3S7j/nvlcN2sRK7spPhhjDISpq3xrOdgCaeGqNL17CWmLPsBu8sLSpexf2FOxPfggn373JrEjB/POxc/hY/U5/UFC1DKTl9G/yZGfR66nB590u5hpO5axspcTDzuM3OHD/r3G73LiTn8sHT+ixZBrSfgriLxkDw73U4R7NznVJdzahgQRl2+8zor1xBG9ldx5U0g7bHQAP/Hr9wzoOKLUcc60E6A0aMWeBF/avNyJfRctoNOg0oNa0rYXYIzdgYxwGNmy/JHG/zQucjh/hFtodcLo2O5Y+7F7X+o3ceSG/QaAtXknnrz5HRZ5PgVbv8L2949kbf8WMPqT7G0Gc0ebmXPhHPeEsy8Mf6HU9fo36e/e36h1V+6fauJEkOLh5tNoPHMOoXFmzDlJxPy0CLDw4pWQ4mfGJw/uG/yg+zweFg8sj90FU14mMNEITJsNuYYf2u1k7DvriT/gSY/PR8DMmpnhv67Quense3w5wZ2W0PjVeRDeA7yDT3nM4WuNUbm2i9oScGILHm1yOfDDW3S581NwOsj56hWUQ/HCFSam3121S+Wcresvf4ZPOrfjru5jy9xvNpn56Y5e+Fh8eKDryNOer1VYR94aZ2ZKpylVXNKGRwKuytCatTMfJPCQFz/1V0wcVPYv7KlcN+JaGHHt6TMKUYdYfY3JfdMLIdcCv/Sx83PvoXiFbWDBxZ/CsCvceZ0FJjy3LSVNtyQz2ghqDjVRDA+qWD9Ff5s/ccW27Rt+5eiyoqV/8qK3lnlcwce3glbYTdDmuCLtiBeJP80qM+A6GZgBtI6HjsEVX0LHZvHgvN82sr1vJL55cPCNotltHBZN6l9LsaHo2tfo39m+9/nAV+gtvu6lNlJ84bUJZuaO/oo+TTpX+NpKKTpfNIWRPuGMibgVLn+Ij2fdxMDPjA75OR5w/hWP0iu8Bx2DOpYaCHBjxM3s5WX3dmCbbgwbPZ5lW69h1JosMuJs7hGN5wpHzCEAUvb5UnjrDQSN6Y/PQ1+Wf0Bhrvtl/i+HSSCAhG0BwAYOJfcmgFxSFzsAM7uaW2gfUrdafYI9g7m/z/2nzPPZxZ+dcn9xZpOZDddswMNc9ohdUUQCrkrQSYew7bUQGwQJUy6iQ0ir2i6SEDXCM8CY+6aw0ITdDD4hm8jJDiHcqxVdwrpx+yQP8kx2DjRVvPeWgwPHLYSY1rn/wcS2CGZy94rN7vzP2e710eiSGbKSjDe9f/Tjyt62Hwhg0VATU1c6iVsXhNOeUHLuMBezl8aRY6TFNA2q9GN9m8XGt+PDufaLE+QdycWGcbzZrvDcpdnQUTG210gAwpp3YH8ghKcVHf/5SBOPX/YyfZpWPNg66alBT5XYvu6x91l78VL2f7cE87D+3BhxXbnHKqV4aZKJAXs1+5spbmvXlQ5BrdnbZxSs+Y7dO4MYaC8Ay7nz5lkYfcT9OjPai4JFm0np+D5dR12Ft0/pJWDyj24q91wFn+dirMdgJssTOoVNwmapnrm2qlNZK06ciqeldkf/1RfSh6sScjf8gVcBfD3UzKwxs2u7OELUGE8/o93DWWCi0AwFZGDxOUKPMKOz+S33fsToax5n3jXfs6m9wvugB85D2wCYfpOZcSPPfJJHS2JuiW2/uDRyH26BM/EgZMZT+Pv75H7yMNlpVpL84duhVhaMMJHqAwHbLBzYurLUOR0OSAiAdR0V9vtOP31EWe575Ev+jDBjyzCCrXxXdLmtjYn5k9sQ7mu0yjX2acyBViUDmL6NBnJR64vO6Lr/ZDFZGNp7PDc9PYcbLrjttPmn3fEe70608Vs/K+2DjA+NI/71GLHB4JVmImHT91VSroraMONWtt59Pkc2/FzhY9Lij+F0OKvk+vl7t5fcTrPi8/CrZN3TAR1fcmklffhPku8umvDWboL77vLl8D+6aX14cRBv3z2a98c9WiVlFA2DtHBVQvzPiwEI7jEBWwWWJBCiofBwTdVgKlDYPY15qY5lHqNrqDHSqU/jPvRpbAwE333l1fg9Nx/2eHIwHNJbhHJlpyvLPXdZPL/+iARHKrarH8QWbQQr884zMXGNE5+dXhzd6UV44jCyT9jcjy2xehLdXNHIswmLB0eTZ4Ubf3OScWQv9CrW58vpwGlX/N1ZMf98M3PbR5zRzyTMOwzTiCGw3QjoXrsmgEYxmfzcV/H5mBfd+SwmC959+8O2ogklW/QdfEbXrArDmg9j4zUbsWu7e96/AFsAaTdOoenLX7B7ycc0GnB5jZXH94tVAFji/41z3h5MHiVbS1ITY/Hy9sHTkQP+Tciady327/7gT7+unPdRsY7ueRng4eOe+byiUlb9AUC6l4WA3KKVQZJXB5E8ZgKOx+6g+5X34UyKJumxG0k/6k2WJ/jmwcuTTNx58X9oNbUth3avRT31MlH3jOflSfKBXJR2zrdw6T9fRS+8kbTPHib570Xl58vLIHP9IfY1g26RI2uugELUAR7erslI88FhVu4Aqn1g+1J5u46c4H59uIni/VHz8PeoXM+gNt0G0bvbaP7uUdQH6ZfeiuVTOpDims3zxMZAslICye7hmku50ERsCIR5G80NeQFGIJbr6qNzUl5GEiaHosAKN3a7kZ5hPStVtuI6XDjJ/XromAfYdX5rfrniV7qHlRz1OPK2p3h3UjA3PRbAc7O60bX/xWd8zapgNplLfWjsNmYCTgUc3k9hQT6Hd5Y9lUHmpy+ScPekMvdVitZk7F3t3kzd5cn6pXNK5vltJkFvd8Hzfy3hlc44Y/eQ9H9rSNzhT/iaaA6sXgzRm4xga3YL8n+ZUaFL5544wrH3Hidz1hXkb05iXUeFNjvZ2Upxxx1mPr7A9daYaybz7/kkHdtL9LQRJG8zfmbPTjVz1cNmHnvgG8a1G0f30O6MHf4vmn25gNsmlJrzWwhAWrjY9fYSzNuN4eMFjRfjubA32a88SXZjG8lHjuCX44mzW1u89m7AmmZi9QAvZnauvU+nQtQGD18jYPIsUNgtMKXTFGxmGwObDiyVt3Wzbux1vT7SWNEqKKxUnoqwmq0Mfm0+1y2bRr4ji1FNJ3P/zY9z5NZDLL1nEjGhit+7eKFMR5i/wzgmJkRxfeeb2JjUno4BZvj6U5z7NpY4b9oSY9SYEw8e6PvAPy9bKQNaD+O5SWGkelh5M2IS/+pVdktec/8WvPHf1WXuqyvaNe3GL40VQfGw/9WL6Za7ieOmX2jRtWQdR//XGJUZ5nSiKjEPYQlaw5fX4fj+dyCQlREWhm+3k3pgNQdnf05SYAQDb3kTvepVCjIsJO7wwzusgMybJpCbaAQ9KYHQ6fW7SLM5MXXuT+yXTWid9R5c/Jz7MhkvTsOja188xxqjCpNeuBOds5WU35NwJpnIduU72lgxYL+T3aM7MGPiA4RlgPO3f2MCCjZkYr/vIrIPFgX/hR4m1t2woVTQGtko8sx+HuKccM4HXO+1yGZUijFoqVOMhfwHh5K82RiR5QM4Af6OIhc42gh6X/s8Ph7lLwEiREPk37wNJx+2OEwKT4snUztPLTOvUorjY3vT4ofN+HcajLf1zB+/92zcmXmXzmXy95MZ0SYCq8lKx9DO5Lz2OfN2LaJvbiEnspKANQDEhkCrgGaMaf8kvx/8hULzp3jFRVFYkIdV29G5qWTsN/rlbGh59vPyeFu9+e9/S/cRq4+sZivRrX1ptzaT9klbwAdafHlRudNEOBOOYQ5vXbmLaA1px3AWOtn39Ea02Z9sT4ge2gW27yA0egVtfHNom72T7P8s5egvjTFlG48I3Y+OgU0dTHQ/4iRxu/FBwHZgF9pppTDdhO2pANIj/4Vv17HEfLQOWEe7cH+sx9aS+PEfrjMYgWKeFTwLIc0HDjQ30Xv4ZHq1GAlA0pZV/D71QiL25ZKaVPJ/fmhQU+lWIirtnA+4bpz+PtN+uY62puY8/PpRcAVbACsiLAzYa8erAH7vaWXb5RP4oF/VdHQVoj5p0rYHR0xgcRqPFE9n4NNv8dfAD/jPpFMPP6+IzsGdWXHlCoI8g9xpkY0iS7Qm7HmqCwDRIYpQb+NvuH2jzmxrBP6pFqJevQCvvQ6yNqbgbJsHeDNiePmj+c5Vqb07wtpNZBzzIqRL9inz2o/srnTAFbVoBk03vklm84ngVCin4khTxfk9xwE7sP3ty/5sf4xnm0V9Xra3VkQcNWbtf3W8icu7XEnuGwuxuT4F5KcZAzJSYr2I+TsIn9VfExfzo/u62e9Ox+SE4nOgvT3WzG0rbHTfl0NMm/Zc+so3JUbnhXqF0v7Zl9g1/R72NnOyt4XiiS+MjvpNQio2ia8QxZ3zfbj6hEey44YdPD7qWd69pOjH8esHt3Prwq00/ms5bXZs5Y6FW/ngymdqsaRC1B5fT3+SAow3Qbvl9AGXv08Ql1zxMFZT1QyJD/EKqdBQ9XQf8Pc0+pu18m9FbvtmhJ5QBG89TMbfacYM7/uM1op2Ye2qpGwNic/Q/uR4wMHC0w/zzzq8r8Ln1QW5HLz/avKe+YKD34WT+llRq+C2dhYiI0bhVGDNNLuDreJ2tC5KS23SgYumzSD+y+d5/PqSHeRzDnmj7SayYozWsB2tjONOrA4m9m8j2FoyQOH/wRt8cfuftHrhf7x5mZkbx96J2WR2DyI4qU/E+Vz+8w66PPost97yrju9ZaOKz9smxEnnfAvXSQOa9qXTIytZvXIY6yP9mTn0HpRSNPOv2OzYQjR0qcEehKfmk2+te5/Tdj46gfWbloBSJR71mLp1xLwqhvgtRS3Xq7so9rZQPNnuzDvLN1SjWo4i1u9dCvLLDpR1Tob7debRI5RetrtsSW8+Q+FPWzj5Gb8gw8qf3RW/R5oI7NefgMDGrGim6BytSxyXbQOffPA+bwSsMB4H5oQZ/5MntJ9A2zFe8Ol9JY45OYIQYF0nRXQoXLzJOO/TV5sI6nUTj7QdDUBI5/PpNXvLKacsUUpxeUdj1OYeV1qbsNOvvSnEP0nAVUygTwh9li5noMla6pOOEOe6rFA/OFQ3A67zpjzIM+qHUul+PXsDf7i3vx6s+H1MY67qfBWBnqUntTzXdQvtxjFPE20PQVRmCK3OTy6xv/DgLvfrvNjofx5erqw9B9yvv++v8M6H/7vYxIsj/sfgpoMxKRPLhnjT+YtsMrxN/DUinA5bY3lrSivMWdE8PngqJ+sxN7+o3po06UCS6/U3gxXtY2FFD8Vlva6hzTOfETpgPHHNC7ny6M945mtaB13KUyNuLFG2yswPl/rkzcQu+Yph4f0qfIwQJ0nA9Q/hPuG1XQQh6iR7k3AgCe2oe4uth3qF8lDfhwj2LLkGXrMuRW+MH1xkIumi3vxxScWXLTkXOa1Ga1BOgs2YpL/YPntCUZCVn+wKdVIOQ1CbUrP5F+dwFE1eGzL9QW7qfhNX5MSX+H9bOLgnSw/9zaCr7uOui27g/p/fYs6w6wjwsuFn9WMvsLaTYmTrSPcxgaHN3AHXwhHG76Wv1Y93r36cgskP8phrwMbMwTOxmW1YTGf3ljf42ofg2ofO6hzi3CUBlxCiQmzNWgI78cqtm62/N3S7oVRa6+C2PHGJiSR/uGjyw2XmEf9gLnqs9/e2EAZnxIK/sR5gelyse58zPQOOb4A5F8Blb0CXy6AgGwJblDplnCONUIyA6abuN6GUKvXh9v9Gv4/zAqe7xemdsSWn7GizfRPNnIX4exY9HrZabeyd2IuvfZO5psM45h94j6zCTAA8io2O9bH6nOEPQ4iqIwGXEKJCwlu3BSCwDj5SLI+fhx9/9DTK+7kEWxVizfcB1wxVQXttpOz5k+ABxkLc2QlGwJXuDV5ZOZB+nMIcE9b9v5A571k8rclYX0wtdc6CPKOFK+y/L5TbXcNsMmOm/NZTTw9vyurKP/H5z5kI5NpzmX/gvYrfqBA1rP785xRC1KqA3v1YPEjx8+WlWzDqsg8u/ICvx31d28WoN4LTHYAx7yBA1Mai6RWyUuIBSPIHVQgZm7dxcEk4yRuiiP7JypGfG2FPPgoOOymvjyZ19VwAPFLy2d8ULug0utrK7WXx4skBT/J/F/xftV1DiLMhAZcQokKaB7ZkwUgzPXqcX9tFqZSBTQbSMUhGlVVUdmtjQtjvBxhvD16HfoV84zFdevrJgEtBgSJnlzHFf/quBAAcBSaO/f01udu/J/7daApfepLCuH34JzqICTUmzK1OUzpPYXAzWQlE1E3ySFEIUSHhPuEsu3wZjbwb1XZRRDUK/d8spn95E9r15C85xwq/PQ2XvgQpqeRZISEQTIcV9lTjEaMlz06+6+2k9dpnScBYDigtyhv+cxke+WY2dJVRoeLcJgGXEKLCmvjKvHQNXbfW/Rl13l3EJB0Gvic7y4ozKwETYE3OJi4YMr0UZrvCGh8D+JIdX9RytW9REyAKgD2hXkQczCQ+0Ex61z61cTtC1BkScAkhhCjh/n63A7Dn/u9psdHGimbRnL8nAK+UcHY3N5Me6g1kkZToWaJfyv6m0LFoICPtjheQo21s66V4eMgtNXoPQtQ1EnAJIYQ4pR2pcYz0AFumIiZEEd3CCLhMKRYOhcNjN1oITdd4N2tJWvwxmqaAxaEZdNSGvSCPmFEDuLdZr9q+DSFqlQRcQgghyvTfKb48/kUWVruTgkwLCkVssGJA5Hj+7vwhg/Zq1nc02rhSAjz4ZcK3bEvcxrKjy+gY3JFJ7Sex7sQ6uod2r+U7EaL2ScAlhBCiTLta+1FgycIzHwoyjLeLmGArz/a4jgkXfcSiwYrjjeGt899iaLOhmE1m+oX3o1+xpW8GN5VRg0KABFxCCCHKZSbHBs1jFTFxxrJJJ4JthHgFk+mtyPQGZ0EQI1qMqOVyClH3yTxcQgghyqYVOTZoEVc0O7zd4oHZVDQjfGOPLrVRMiHqHWnhEkIIUa6Cf7xLOBxGwvcTvsfPI4AgW0AZRwkh/kkCLiGEEGWyms0lAq7ZV5ho4m9MYNo6oHXtFEqIekoeKQohhChTkwBPCl0BV6EZNncwEebnW7uFEqKekoBLCCFEmXys3hSajf5bha5uW52COtViiYSovyTgEkIIUab/jfhfUQuX63vxKR+EEBUnAZcQQogyNfVtirdrgOLJFi4JuIQ4MxJwCSGEKJfTFWidbOEK9QqtvcIIUY9JwCWEEKJcGbZAwGjhGtB4aO0WRoh6TAIuIYQQ5cpTRtNWrg3+1e2eWi6NEPWXzMMlhBCiXCvbB+MgiaX9THzoL1NCCHGmJOASQghRru1hvuxpb3Tk8rBYa7k0QtRf8khRCCFEubq1KHrt7+FfewURop6TgEsIIUS50u0nAPjs4s/wtnrXcmmEqL8k4BJCCFGu+Jx4ANoEtKnlkghRv0nAJYQQolwzBs2gQ1AHAmwBtV0UIeo16TQvhBCiXFd0vIIrOl5R28UQot6TFi4hhBBCiGomAZcQQgghRDWTgEsIIYQQoppJwCWEEEIIUc0k4BJCCCGEqGYScAkhhBBCVDMJuIQQQgghqtlpAy6lVAul1B9KqT1KqV1KqXtd6cFKqV+VUgdc34OKHfOYUuqgUmqfUuqiYul9lFI7XPveUEqp6rktIYQQQoi6oyItXHbgQa11F2AgcKdSqivwKPC71roD8LtrG9e+qUA3YAzwjlLK7DrXu8CtQAfX15gqvBchhBBCiDrptAGX1jpOa73Z9ToT2AM0A8YDn7iyfQJMcL0eDyzUWudrrY8AB4H+SqkmgL/W+m+ttQY+LXaMEEIIIUSDVak+XEqp1kAvYB3QWGsdB0ZQBjRyZWsGHC92WLQrrZnr9T/Ty7rOrUqpjUqpjYmJiZUpohBCCCFEnVPhgEsp5Qt8Ddyntc44VdYy0vQp0ksnav2+1rqv1rpvWFhYRYsohBBCCFEnVSjgUkpZMYKt+Vrrb1zJ8a7HhLi+J7jSo4EWxQ5vDsS60puXkS6EEEII0aBVZJSiAuYAe7TWrxTbtQS4wfX6BuC7YulTlVI2pVQbjM7x612PHTOVUgNd57y+2DFCCCGEEA2WpQJ5hgDXATuUUltdaY8Ds4EvlVI3A8eAyQBa611KqS+B3RgjHO/UWjtcx/0bmAt4AT+5voQQQgghGjRlDBisu/r27as3btxY28UQQgghhDgtpdQmrXXff6bLTPNCCCGEENVMAi4hhBBCiGomAZcQQgghRDWTgEsIIYQQoppJwCWEEEIIUc0k4BJCCCGEqGYScAkhhBBCVDMJuIQQQgghqpkEXEIIIYQQ1UwCLiGEEEKIaiYBlxBCCCFENZOASwghhBCimknAJYQQQghRzSTgEkIIIYSoZpbaLoAQQghRnxUWFhIdHU1eXl5tF0XUIE9PT5o3b47Vaq1Qfgm4hBBCiLMQHR2Nn58frVu3RilV28URNUBrTXJyMtHR0bRp06ZCx8gjRSGEEOIs5OXlERISIsHWOUQpRUhISKVaNSXgEkIIIc6SBFvnnsrWuQRcQgghhBDVTAIuIYQQop6Ljo5m/PjxdOjQgXbt2nHvvfdSUFBQ28USxUjAJYQQQtRjWmsmTZrEhAkTOHDgAPv37ycrK4snnniitosmipFRikIIIUQ9tnz5cjw9PbnxxhsBMJvNvPrqq7Rp04Y2bdrwyy+/kJ+fz5EjR7j66quZMWMGAPPmzeONN96goKCAAQMG8M4772A2m/H19eXee+/lhx9+wMvLi++++47GjRvX5i02CBJwCSGEEFXk6e93sTs2o0rP2bWpPzMu61bu/l27dtGnT58Saf7+/rRs2RK73c769evZuXMn3t7e9OvXj0svvRQfHx+++OILVq9ejdVq5Y477mD+/Plcf/31ZGdnM3DgQGbNmsXDDz/MBx98wJNPPlml93QukoBLCCGEqMe01mWOmDuZPnr0aEJCQgCYNGkSf/31FxaLhU2bNtGvXz8AcnNzadSoEQAeHh6MHTsWgD59+vDrr7/W0J00bBJwCSGEEFXkVC1R1aVbt258/fXXJdIyMjI4fvw4ZrO5VDCmlEJrzQ033MDzzz9f6nxWq9V9jNlsxm63V1/hzyHSaV4IIYSox0aNGkVOTg6ffvopAA6HgwcffJBp06bh7e3Nr7/+SkpKCrm5uXz77bcMGTKEUaNGsWjRIhISEgBISUkhKiqqNm+jwZOASwghhKjHlFIsXryYr776ig4dOtCxY0c8PT3573//C8DQoUO57rrriIyM5PLLL6dv37507dqV5557jgsvvJCIiAhGjx5NXFxcLd9Jw6a01rVdhlPq27ev3rhxY20XQwghhCjTnj176NKlS20Xo0xz585l48aNvPXWW7VdlAaprLpXSm3SWvf9Z15p4RJCCCGEqGbSaV4IIYRooKZNm8a0adNquxgCaeESQgghhKh2EnAJIYQQQlQzCbiEEEIIIaqZBFxCCCGEENVMAi4hhBCinvP19S2xPXfuXO666y4A3nvvPfekqOUpnl9UDxmlKIQQQjRgt99+e20XQSAtXEIIIUSDNnPmTF566SUANmzYQEREBIMGDWL69Ol0797dnS82NpYxY8bQoUMHHn744doqboMlLVxCCCFEVfnpUTixo2rPGd4DLp59yiy5ublERka6t1NSUhg3blypfDfeeCPvv/8+gwcP5tFHHy2xb+vWrWzZsgWbzUanTp24++67adGiRZXcgpAWLiGEEKLe8/LyYuvWre6vZ555plSetLQ0MjMzGTx4MABXX311if2jRo0iICAAT09PunbtKotZVzFp4RJCCCGqymlaomrT6dZOttls7tdmsxm73V7dRTqnSAuXEEIIcQ4ICgrCz8+PtWvXArBw4cJaLtG5RQIuIYQQ4hwxZ84cbr31VgYNGoTWmoCAgNou0jlDna6Jsbb17dtXb9y4sbaLIYQQQpRpz549dOnSpbaLUSFZWVnuObtmz55NXFwcr7/+ei2Xqv4qq+6VUpu01n3/mVf6cAkhhBDniKVLl/L8889jt9tp1aoVc+fOre0inTMk4BJCCCHOEVOmTGHKlCm1XYxzkvThEkIIIYSoZhJwCSGEEEJUMwm4hBBCCCGqmQRcQgghhBDVTAIuIYQQop47OdWDqLsk4BJCCCGEqGanDbiUUh8ppRKUUjuLpQUrpX5VSh1wfQ8qtu8xpdRBpdQ+pdRFxdL7KKV2uPa9oZRSVX87QgghhADYunUrAwcOJCIigokTJ5KamkpCQgJ9+vQBYNu2bSilOHbsGADt2rUjJyenNovcoFVkHq65wFvAp8XSHgV+11rPVko96tp+RCnVFZgKdAOaAr8ppTpqrR3Au8CtwFrgR2AM8FNV3YgQQghR215Y/wJ7U/ZW6Tk7B3fmkf6PVPq466+/njfffJMRI0bw1FNP8fTTT/Paa6+Rl5dHRkYGq1atom/fvqxatYqhQ4fSqFEjvL29q7TsoshpW7i01iuBlH8kjwc+cb3+BJhQLH2h1jpfa30EOAj0V0o1Afy11n9rYy2hT4sdI4QQQogqlJ6eTlpaGiNGjADghhtuYOXKlQAMHjyY1atXs3LlSh5//HFWrlzJqlWrGDZsWG0WucE705nmG2ut4wC01nFKqUau9GYYLVgnRbvSCl2v/5leJqXUrRitYbRs2fIMiyiEEELUrDNpiappw4YNY9WqVURFRTF+/HheeOEFlFKMHTu2tovWoFV1p/my+mXpU6SXSWv9vta6r9a6b1hYWJUVTgghhDgXBAQEEBQUxKpVqwD47LPP3K1dw4cPZ968eXTo0AGTyURwcDA//vgjQ4YMqc0iN3hn2sIVr5Rq4mrdagIkuNKjgRbF8jUHYl3pzctIF0IIIcRZysnJoXnzorfZBx54gE8++YTbb7+dnJwc2rZty8cffwxA69atASPwAhg6dCjR0dEEBQWVOq+oOmcacC0BbgBmu75/Vyz9c6XUKxid5jsA67XWDqVUplJqILAOuB5486xKLoQQQggAnE5nmelr164tM/3kyESAxx9/nMcff7xayiWKnDbgUkotAEYCoUqpaGAGRqD1pVLqZuAYMBlAa71LKfUlsBuwA3e6RigC/BtjxKMXxuhEGaEohBBCiHPCaQMurfVV5ewaVU7+WcCsMtI3At0rVTohhBBCiAZAZpoXQgghhKhmEnAJIYQQQlQzCbiEEEIIIaqZBFxCCCGEENVMAi4hhBCinjtx4gRTp06lXbt2dO3alUsuuYT9+/fTvbuMVasrznQeLiGEEELUAVprJk6cyA033MDChQsB2Lp1K/Hx8bVcMlGctHAJIYQQ9dgff/yB1Wrl9ttvd6dFRkbSokXRwi95eXnceOON9OjRg169evHHH38AsGvXLvr3709kZCQREREcOHAAgHnz5rnTb7vtNhwOB+LsSAuXEEIIUUVO/Pe/5O/ZW6XntHXpTPgpZoLfuXMnffr0OeU53n77bQB27NjB3r17ufDCC9m/fz/vvfce9957L9dccw0FBQU4HA727NnDF198werVq7Fardxxxx3Mnz+f66+/vkrv61wjAZcQQgjRwP3111/cfffdAHTu3JlWrVqxf/9+Bg0axKxZs4iOjmbSpEl06NCB33//nU2bNtGvXz8AcnNzadSoUW0Wv0GQgEsIIYSoIqdqiaou3bp1Y9GiRafMo7UuM/3qq69mwIABLF26lIsuuogPP/wQrTU33HADzz//fHUU95wlfbiEEEKIeuz8888nPz+fDz74wJ22YcMGoqKi3NvDhw9n/vz5AOzfv59jx47RqVMnDh8+TNu2bbnnnnsYN24c27dvZ9SoUSxatIiEhAQAUlJSSpxLnBkJuIQQQoh6TCnF4sWL+fXXX2nXrh3dunVj5syZNG3a1J3njjvuwOFw0KNHD6ZMmcLcuXOx2Wx88cUXdO/encjISPbu3cv1119P165dee6557jwwguJiIhg9OjRxMXF1eIdNgyqvGbGuqJv375648aNtV0MIYQQokx79uyhS5cutV0MUQvKqnul1Catdd9/5pUWLiGEEEKIaiYBlxBCCCFENZOASwghhBCimknAJYQQQghRzSTgEkIIIYSoZhJwCSGEEEJUMwm4hBBCiAZg8eLFKKXYu7fstRxHjhzJyWmWLrnkEtLS0ip9jRUrVrBmzZqzKeYZXWfmzJk0a9aMyMhIIiMjefTRRyt1vrS0NN55552qLmalSMAlhBBCNAALFixg6NChLFy48LR5f/zxRwIDAyt9jdoKuADuv/9+tm7dytatW5k9e3alzncmAZfD4ahU/tORgEsIIYSo57Kysli9ejVz5sxxB1y5ublMnTqViIgIpkyZQm5urjt/69atSUpK4ujRo3Tv3t2d/tJLLzFz5kwA3njjDbp27UpERARTp07l6NGjvPfee7z66qtERkayatUqpk2bxr///W/OO+882rZty59//slNN91Ely5dmDZtmvu8y5YtY9CgQfTu3ZvJkyeTlZXlLseMGTPo3bs3PXr0YO/evWVepywffPAB/fr1o2fPnlx++eXk5OQAEB8fz8SJE+nZsyc9e/ZkzZo1PProoxw6dIjIyEimT5+O1prp06fTvXt3evTowRdffAEYgd55553H1VdfTY8ePaqsfkAWrxZCCCGqzKov95N0PKtKzxnawpdhV3Y8ZZ5vv/2WMWPG0LFjR4KDg9m8eTMrVqzA29ub7du3s337dnr37l2p686ePZsjR45gs9lIS0sjMDCQ22+/HV9fXx566CEA5syZQ2pqKsuXL2fJkiVcdtllrF69mg8//JB+/fqxdetWmjdvznPPPcdvv/2Gj48PL7zwAq+88gpPPfWUcX+hoWzevJl33nmHl156iQ8//LDUdX7//XdeffVV5s2bB8ALL7zApEmTuOWWWwB48sknmTNnDnfffTf33HMPI0aMYPHixTgcDrKyspg9ezY7d+5k69atAHz99dds3bqVbdu2kZSURL9+/Rg+fDgA69evZ+fOnbRp06ZSP6/TkYBLCCGEqOcWLFjAfffdB8DUqVNZsGABBw4c4J577gEgIiKCiIiISp0zIiKCa665hgkTJjBhwoRy81122WUopejRoweNGzd2twx169aNo0ePEh0dze7duxkyZAgABQUFDBo0yH38pEmTAOjTpw/ffPNNude5//773QEYwJ9//smTTz5JWloaWVlZXHTRRQAsX76cTz/9FACz2UxAQACpqaklzvXXX39x1VVXYTabady4MSNGjGDDhg34+/vTv3//Kg+2QAIuIYQQosqcriWqOiQnJ7N8+XJ27tyJUgqHw4FSil69eqGUOuWxFosFp9Pp3s7Ly3O/Xrp0KStXrmTJkiU8++yz7Nq1q8xz2Gw2AEwmk/v1yW273Y7ZbGb06NEsWLDglMebzWbsdnvFbhqYNm0a3377LT179mTu3LmsWLGiwseeah1pHx+fCp+nMqQPlxBCCFGPLVq0iOuvv56oqCiOHj3K8ePHadOmDb1792b+/PkA7Ny5k+3bt5c6tnHjxiQkJJCcnEx+fj4//PADAE6nk+PHj3Peeefx4osvuluR/Pz8yMzMrFT5Bg4cyOrVqzl48CAAOTk57N+//5THVOQ6mZmZNGnShMLCQvd9AowaNYp3330XMDq+Z2RklDrf8OHD+eKLL3A4HCQmJrJy5Ur69+9fqfuqLAm4hBBCiHpswYIFTJw4sUTa5ZdfztGjR8nKyiIiIoIXX3yxVEChlMJqtfLUU08xYMAAxo4dS+fOnQEjULn22mvp0aMHvXr14v777ycwMJDLLruMxYsXn7Iz+z+FhYUxd+5crrrqKiIiIhg4cGC5U1ecVJHrPPvsswwYMIDRo0e7yw3w+uuv88cff9CjRw/69OnDrl27CAkJYciQIXTv3p3p06czceJEIiIi6NmzJ+effz4vvvgi4eHhFbqfM6VO1axWF/Tt21efnDdECCGEqGv27NlDly5darsYFeZwOGjUqBEnTpzAarXWdnHqtbLqXim1SWvd9595pYVLCCGEOId069aNf/3rXxJs1TDpNC+EEEKcQ073OE9UD2nhEkIIIYSoZhJwCSGEEEJUMwm4hBBCCCGqmQRcQgghhBDVTAIuIYQQop4zm81ERka6v2bPnl3t10xLS+Odd96p9HEzZ87kpZdeAozZ4tu0aUPPnj3p2LEj119/PTExMe68l1xyCWlpaeWeKzY2liuuuKLMfSNHjqSqppU6udj32ZBRikIIIUQ95+Xl5V6YuaacDLjuuOOOszrP//73P6644gq01rz22mucd9557Ny5Ew8PD3788cdTHtu0aVMWLVp0VtevKdLCJYQQQjRA6enpdOrUiX379gFw1VVX8cEHHwDg6+vLgw8+SO/evRk1ahSJiYkAHDp0iDFjxtCnTx+GDRvmnkIiPj6eiRMn0rNnT3r27MmaNWt49NFHOXToEJGRkUyfPh0wgqd+/foRERHBjBkz3GWZNWsWnTp14oILLnCX55+UUtx///2Eh4fz008/AUUtS4888kiJ1rSZM2fy8ssvc/ToUbp37w5Abm4uU6dOJSIigilTppCbm+vOv2zZMgYNGkTv3r2ZPHkyWVlZ7vPPmDGD3r1706NHD/f9Jicnc+GFF9KrVy9uu+22U669WFHSwiWEEEJUkT/mvk9C1OEqPWejVm05b9qtp8yTm5tLZGSke/uxxx5jypQpvPXWW0ybNo17772X1NRUbrnlFgCys7Pp3bs3L7/8Ms888wxPP/00b731FrfeeivvvfceHTp0YN26ddxxxx0sX76ce+65hxEjRrB48WIcDgdZWVnMnj2bnTt3ulvWli1bxoEDB1i/fj1aa8aNG8fKlSvx8fFh4cKFbNmyBbvdTu/evenTp0+599K7d2/27t3L+PHj3WlTp07lvvvuc7emffnll/z8888lFt5+99138fb2Zvv27Wzfvp3evXsDkJSUxHPPPcdvv/2Gj48PL7zwAq+88gpPPfUUAKGhoWzevJl33nmHl156iQ8//JCnn36aoUOH8tRTT7F06VLef//9ildYOSTgEkIIIeq58h4pjh49mq+++oo777yTbdu2udNNJhNTpkwB4Nprr2XSpElkZWWxZs0aJk+e7M6Xn58PwPLly/n0008Bo79YQEAAqampJa61bNkyli1bRq9evQDIysriwIEDZGZmMnHiRLy9vQEYN27cKe+lrNakXr16kZCQQGxsLImJiQQFBdGyZUuOHj3qzrNy5UruueceACIiIoiIiABg7dq17N69myFDhgBQUFDAoEGD3MdNmjQJgD59+vDNN9+4z3Xy9aWXXkpQUNApy1wREnAJIYQQVeR0LVE1zel0smfPHry8vEhJSaF58+Zl5lNK4XQ6CQwMPOO+YFprHnvsMW677bYS6a+99hpKqQqfZ8uWLYwaNapU+hVXXMGiRYs4ceIEU6dOLfPYsq6jtWb06NEsWLCgzGNsNhtgBJJ2u/2U5zob0odLCCGEaKBeffVVunTpwoIFC7jpppsoLCwEjEDsZGfzzz//nKFDh+Lv70+bNm346quvACNQOdkqNmrUKN59913AWPw6IyMDPz8/MjMz3de66KKL+Oijj9z9o2JiYkhISGD48OEsXryY3NxcMjMz+f7778ssq9aaN954g7i4OMaMGVNq/9SpU1m4cCGLFi0qc2Ti8OHDmT9/PgA7d+5k+/btAAwcOJDVq1dz8OBBAHJycti/f/8pf27Fz/XTTz+Vas07ExJwCSGEEPXcyT5cJ78effRR9u/fz4cffsjLL7/MsGHDGD58OM899xwAPj4+7Nq1iz59+rB8+XJ3f6b58+czZ84cevbsSbdu3fjuu+8AeP311/njjz/o0aMHffr0YdeuXYSEhDBkyBC6d+/O9OnTufDCC7n66qsZNGgQPXr04IorriAzM5PevXszZcoUIiMjufzyyxk2bFiJsk+fPt09LcSGDRv4448/8PDwKHWP3bp1IzMzk2bNmtGkSZNS+//973+TlZVFREQEL774Iv379wcgLCyMuXPnctVVVxEREcHAgQNPu57kjBkzWLlyJb1792bZsmW0bNmy8pXyD6oqet5Xp759++qqmkdDCCGEqGp79uyhS5cutV2MSvH19XW3RIkzV1bdK6U2aa37/jOvtHAJIYQQQlQzCbiEEEKIc4y0btU8CbiEEEIIIaqZBFxCCCGEENVMAi4hhBBCiGomAZcQQgghRDWTgEsIIYSox5KTk93zb4WHh9OsWTP3dkFBQZVeKy0trcQi0qLiZGkfIYQQoh4LCQlxL8czc+ZMfH19eeihh057nN1ux2KpXBhwMuA6uYi0qLgab+FSSo1RSu1TSh1USj1a09cXQgghGroPPviAfv360bNnTy6//HJycnIAmDZtGg888ADnnXcejzzyCIcOHWLgwIH069ePp556Cl9fX/c5/ve//9GvXz8iIiKYMWMGAI8++iiHDh0iMjKS6dOn18q91Vc12sKllDIDbwOjgWhgg1JqidZ6d02WQwghhKgOad8foiA2u0rP6dHUh8DL2lXqmEmTJnHLLbcA8OSTTzJnzhzuvvtuAPbv389vv/2G2Wxm7Nix3HvvvVx11VW899577uOXLVvGgQMHWL9+PVprxo0bx8qVK5k9ezY7d+484wWuz2U1/UixP3BQa30YQCm1EBgP1FrAtfPNLRCfU1uXF0IIUc85LvUhN8aYSNSeVYizwFGl57dnFbrPfzqFGQUUOvLZ9McGnv7fM6Snp5OVk80FI0aRG5OFI6eQ8RdcRsGJXAD+Xr2GBW/PIzcmi4kjx/GQfojcmCx+/OYHfvnpF3p27wlAdnY2u9bvoJFHCNrurHB56hqPxt6YLbXTfb2mA65mwPFi29HAgH9mUkrdCtwKVMmCkadiAZSq1ksIIYRowJzAybcR3+HNa7Mo7nLc+sDtfDlnARFde/DZl/NY+fcq9z4fLx/UP45RxY5VgNaa6Xc9yL+uvanE+aOOR5W4Tn1Tm+Wu6YCrrHsttXq21vp94H0wFq+uzgJ1vrtXdZ5eCCFEA7dnzx48m/mePmMNsPh7YPW1kZWTReue7TAH2fjyx69p1qwZns18MXtb8QjxdJd34OBBLF37C1OmTOHT9z8HBZ7NfLn08sv4z3/+w7Q7b8LX15eYmBisViuhHcLJys2uM/dbn9R0u1o00KLYdnMgtobLIIQQQjRozz77LAMGDGD06NF07ty53HyvvfYar7zyCv379ycuLo6AgAAALrzwQq6++moGDRpEjx49uOKKK8jMzCQkJIQhQ4bQvXt36TRfSUrram1AKnkxpSzAfmAUEANsAK7WWu8q75i+ffvqjRs31lAJhRBCiMrZs2cPXbp0qe1inJGcnBy8vLxQSrFw4UIWLFjAd999V9vFqjfKqnul1Catdd9/5q3RR4paa7tS6i7gF8AMfHSqYEsIIYQQ1WfTpk3cddddaK0JDAzko48+qu0iNVg1PvGp1vpH4Meavq4QQgghSho2bBjbtm2r7WKcE2RpHyGEEOIs1WT3HFE3VLbOJeASQgghzoKnpyfJyckSdJ1DtNYkJyfj6elZ4WNkLUUhhBDiLDRv3pzo6GgSExNruyiiBnl6etK8ecXnXZOASwghhDgLVquVNm3a1HYxRB0njxSFEEIIIaqZBFxCCCGEENVMAi4hhBBCiGpWozPNnwmlVCIQVY2XCAWSqvH84sxJ3dRtUj91l9RN3SV1U7dVRf200lqH/TOxzgdc1U0ptbGsKfhF7ZO6qdukfuouqZu6S+qmbqvO+pFHikIIIYQQ1UwCLiGEEEKIaiYBF7xf2wUQ5ZK6qdukfuouqZu6S+qmbqu2+jnn+3AJIYQQQlQ3aeESQgghhKhmEnAJIYQQQlQzCbiEEGVSSqnaLoMon9SPEJVXm38350TApZS6QCnVp7bLIUpTSgUUey1vIHWLLG5ft1lruwCifEopc22XQZSp1uKeBh1wKaV6KaV+AhYD7Wu7PKKIUmqAUuo74EOl1E1KKZuWERx1glJqoFJqPvCMUqqDvHHULUqpQUqpr4CXlFJdpX7qDlfdPAOgtXbUdnlEEaVUf6XUPOB5pVQPpVSNxz8NMuBSSpmVUu8DHwD/B3wOdHHta5D3XJ8opSKAt4FFwFfA+UhAXCcopboDbwI/APHArcD1rn3SAlnLlFKNgLeAHzGWH7kXuMm1T+qnFimlbgA+AZ5USl3pSpNW4lqmlDIppWYAHwI/YbTc3wn0rOmyNMjgw/XJ4mdgmNb6W+Br4DyllKfW2lmrhRMAfYCDWuvPgF8BT+DYyZ3yxlGrBgJ7tdYLMD6w5ADXKKVaa6211E2t6wns11p/DLwMfAOMV0p1lPqpdTEYHx7HYNQNWmu71Entcr3nRwPTtNbzgVlAK6DGW4YbTMCllBqhlBpwcltr/Y3WOtf1y+4E9gPetVbAc9g/6wZYCkxUSs0CdgDNgTeUUo8AyKPFmlNG3WwAWiil2mmtszH+dtKBW0DqpqYppSYopR5XSl3qStoK9C1WPxuAjcBtIPVTk4rVzVhX0h9AvNZ6GRCllHrWlS6tXDWsjL+bBcA2V9eVZCATaFLT5ar3AZdSyk8p9Q1GP63blFJBrnSllFKuf0B7gVEYLSnSglJDyqsbrXUCxid1C/C41nogMBcYqpQaVFvlPZeUUTfBrl2HgPXAx0qpb4G+GI99LUopz1op7DlIKRXm+vk/AKRg1McVWutEjBb7u11Z04DfAG+lVI2/gZyLyqibj5RSE11PVk6+t9wG3KOUaqy1Lqylop5zyvm7mai1ztFaO7TW+UopK8aH/H01Xb56H3ABBcBy4FogFpgMxic9VxO7SWsdDawDrji5r7YKe44ps24AtNZ7gc7AcVfSJiAByK/hMp6ryvu7ydJaPwzcBczVWl8GHAQitNZ5tVXYc1A7YLXWerjW+j3gQeB+174FQGel1CjX45JkoBlGS6SofmXVzXQArXWBUsqstd6F8UFlNoBS6uJaK+25pdy6KaYLRkvkftcHz/41Vbh6GXAppa53PQoJ1FrnY3SG+w3jsWFfpVRHVz6T1trp6rh4AMiuvVKfGypaNy7LgJmuFsepQDeMNw9RDU5TN32K143Werur/yMY/VLWSstw9XLVz0illDfGB5BPXelmYLfrC4zH8AuB15VS7TFa7xXgUfOlPjdUoG52uLYVoAG01v8CblBKpQI9ZcBW9ahE3Zx8tBsM5CilpgFrgB419b+t3jxbdv1AwjFGHDoxHn3cqpS6V2ud5MrzN9ARuBJ4zhVsmVwdF/2A1rVT+oatknUzBTjZt+EjjE7aP2N0YLxJax1Vw8Vv0M7k76bYsX0wOv86gFulZbjqlVM/twD3aq3jXa0lDqVUFyAA3J2A5ypjxOKjGC3Ft2it02rjHhqqStbNye4SGtBKqVbAq8Aq4E6t9c5auYkG6gzrxu46/CLgKoynKddorbfXVLnrRcTt+uFpwA+I0VqPAu7AeEb7fyfzaa0PYES4TZVS7V19Trxcux/QWv+nhove4J1B3TRRxtxO3lrrXOBG4Aat9QVa691lXEKcobP4uzn5N3MUmKG1HqW1PlSzpW/4TlM/7/8j+4UY06iglAoH0Fq/CNyhtR6qtd5TcyVv+M6ibsJcaenAbK31CAm2qtZZ1E1jV9oPwFVa65tqMtiCOt7C5WoCfAYwK6V+BPwxPm2fHG57DxCrlBqhtf7Tlb7YFdX+DPgC5wF75NN51TrLuvkJ8FVKned6ozhRO3fRMFXF341S6nxXAPxn7dxFw3Um9QNkAUeUManmJKXUGK11tNa6oDbuoaGqorq5RGt9DGPwiagiVVQ3F2utV9dG+aEOt3AppUZgfOoOwui0+yxQiDGfVn9wN98+A8wsdtxk4AmMIboR8smv6knd1F1VWDfS2lgNzqR+XH1RbsL4pO4PnKeNgUCiClVh3RwrdXJxVqqwbo6XOnkNUnW14UcpNQxorY3JMVFKvYPR+S0XuFtr3cfVCbER8AbwiNb6iOs4tNaraqnoDZ7UTd0ldVO3nUH9TMd4EnE38KnWenPtlLzhk7qpuxpK3dTZFi6MaPZLVbRO2GqgpdZ6LkaT4t2uzqPNAYfW+ggYbxjyplHtpG7qLqmbuq0y9ePUWkdprQ9pre+rK28aDZjUTd3VIOqmzgZc2pioLF8XLQA6Gkh0vb4R6KKU+gFjTpo68wM9F0jd1F1SN3VbJetnE8hEzTVF6qbuaih1U6c7zYP7OawGGgNLXMmZwONAd+CI1jqmlop3TpO6qbukbuq2ytSPDPipWVI3dVd9r5s628JVjBOwAklAhCuK/Q9Gs+Ff8qZRq6Ru6i6pm7pN6qfukrqpu+p13dTZTvPFKaUGYswIuwb4WGs9p5aLJFykbuouqZu6Teqn7pK6qbvqc93Ul4CrOXAd8Io2liQRdYTUTd0ldVO3Sf3UXVI3dVd9rpt6EXAJIYQQQtRn9aEPlxBCCCFEvSYBlxBCCCFENZOASwghhBCimknAJYQQQghRzSTgEkI0GEoph1Jqq1Jql1Jqm1LqAdcaa6c6prVS6uqaKqMQ4twkAZcQoiHJ1VpHaq27YSz/cQkw4zTHtAYk4BJCVCuZFkII0WAopbK01r7FttsCG4BQoBXwGeDj2n2X1nqNUmot0AU4AnwCvAHMBkYCNuBtrfX/1dhNCCEaJAm4hBANxj8DLldaKtAZY801p9Y6TynVAVigte6rlBoJPKS1HuvKfyvQSGv9nFLKBqwGJmutj9TkvQghGpY6v3i1EEKcJeX6bgXeUkpFAg6gYzn5L8RYp+0K13YA0AGjBUwIIc6IBFxCiAbL9UjRASRg9OWKB3pi9F/NK+8w4G6t9S81UkghxDlBOs0LIRokpVQY8B7wljb6TgQAcVprJ8ZabGZX1kzAr9ihvwD/VkpZXefpqJTyQQghzoK0cAkhGhIvpdRWjMeHdoxO8q+49r0DfK2Umgz8AWS70rcDdqXUNmAu8DrGyMXNSikFJAITaqb4QoiGSjrNCyGEEEJUM3mkKIQQQghRzSTgEkIIIYSoZhJwCSGEEEJUMwm4hBBCCCGqmQRcQgghhBDVTAIuIYQQQohqJgGXEEIIIUQ1k4BLCCGEEKKa/T/lVmiD0p6f9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical shape: (1202, 4)\n",
      "xtrain.shape: (900, 1)\n",
      "[[-0.00145879]\n",
      " [ 0.00073046]\n",
      " [ 0.00291971]\n",
      " [-0.0010917 ]\n",
      " [-0.00510018]]\n",
      "\n",
      "ytrain.shape: (901, 1)\n",
      "[[ 0.00073046]\n",
      " [ 0.00291971]\n",
      " [-0.0010917 ]\n",
      " [-0.00510018]\n",
      " [-0.0032955 ]]\n",
      "df_train_cat.shape: (901, 4)\n",
      "            day_of_year  month  day_of_week  RowId\n",
      "Date                                              \n",
      "2017-01-04            4      1            4    0.0\n",
      "2017-01-05            5      1            5    1.0\n",
      "2017-01-06            6      1            6    2.0\n",
      "2017-01-10           10      1           10    3.0\n",
      "2017-01-11           11      1           11    4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['RowId'] = enc.fit_transform(df['RowId'].to_numpy().reshape(-1, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' xtrain and df_train_cat have different shapes!!!!!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print('Raw Time Series data shape:', train_df.shape)\n",
    "print('No Unique Securities code:', train_df['SecuritiesCode'].nunique())\n",
    "\n",
    "df_1301 = train_df[train_df['SecuritiesCode'] == 1301].drop(['SecuritiesCode', 'Volume'], axis=1)\n",
    "\n",
    "print('df_1301.head()')\n",
    "print(df_1301.head(2))\n",
    "print(df_1301.info())\n",
    "\n",
    "df_1301.plot(figsize=(10, 6));\n",
    "plt.show();\n",
    "\n",
    "df_1301 = date_features(df_1301)\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Add RowId as extra catcol.\n",
    "\"\"\"\n",
    "# cont, cat = cont_cat_split(df_1301, 'int64')\n",
    "cat_cols = ['day_of_year', 'month', 'day_of_week', 'RowId']\n",
    "cont, cat = cont_cat_split(df_1301, cat_cols=cat_cols)\n",
    "print('categorical shape:', cat.shape)\n",
    "\n",
    "df_train_cat, df_val_cat = ts_split(cat)\n",
    "df_train, df_val = ts_split(cont)\n",
    "\n",
    "xtrain, ytrain = preprocess(df_train, 'Target', 1, continous_cols=['Close'])\n",
    "xval, yval = preprocess(df_val, 'Target', 1, continous_cols=['Close'])\n",
    "\n",
    "print('xtrain.shape:', xtrain.shape)\n",
    "print(xtrain[:5])\n",
    "print()\n",
    "print('ytrain.shape:', ytrain.shape)\n",
    "print(ytrain[:5])\n",
    "print('df_train_cat.shape:', df_train_cat.shape)\n",
    "print(df_train_cat.head())\n",
    "\n",
    "\"\"\" xtrain and df_train_cat have different shapes!!!!!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_FEATURES: 4\n",
      "NO_EMBEDDING: 1802\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (embedding): Embedding(1802, 10)\n",
      "  (embedding_to_hidden): Linear(in_features=10, out_features=500, bias=True)\n",
      "  (embedding_output): Linear(in_features=500, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=1, out_features=500, bias=True)\n",
      "  (hidden_layer): Linear(in_features=504, out_features=504, bias=True)\n",
      "  (output_layer): Linear(in_features=504, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (position_enc): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Using cuda-device\n",
      "Epoch: <<< 0 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.11568516492843628 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:239.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Loss: 0.06760261207818985 [1/15]\n",
      "train metrics: <<< {'mse': 0.06760261207818985, 'mae': 0.2060118168592453} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 1.8002163171768188 [2/15]\n",
      "train metrics: <<< {'mse': 1.8002163171768188, 'mae': 1.3231879472732544} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 1.1906684637069702 [3/15]\n",
      "train metrics: <<< {'mse': 1.1906684637069702, 'mae': 1.0686976909637451} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.29781174659729004 [4/15]\n",
      "train metrics: <<< {'mse': 0.29781174659729004, 'mae': 0.5069152116775513} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.37866008281707764 [5/15]\n",
      "train metrics: <<< {'mse': 0.37866008281707764, 'mae': 0.578450083732605} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.4999576508998871 [6/15]\n",
      "train metrics: <<< {'mse': 0.4999576508998871, 'mae': 0.6823417544364929} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.14788296818733215 [7/15]\n",
      "train metrics: <<< {'mse': 0.14788296818733215, 'mae': 0.3294672966003418} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 1.3918793201446533 [8/15]\n",
      "train metrics: <<< {'mse': 1.3918793201446533, 'mae': 1.1528382301330566} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.21075040102005005 [9/15]\n",
      "train metrics: <<< {'mse': 0.21075040102005005, 'mae': 0.39112821221351624} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 2.247816562652588 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.2740909457206726 [11/15]\n",
      "train metrics: <<< {'mse': 0.2740909457206726, 'mae': 0.3989998698234558} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 1.968400478363037 [12/15]\n",
      "train metrics: <<< {'mse': 1.968400478363037, 'mae': 1.3287765979766846} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.6214345693588257 [13/15]\n",
      "train metrics: <<< {'mse': 0.6214345693588257, 'mae': 0.7550280094146729} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.23546646535396576 [14/15]\n",
      "train metrics: <<< {'mse': 0.23546646535396576, 'mae': 0.4382825791835785} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.2535374164581299 [1/5]\n",
      "val metrics: {'mse': 0.2535374164581299, 'mae': 0.5032436847686768}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.2555088400840759 [2/5]\n",
      "val metrics: {'mse': 0.2555088400840759, 'mae': 0.5051485300064087}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.24742983281612396 [3/5]\n",
      "val metrics: {'mse': 0.24742983281612396, 'mae': 0.4970139265060425}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.25223469734191895 [4/5]\n",
      "val metrics: {'mse': 0.25223469734191895, 'mae': 0.5020253658294678}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.251009464263916 [5/5]\n",
      "val metrics: {'mse': 0.251009464263916, 'mae': 0.5004978775978088}\n",
      "\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.3056684136390686 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.28814253211021423 [1/15]\n",
      "train metrics: <<< {'mse': 0.28814253211021423, 'mae': 0.4929947257041931} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.24014589190483093 [2/15]\n",
      "train metrics: <<< {'mse': 0.24014589190483093, 'mae': 0.4382588565349579} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.10307320952415466 [3/15]\n",
      "train metrics: <<< {'mse': 0.10307320952415466, 'mae': 0.26360857486724854} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.06160789728164673 [4/15]\n",
      "train metrics: <<< {'mse': 0.06160789728164673, 'mae': 0.20750904083251953} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.08550457656383514 [5/15]\n",
      "train metrics: <<< {'mse': 0.08550457656383514, 'mae': 0.24696451425552368} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.24928459525108337 [6/15]\n",
      "train metrics: <<< {'mse': 0.24928459525108337, 'mae': 0.45812177658081055} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.29399991035461426 [7/15]\n",
      "train metrics: <<< {'mse': 0.29399991035461426, 'mae': 0.49783894419670105} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.2097587287425995 [8/15]\n",
      "train metrics: <<< {'mse': 0.2097587287425995, 'mae': 0.4242974519729614} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.136423259973526 [9/15]\n",
      "train metrics: <<< {'mse': 0.136423259973526, 'mae': 0.32241690158843994} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.039627231657505035 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.046555083245038986 [11/15]\n",
      "train metrics: <<< {'mse': 0.046555083245038986, 'mae': 0.18634068965911865} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.11852268874645233 [12/15]\n",
      "train metrics: <<< {'mse': 0.11852268874645233, 'mae': 0.31019139289855957} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.16957572102546692 [13/15]\n",
      "train metrics: <<< {'mse': 0.16957572102546692, 'mae': 0.3888171911239624} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.17140573263168335 [14/15]\n",
      "train metrics: <<< {'mse': 0.17140573263168335, 'mae': 0.3982856869697571} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0037873433902859688 [1/5]\n",
      "val metrics: {'mse': 0.0037873433902859688, 'mae': 0.05850759893655777}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.003518475219607353 [2/5]\n",
      "val metrics: {'mse': 0.003518475219607353, 'mae': 0.05733266472816467}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0038606193847954273 [3/5]\n",
      "val metrics: {'mse': 0.0038606193847954273, 'mae': 0.05941550061106682}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.003534924238920212 [4/5]\n",
      "val metrics: {'mse': 0.003534924238920212, 'mae': 0.05798567831516266}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0040704188868403435 [5/5]\n",
      "val metrics: {'mse': 0.0040704188868403435, 'mae': 0.06082766875624657}\n",
      "\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.02672938071191311 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.021761130541563034 [1/15]\n",
      "train metrics: <<< {'mse': 0.021761130541563034, 'mae': 0.11687178164720535} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.026673700660467148 [2/15]\n",
      "train metrics: <<< {'mse': 0.026673700660467148, 'mae': 0.12875306606292725} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.025174368172883987 [3/15]\n",
      "train metrics: <<< {'mse': 0.025174368172883987, 'mae': 0.1282605230808258} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.020214512944221497 [4/15]\n",
      "train metrics: <<< {'mse': 0.020214512944221497, 'mae': 0.11445305496454239} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.024210959672927856 [5/15]\n",
      "train metrics: <<< {'mse': 0.024210959672927856, 'mae': 0.12618327140808105} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.027582187205553055 [6/15]\n",
      "train metrics: <<< {'mse': 0.027582187205553055, 'mae': 0.13525840640068054} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.02541058324277401 [7/15]\n",
      "train metrics: <<< {'mse': 0.02541058324277401, 'mae': 0.12086984515190125} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.035840440541505814 [8/15]\n",
      "train metrics: <<< {'mse': 0.035840440541505814, 'mae': 0.1565043330192566} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.020601172000169754 [9/15]\n",
      "train metrics: <<< {'mse': 0.020601172000169754, 'mae': 0.11682652682065964} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.023687615990638733 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01678982749581337 [11/15]\n",
      "train metrics: <<< {'mse': 0.01678982749581337, 'mae': 0.1063758134841919} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01732882298529148 [12/15]\n",
      "train metrics: <<< {'mse': 0.01732882298529148, 'mae': 0.10812603682279587} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.025682326406240463 [13/15]\n",
      "train metrics: <<< {'mse': 0.025682326406240463, 'mae': 0.12784183025360107} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.012329036369919777 [14/15]\n",
      "train metrics: <<< {'mse': 0.012329036369919777, 'mae': 0.08806419372558594} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0016924382653087378 [1/5]\n",
      "val metrics: {'mse': 0.0016924382653087378, 'mae': 0.03689152002334595}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.001504015177488327 [2/5]\n",
      "val metrics: {'mse': 0.001504015177488327, 'mae': 0.03630133345723152}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0016888686222955585 [3/5]\n",
      "val metrics: {'mse': 0.0016888686222955585, 'mae': 0.03769848495721817}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0014882844407111406 [4/5]\n",
      "val metrics: {'mse': 0.0014882844407111406, 'mae': 0.03642057627439499}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.001928520854562521 [5/5]\n",
      "val metrics: {'mse': 0.001928520854562521, 'mae': 0.03986773267388344}\n",
      "\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014899433590471745 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014854548498988152 [1/15]\n",
      "train metrics: <<< {'mse': 0.014854548498988152, 'mae': 0.0989760309457779} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01576191559433937 [2/15]\n",
      "train metrics: <<< {'mse': 0.01576191559433937, 'mae': 0.10143503546714783} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01862940564751625 [3/15]\n",
      "train metrics: <<< {'mse': 0.01862940564751625, 'mae': 0.10910230129957199} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013951126486063004 [4/15]\n",
      "train metrics: <<< {'mse': 0.013951126486063004, 'mae': 0.09975247085094452} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01281608548015356 [5/15]\n",
      "train metrics: <<< {'mse': 0.01281608548015356, 'mae': 0.08958594501018524} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.015213612467050552 [6/15]\n",
      "train metrics: <<< {'mse': 0.015213612467050552, 'mae': 0.09643784165382385} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013448139652609825 [7/15]\n",
      "train metrics: <<< {'mse': 0.013448139652609825, 'mae': 0.09491802752017975} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.012562963180243969 [8/15]\n",
      "train metrics: <<< {'mse': 0.012562963180243969, 'mae': 0.08479461073875427} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.012148160487413406 [9/15]\n",
      "train metrics: <<< {'mse': 0.012148160487413406, 'mae': 0.08579616248607635} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.02160998061299324 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013527310453355312 [11/15]\n",
      "train metrics: <<< {'mse': 0.013527310453355312, 'mae': 0.09306789934635162} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.016147702932357788 [12/15]\n",
      "train metrics: <<< {'mse': 0.016147702932357788, 'mae': 0.09982915222644806} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01356487162411213 [13/15]\n",
      "train metrics: <<< {'mse': 0.01356487162411213, 'mae': 0.08994849026203156} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.003043312346562743 [14/15]\n",
      "train metrics: <<< {'mse': 0.003043312346562743, 'mae': 0.04745214059948921} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0015413593500852585 [1/5]\n",
      "val metrics: {'mse': 0.0015413593500852585, 'mae': 0.03688971325755119}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.001468819216825068 [2/5]\n",
      "val metrics: {'mse': 0.001468819216825068, 'mae': 0.036583349108695984}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0014352102298289537 [3/5]\n",
      "val metrics: {'mse': 0.0014352102298289537, 'mae': 0.03575824946165085}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0014083108399063349 [4/5]\n",
      "val metrics: {'mse': 0.0014083108399063349, 'mae': 0.03633877635002136}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0016123687382787466 [5/5]\n",
      "val metrics: {'mse': 0.0016123686218634248, 'mae': 0.03771553933620453}\n",
      "\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014117853716015816 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.015117919072508812 [1/15]\n",
      "train metrics: <<< {'mse': 0.015117919072508812, 'mae': 0.09549814462661743} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014288794249296188 [2/15]\n",
      "train metrics: <<< {'mse': 0.014288794249296188, 'mae': 0.09383377432823181} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.015837304294109344 [3/15]\n",
      "train metrics: <<< {'mse': 0.015837304294109344, 'mae': 0.10309919714927673} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.015194121748209 [4/15]\n",
      "train metrics: <<< {'mse': 0.015194121748209, 'mae': 0.09529902040958405} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014682091772556305 [5/15]\n",
      "train metrics: <<< {'mse': 0.014682091772556305, 'mae': 0.093904510140419} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014124440029263496 [6/15]\n",
      "train metrics: <<< {'mse': 0.014124440029263496, 'mae': 0.09522294998168945} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011610709130764008 [7/15]\n",
      "train metrics: <<< {'mse': 0.011610709130764008, 'mae': 0.08757957071065903} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01267588883638382 [8/15]\n",
      "train metrics: <<< {'mse': 0.01267588883638382, 'mae': 0.08947160840034485} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01718669757246971 [9/15]\n",
      "train metrics: <<< {'mse': 0.01718669757246971, 'mae': 0.10489422082901001} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.014584757387638092 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.017433103173971176 [11/15]\n",
      "train metrics: <<< {'mse': 0.017433103173971176, 'mae': 0.10606493800878525} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01860676519572735 [12/15]\n",
      "train metrics: <<< {'mse': 0.01860676519572735, 'mae': 0.10740931332111359} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013711318373680115 [13/15]\n",
      "train metrics: <<< {'mse': 0.013711318373680115, 'mae': 0.09671442210674286} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.003063552314415574 [14/15]\n",
      "train metrics: <<< {'mse': 0.003063552314415574, 'mae': 0.04579853639006615} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.000770466635003686 [1/5]\n",
      "val metrics: {'mse': 0.000770466635003686, 'mae': 0.02535964548587799}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0007576412754133344 [2/5]\n",
      "val metrics: {'mse': 0.0007576412754133344, 'mae': 0.0255521759390831}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006624764646403491 [3/5]\n",
      "val metrics: {'mse': 0.0006624764646403491, 'mae': 0.023551873862743378}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006766897859051824 [4/5]\n",
      "val metrics: {'mse': 0.0006766897859051824, 'mae': 0.0246626827865839}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0008044728892855346 [5/5]\n",
      "val metrics: {'mse': 0.0008044728892855346, 'mae': 0.02527257800102234}\n",
      "\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008690379559993744 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01036353874951601 [1/15]\n",
      "train metrics: <<< {'mse': 0.01036353874951601, 'mae': 0.07881384342908859} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013023314997553825 [2/15]\n",
      "train metrics: <<< {'mse': 0.013023314997553825, 'mae': 0.09719645977020264} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.01004201453179121 [3/15]\n",
      "train metrics: <<< {'mse': 0.01004201453179121, 'mae': 0.08287343382835388} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011993011459708214 [4/15]\n",
      "train metrics: <<< {'mse': 0.011993011459708214, 'mae': 0.08363164961338043} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.016750594601035118 [5/15]\n",
      "train metrics: <<< {'mse': 0.016750594601035118, 'mae': 0.10625363886356354} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013946173712611198 [6/15]\n",
      "train metrics: <<< {'mse': 0.013946173712611198, 'mae': 0.09308349341154099} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011813770979642868 [7/15]\n",
      "train metrics: <<< {'mse': 0.011813770979642868, 'mae': 0.0902499407529831} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.013073988258838654 [8/15]\n",
      "train metrics: <<< {'mse': 0.013073988258838654, 'mae': 0.0909467339515686} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010514134541153908 [9/15]\n",
      "train metrics: <<< {'mse': 0.010514134541153908, 'mae': 0.07893157005310059} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011059518903493881 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.012491719797253609 [11/15]\n",
      "train metrics: <<< {'mse': 0.012491719797253609, 'mae': 0.08917184174060822} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.012104073539376259 [12/15]\n",
      "train metrics: <<< {'mse': 0.012104073539376259, 'mae': 0.0935269445180893} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011351985856890678 [13/15]\n",
      "train metrics: <<< {'mse': 0.011351985856890678, 'mae': 0.07897959649562836} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.005040670279413462 [14/15]\n",
      "train metrics: <<< {'mse': 0.005040670279413462, 'mae': 0.06020531430840492} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0004102999228052795 [1/5]\n",
      "val metrics: {'mse': 0.0004102999228052795, 'mae': 0.01733315736055374}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003962994087487459 [2/5]\n",
      "val metrics: {'mse': 0.0003962994087487459, 'mae': 0.01744544878602028}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003388627665117383 [3/5]\n",
      "val metrics: {'mse': 0.0003388627665117383, 'mae': 0.015558434650301933}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00032851274590939283 [4/5]\n",
      "val metrics: {'mse': 0.00032851274590939283, 'mae': 0.01637178286910057}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0004619636165443808 [5/5]\n",
      "val metrics: {'mse': 0.00046196358744055033, 'mae': 0.01728987507522106}\n",
      "\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011874456889927387 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.012516929768025875 [1/15]\n",
      "train metrics: <<< {'mse': 0.012516929768025875, 'mae': 0.09164250642061234} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008532621897757053 [2/15]\n",
      "train metrics: <<< {'mse': 0.008532621897757053, 'mae': 0.07714015990495682} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011874058283865452 [3/15]\n",
      "train metrics: <<< {'mse': 0.011874058283865452, 'mae': 0.08926413953304291} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010835538618266582 [4/15]\n",
      "train metrics: <<< {'mse': 0.010835538618266582, 'mae': 0.08578010648488998} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008878736756742 [5/15]\n",
      "train metrics: <<< {'mse': 0.008878736756742, 'mae': 0.0751415565609932} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007970135658979416 [6/15]\n",
      "train metrics: <<< {'mse': 0.007970135658979416, 'mae': 0.06996677815914154} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010864555835723877 [7/15]\n",
      "train metrics: <<< {'mse': 0.010864555835723877, 'mae': 0.07850345969200134} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008536070585250854 [8/15]\n",
      "train metrics: <<< {'mse': 0.008536070585250854, 'mae': 0.07687698304653168} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00965543556958437 [9/15]\n",
      "train metrics: <<< {'mse': 0.00965543556958437, 'mae': 0.07889998704195023} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.011996790766716003 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008226701058447361 [11/15]\n",
      "train metrics: <<< {'mse': 0.008226701058447361, 'mae': 0.07523314654827118} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010633033700287342 [12/15]\n",
      "train metrics: <<< {'mse': 0.010633033700287342, 'mae': 0.08794751763343811} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00827029999345541 [13/15]\n",
      "train metrics: <<< {'mse': 0.00827029999345541, 'mae': 0.07371900975704193} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.005203293636441231 [14/15]\n",
      "train metrics: <<< {'mse': 0.005203293636441231, 'mae': 0.0646420568227768} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00019523827359080315 [1/5]\n",
      "val metrics: {'mse': 0.00019523827359080315, 'mae': 0.010373670607805252}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016837919247336686 [2/5]\n",
      "val metrics: {'mse': 0.00016837919247336686, 'mae': 0.010551100596785545}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016124802641570568 [3/5]\n",
      "val metrics: {'mse': 0.00016124802641570568, 'mae': 0.009426813572645187}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00011889437155332416 [4/5]\n",
      "val metrics: {'mse': 0.00011889437155332416, 'mae': 0.008631531149148941}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0002738600305747241 [5/5]\n",
      "val metrics: {'mse': 0.0002738600305747241, 'mae': 0.011395248584449291}\n",
      "\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00684349425137043 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.009404605254530907 [1/15]\n",
      "train metrics: <<< {'mse': 0.009404605254530907, 'mae': 0.08063390105962753} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.009195463731884956 [2/15]\n",
      "train metrics: <<< {'mse': 0.009195463731884956, 'mae': 0.08246135711669922} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010159211233258247 [3/15]\n",
      "train metrics: <<< {'mse': 0.010159211233258247, 'mae': 0.0775141716003418} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.010340615175664425 [4/15]\n",
      "train metrics: <<< {'mse': 0.010340615175664425, 'mae': 0.08286319673061371} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007683280855417252 [5/15]\n",
      "train metrics: <<< {'mse': 0.007683280855417252, 'mae': 0.06914918124675751} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007295920513570309 [6/15]\n",
      "train metrics: <<< {'mse': 0.007295920513570309, 'mae': 0.06695128977298737} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007321340963244438 [7/15]\n",
      "train metrics: <<< {'mse': 0.007321340963244438, 'mae': 0.07024596631526947} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007036373484879732 [8/15]\n",
      "train metrics: <<< {'mse': 0.007036373484879732, 'mae': 0.06772632896900177} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.009719669818878174 [9/15]\n",
      "train metrics: <<< {'mse': 0.009719669818878174, 'mae': 0.08221647143363953} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006008266471326351 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.008360820822417736 [11/15]\n",
      "train metrics: <<< {'mse': 0.008360820822417736, 'mae': 0.07123054563999176} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0075910137966275215 [12/15]\n",
      "train metrics: <<< {'mse': 0.0075910137966275215, 'mae': 0.07224729657173157} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006178070791065693 [13/15]\n",
      "train metrics: <<< {'mse': 0.006178070791065693, 'mae': 0.062347300350666046} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.005155843682587147 [14/15]\n",
      "train metrics: <<< {'mse': 0.005155843682587147, 'mae': 0.06639096140861511} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00014545654994435608 [1/5]\n",
      "val metrics: {'mse': 0.00014545654994435608, 'mae': 0.009264256805181503}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012500360026024282 [2/5]\n",
      "val metrics: {'mse': 0.00012500360026024282, 'mae': 0.008090625517070293}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016341390437446535 [3/5]\n",
      "val metrics: {'mse': 0.00016341390437446535, 'mae': 0.01017152052372694}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 9.160863555734977e-05 [4/5]\n",
      "val metrics: {'mse': 9.160863555734977e-05, 'mae': 0.007825152017176151}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0002390326262684539 [5/5]\n",
      "val metrics: {'mse': 0.00023903261171653867, 'mae': 0.011419525370001793}\n",
      "\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006015883758664131 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00763004831969738 [1/15]\n",
      "train metrics: <<< {'mse': 0.00763004831969738, 'mae': 0.06784921139478683} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00789698027074337 [2/15]\n",
      "train metrics: <<< {'mse': 0.00789698027074337, 'mae': 0.06745818257331848} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006182387471199036 [3/15]\n",
      "train metrics: <<< {'mse': 0.006182387471199036, 'mae': 0.06414490193128586} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007628652732819319 [4/15]\n",
      "train metrics: <<< {'mse': 0.007628652732819319, 'mae': 0.0693008154630661} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00784367322921753 [5/15]\n",
      "train metrics: <<< {'mse': 0.00784367322921753, 'mae': 0.07069651782512665} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006450665183365345 [6/15]\n",
      "train metrics: <<< {'mse': 0.006450665183365345, 'mae': 0.06300216168165207} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006249952130019665 [7/15]\n",
      "train metrics: <<< {'mse': 0.006249952130019665, 'mae': 0.0640755444765091} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004752920940518379 [8/15]\n",
      "train metrics: <<< {'mse': 0.004752920940518379, 'mae': 0.05297747999429703} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005341281183063984 [9/15]\n",
      "train metrics: <<< {'mse': 0.005341281183063984, 'mae': 0.059268224984407425} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0072255684062838554 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0062468512915074825 [11/15]\n",
      "train metrics: <<< {'mse': 0.0062468512915074825, 'mae': 0.061131566762924194} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0054739685729146 [12/15]\n",
      "train metrics: <<< {'mse': 0.0054739685729146, 'mae': 0.0590076707303524} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.009609981440007687 [13/15]\n",
      "train metrics: <<< {'mse': 0.009609981440007687, 'mae': 0.07953006029129028} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.006047312635928392 [14/15]\n",
      "train metrics: <<< {'mse': 0.006047312635928392, 'mae': 0.06277000904083252} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012063253234373406 [1/5]\n",
      "val metrics: {'mse': 0.00012063253234373406, 'mae': 0.007786264643073082}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012264792167115957 [2/5]\n",
      "val metrics: {'mse': 0.00012264792167115957, 'mae': 0.008284207433462143}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00013305475295055658 [3/5]\n",
      "val metrics: {'mse': 0.00013305475295055658, 'mae': 0.008640743792057037}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 7.302130688913167e-05 [4/5]\n",
      "val metrics: {'mse': 7.302130688913167e-05, 'mae': 0.006825165823101997}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0001947487035067752 [5/5]\n",
      "val metrics: {'mse': 0.00019474868895485997, 'mae': 0.009528983384370804}\n",
      "\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006638731341809034 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0073228515684604645 [1/15]\n",
      "train metrics: <<< {'mse': 0.0073228515684604645, 'mae': 0.06816941499710083} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0052361441776156425 [2/15]\n",
      "train metrics: <<< {'mse': 0.0052361441776156425, 'mae': 0.05660523474216461} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006955157034099102 [3/15]\n",
      "train metrics: <<< {'mse': 0.006955157034099102, 'mae': 0.06795932352542877} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.007050163112580776 [4/15]\n",
      "train metrics: <<< {'mse': 0.007050163112580776, 'mae': 0.06895922869443893} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005935130640864372 [5/15]\n",
      "train metrics: <<< {'mse': 0.005935130640864372, 'mae': 0.06361763179302216} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0051330020651221275 [6/15]\n",
      "train metrics: <<< {'mse': 0.0051330020651221275, 'mae': 0.05663958191871643} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006834275089204311 [7/15]\n",
      "train metrics: <<< {'mse': 0.006834275089204311, 'mae': 0.06618592143058777} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005475952755659819 [8/15]\n",
      "train metrics: <<< {'mse': 0.005475952755659819, 'mae': 0.060216501355171204} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006331061478704214 [9/15]\n",
      "train metrics: <<< {'mse': 0.006331061478704214, 'mae': 0.06341937184333801} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006091682240366936 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004786644130945206 [11/15]\n",
      "train metrics: <<< {'mse': 0.004786644130945206, 'mae': 0.05554831773042679} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0057387566193938255 [12/15]\n",
      "train metrics: <<< {'mse': 0.0057387566193938255, 'mae': 0.058673709630966187} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0049202218651771545 [13/15]\n",
      "train metrics: <<< {'mse': 0.0049202218651771545, 'mae': 0.05491477623581886} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.005713434424251318 [14/15]\n",
      "train metrics: <<< {'mse': 0.005713434424251318, 'mae': 0.05067546293139458} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00023754579888191074 [1/5]\n",
      "val metrics: {'mse': 0.00023754579888191074, 'mae': 0.013337496668100357}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002287223469465971 [2/5]\n",
      "val metrics: {'mse': 0.0002287223469465971, 'mae': 0.012184832245111465}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003292685141786933 [3/5]\n",
      "val metrics: {'mse': 0.0003292685141786933, 'mae': 0.015613589435815811}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00021127352374605834 [4/5]\n",
      "val metrics: {'mse': 0.00021127352374605834, 'mae': 0.012131886556744576}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0003501058090478182 [5/5]\n",
      "val metrics: {'mse': 0.00035010577994398773, 'mae': 0.015810368582606316}\n",
      "\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004293580539524555 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0049728164449334145 [1/15]\n",
      "train metrics: <<< {'mse': 0.0049728164449334145, 'mae': 0.057665638625621796} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004752228036522865 [2/15]\n",
      "train metrics: <<< {'mse': 0.004752228036522865, 'mae': 0.058701515197753906} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0038630214985460043 [3/15]\n",
      "train metrics: <<< {'mse': 0.0038630214985460043, 'mae': 0.049109261482954025} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005468314979225397 [4/15]\n",
      "train metrics: <<< {'mse': 0.005468314979225397, 'mae': 0.06174861639738083} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0066909948363900185 [5/15]\n",
      "train metrics: <<< {'mse': 0.0066909948363900185, 'mae': 0.06321072578430176} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.006600127089768648 [6/15]\n",
      "train metrics: <<< {'mse': 0.006600127089768648, 'mae': 0.06372208893299103} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005570080131292343 [7/15]\n",
      "train metrics: <<< {'mse': 0.005570080131292343, 'mae': 0.059713706374168396} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005128835327923298 [8/15]\n",
      "train metrics: <<< {'mse': 0.005128835327923298, 'mae': 0.06032302603125572} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003914591856300831 [9/15]\n",
      "train metrics: <<< {'mse': 0.003914591856300831, 'mae': 0.05036266893148422} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003518729005008936 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005058324430137873 [11/15]\n",
      "train metrics: <<< {'mse': 0.005058324430137873, 'mae': 0.059551432728767395} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004556235857307911 [12/15]\n",
      "train metrics: <<< {'mse': 0.004556235857307911, 'mae': 0.05266571417450905} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0048310765996575356 [13/15]\n",
      "train metrics: <<< {'mse': 0.0048310765996575356, 'mae': 0.052226945757865906} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0020698471926152706 [14/15]\n",
      "train metrics: <<< {'mse': 0.0020698471926152706, 'mae': 0.040334537625312805} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00018087567877955735 [1/5]\n",
      "val metrics: {'mse': 0.00018087567877955735, 'mae': 0.01031076442450285}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00018878115224651992 [2/5]\n",
      "val metrics: {'mse': 0.00018878115224651992, 'mae': 0.011221772991120815}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0001571980828884989 [3/5]\n",
      "val metrics: {'mse': 0.0001571980828884989, 'mae': 0.009584374725818634}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012266525300219655 [4/5]\n",
      "val metrics: {'mse': 0.00012266525300219655, 'mae': 0.009071031585335732}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00023569785116706043 [5/5]\n",
      "val metrics: {'mse': 0.00023569785116706043, 'mae': 0.011089816689491272}\n",
      "\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003974840976297855 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0047844890505075455 [1/15]\n",
      "train metrics: <<< {'mse': 0.0047844890505075455, 'mae': 0.0527566559612751} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004844787530601025 [2/15]\n",
      "train metrics: <<< {'mse': 0.004844787530601025, 'mae': 0.054550863802433014} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004798085428774357 [3/15]\n",
      "train metrics: <<< {'mse': 0.004798085428774357, 'mae': 0.05518311262130737} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003815093543380499 [4/15]\n",
      "train metrics: <<< {'mse': 0.003815093543380499, 'mae': 0.04958818480372429} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0041144974529743195 [5/15]\n",
      "train metrics: <<< {'mse': 0.0041144974529743195, 'mae': 0.05271118879318237} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005153190344572067 [6/15]\n",
      "train metrics: <<< {'mse': 0.005153190344572067, 'mae': 0.056547775864601135} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0035400772467255592 [7/15]\n",
      "train metrics: <<< {'mse': 0.0035400772467255592, 'mae': 0.04837688058614731} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0040234895423054695 [8/15]\n",
      "train metrics: <<< {'mse': 0.0040234895423054695, 'mae': 0.05096636340022087} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003331846557557583 [9/15]\n",
      "train metrics: <<< {'mse': 0.003331846557557583, 'mae': 0.0446053184568882} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005095197353512049 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.005371210165321827 [11/15]\n",
      "train metrics: <<< {'mse': 0.005371210165321827, 'mae': 0.05897672846913338} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00542051438242197 [12/15]\n",
      "train metrics: <<< {'mse': 0.00542051438242197, 'mae': 0.058585137128829956} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0043151541613042355 [13/15]\n",
      "train metrics: <<< {'mse': 0.0043151541613042355, 'mae': 0.05238625779747963} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0020601684227585793 [14/15]\n",
      "train metrics: <<< {'mse': 0.0020601684227585793, 'mae': 0.04301201552152634} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012195315503049642 [1/5]\n",
      "val metrics: {'mse': 0.00012195315503049642, 'mae': 0.007770991884171963}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00011892828479176387 [2/5]\n",
      "val metrics: {'mse': 0.00011892828479176387, 'mae': 0.008051473647356033}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012932420941069722 [3/5]\n",
      "val metrics: {'mse': 0.00012932420941069722, 'mae': 0.00851261056959629}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 7.170048775151372e-05 [4/5]\n",
      "val metrics: {'mse': 7.170048775151372e-05, 'mae': 0.006733693182468414}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00019511407299432904 [5/5]\n",
      "val metrics: {'mse': 0.00019511407299432904, 'mae': 0.009542648680508137}\n",
      "\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0030847142916172743 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0027292913291603327 [1/15]\n",
      "train metrics: <<< {'mse': 0.0027292913291603327, 'mae': 0.04017888754606247} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004223180934786797 [2/15]\n",
      "train metrics: <<< {'mse': 0.004223180934786797, 'mae': 0.05059737712144852} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003284723497927189 [3/15]\n",
      "train metrics: <<< {'mse': 0.003284723497927189, 'mae': 0.046221472322940826} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004357188008725643 [4/15]\n",
      "train metrics: <<< {'mse': 0.004357188008725643, 'mae': 0.05097697675228119} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0027643118519335985 [5/15]\n",
      "train metrics: <<< {'mse': 0.0027643118519335985, 'mae': 0.043364331126213074} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0037913997657597065 [6/15]\n",
      "train metrics: <<< {'mse': 0.0037913997657597065, 'mae': 0.04923807084560394} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0041156187653541565 [7/15]\n",
      "train metrics: <<< {'mse': 0.0041156187653541565, 'mae': 0.050385698676109314} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0039976914413273335 [8/15]\n",
      "train metrics: <<< {'mse': 0.0039976914413273335, 'mae': 0.04977259039878845} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003770106937736273 [9/15]\n",
      "train metrics: <<< {'mse': 0.003770106937736273, 'mae': 0.04886345565319061} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0035831681452691555 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00390640739351511 [11/15]\n",
      "train metrics: <<< {'mse': 0.00390640739351511, 'mae': 0.05083022266626358} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004557024221867323 [12/15]\n",
      "train metrics: <<< {'mse': 0.004557024221867323, 'mae': 0.05449548736214638} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0033550290390849113 [13/15]\n",
      "train metrics: <<< {'mse': 0.0033550290390849113, 'mae': 0.04612073674798012} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.008336236700415611 [14/15]\n",
      "train metrics: <<< {'mse': 0.008336236700415611, 'mae': 0.06213396415114403} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006512117106467485 [1/5]\n",
      "val metrics: {'mse': 0.0006512117106467485, 'mae': 0.02363615855574608}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006230445578694344 [2/5]\n",
      "val metrics: {'mse': 0.0006230445578694344, 'mae': 0.023169253021478653}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.000727831618860364 [3/5]\n",
      "val metrics: {'mse': 0.000727831618860364, 'mae': 0.02456773817539215}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.000612271367572248 [4/5]\n",
      "val metrics: {'mse': 0.000612271367572248, 'mae': 0.023199480026960373}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.000788953504525125 [5/5]\n",
      "val metrics: {'mse': 0.000788953504525125, 'mae': 0.02497241646051407}\n",
      "\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0027509010396897793 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0035516179632395506 [1/15]\n",
      "train metrics: <<< {'mse': 0.0035516179632395506, 'mae': 0.050545863807201385} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0035138507373631 [2/15]\n",
      "train metrics: <<< {'mse': 0.0035138507373631, 'mae': 0.045998699963092804} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0032940467353910208 [3/15]\n",
      "train metrics: <<< {'mse': 0.0032940467353910208, 'mae': 0.04443184286355972} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0037407870404422283 [4/15]\n",
      "train metrics: <<< {'mse': 0.0037407870404422283, 'mae': 0.048979878425598145} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003181047737598419 [5/15]\n",
      "train metrics: <<< {'mse': 0.003181047737598419, 'mae': 0.043555304408073425} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0040591005235910416 [6/15]\n",
      "train metrics: <<< {'mse': 0.0040591005235910416, 'mae': 0.05053846165537834} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00360471592284739 [7/15]\n",
      "train metrics: <<< {'mse': 0.00360471592284739, 'mae': 0.046008430421352386} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0036707562394440174 [8/15]\n",
      "train metrics: <<< {'mse': 0.0036707562394440174, 'mae': 0.04860338568687439} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.004453648347407579 [9/15]\n",
      "train metrics: <<< {'mse': 0.004453648347407579, 'mae': 0.05389270931482315} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0036846669390797615 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0029502729885280132 [11/15]\n",
      "train metrics: <<< {'mse': 0.0029502729885280132, 'mae': 0.04495718702673912} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002958722645416856 [12/15]\n",
      "train metrics: <<< {'mse': 0.002958722645416856, 'mae': 0.0450390949845314} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0029730130918323994 [13/15]\n",
      "train metrics: <<< {'mse': 0.0029730130918323994, 'mae': 0.044427815824747086} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.007711741607636213 [14/15]\n",
      "train metrics: <<< {'mse': 0.007711741607636213, 'mae': 0.0713440477848053} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003496718709357083 [1/5]\n",
      "val metrics: {'mse': 0.0003496718709357083, 'mae': 0.016390550881624222}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00032481650123372674 [2/5]\n",
      "val metrics: {'mse': 0.00032481650123372674, 'mae': 0.015687722712755203}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0004103932878933847 [3/5]\n",
      "val metrics: {'mse': 0.0004103932878933847, 'mae': 0.018046732991933823}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003087955992668867 [4/5]\n",
      "val metrics: {'mse': 0.0003087955992668867, 'mae': 0.015595048666000366}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0004649220791179687 [5/5]\n",
      "val metrics: {'mse': 0.0004649220791179687, 'mae': 0.01809772290289402}\n",
      "\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003161771921440959 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0033447386231273413 [1/15]\n",
      "train metrics: <<< {'mse': 0.0033447386231273413, 'mae': 0.04650215059518814} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002166218589991331 [2/15]\n",
      "train metrics: <<< {'mse': 0.002166218589991331, 'mae': 0.0371837392449379} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002550590317696333 [3/15]\n",
      "train metrics: <<< {'mse': 0.002550590317696333, 'mae': 0.039804067462682724} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002070147544145584 [4/15]\n",
      "train metrics: <<< {'mse': 0.002070147544145584, 'mae': 0.03875387832522392} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0023198742419481277 [5/15]\n",
      "train metrics: <<< {'mse': 0.0023198742419481277, 'mae': 0.03960802033543587} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0026864935643970966 [6/15]\n",
      "train metrics: <<< {'mse': 0.0026864935643970966, 'mae': 0.04165349155664444} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002273127669468522 [7/15]\n",
      "train metrics: <<< {'mse': 0.002273127669468522, 'mae': 0.0363621786236763} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002037059748545289 [8/15]\n",
      "train metrics: <<< {'mse': 0.002037059748545289, 'mae': 0.03792239725589752} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0030336263589560986 [9/15]\n",
      "train metrics: <<< {'mse': 0.0030336263589560986, 'mae': 0.045386191457509995} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.003759237937629223 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016772476956248283 [11/15]\n",
      "train metrics: <<< {'mse': 0.0016772476956248283, 'mae': 0.03152821958065033} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0034426995553076267 [12/15]\n",
      "train metrics: <<< {'mse': 0.0034426995553076267, 'mae': 0.04811912775039673} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002424691803753376 [13/15]\n",
      "train metrics: <<< {'mse': 0.002424691803753376, 'mae': 0.03912686929106712} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0013370441738516092 [14/15]\n",
      "train metrics: <<< {'mse': 0.0013370441738516092, 'mae': 0.029503541067242622} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0001985251292353496 [1/5]\n",
      "val metrics: {'mse': 0.0001985251292353496, 'mae': 0.011001970618963242}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002101623103953898 [2/5]\n",
      "val metrics: {'mse': 0.0002101623103953898, 'mae': 0.011953191831707954}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016953161684796214 [3/5]\n",
      "val metrics: {'mse': 0.00016953161684796214, 'mae': 0.009967360645532608}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0001394458522554487 [4/5]\n",
      "val metrics: {'mse': 0.0001394458522554487, 'mae': 0.009780718013644218}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00025066148373298347 [5/5]\n",
      "val metrics: {'mse': 0.00025066148373298347, 'mae': 0.011611688882112503}\n",
      "\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0027302787639200687 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002312155906111002 [1/15]\n",
      "train metrics: <<< {'mse': 0.002312155906111002, 'mae': 0.037268780171871185} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0024100085720419884 [2/15]\n",
      "train metrics: <<< {'mse': 0.0024100085720419884, 'mae': 0.03892984986305237} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0022247168235480785 [3/15]\n",
      "train metrics: <<< {'mse': 0.0022247168235480785, 'mae': 0.038177620619535446} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0017480190144851804 [4/15]\n",
      "train metrics: <<< {'mse': 0.0017480190144851804, 'mae': 0.033090777695178986} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0018212329596281052 [5/15]\n",
      "train metrics: <<< {'mse': 0.0018212329596281052, 'mae': 0.033726952970027924} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0026968331076204777 [6/15]\n",
      "train metrics: <<< {'mse': 0.0026968331076204777, 'mae': 0.04025565832853317} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002351371105760336 [7/15]\n",
      "train metrics: <<< {'mse': 0.002351371105760336, 'mae': 0.038312483578920364} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001952015794813633 [8/15]\n",
      "train metrics: <<< {'mse': 0.001952015794813633, 'mae': 0.03681085631251335} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002531285397708416 [9/15]\n",
      "train metrics: <<< {'mse': 0.002531285397708416, 'mae': 0.038875337690114975} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001878345850855112 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001472762320190668 [11/15]\n",
      "train metrics: <<< {'mse': 0.001472762320190668, 'mae': 0.029922470450401306} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002509854966774583 [12/15]\n",
      "train metrics: <<< {'mse': 0.002509854966774583, 'mae': 0.03948184847831726} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001673127873800695 [13/15]\n",
      "train metrics: <<< {'mse': 0.001673127873800695, 'mae': 0.03084520995616913} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0005130621721036732 [14/15]\n",
      "train metrics: <<< {'mse': 0.0005130621721036732, 'mae': 0.0172082781791687} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00013373214460443705 [1/5]\n",
      "val metrics: {'mse': 0.00013373214460443705, 'mae': 0.009016934782266617}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0001278252893825993 [2/5]\n",
      "val metrics: {'mse': 0.0001278252893825993, 'mae': 0.008390890434384346}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00017472774197813123 [3/5]\n",
      "val metrics: {'mse': 0.00017472774197813123, 'mae': 0.010366393253207207}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 9.24999185372144e-05 [4/5]\n",
      "val metrics: {'mse': 9.24999185372144e-05, 'mae': 0.007611508015543222}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00022042353521101177 [5/5]\n",
      "val metrics: {'mse': 0.00022042352065909654, 'mae': 0.011403292417526245}\n",
      "\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016609604936093092 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0011574970558285713 [1/15]\n",
      "train metrics: <<< {'mse': 0.0011574970558285713, 'mae': 0.0278693288564682} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001288068713620305 [2/15]\n",
      "train metrics: <<< {'mse': 0.001288068713620305, 'mae': 0.028659962117671967} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002079706871882081 [3/15]\n",
      "train metrics: <<< {'mse': 0.002079706871882081, 'mae': 0.036200378090143204} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013725939206779003 [4/15]\n",
      "train metrics: <<< {'mse': 0.0013725939206779003, 'mae': 0.030372241511940956} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0015955707058310509 [5/15]\n",
      "train metrics: <<< {'mse': 0.0015955707058310509, 'mae': 0.03260378539562225} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001980807399377227 [6/15]\n",
      "train metrics: <<< {'mse': 0.001980807399377227, 'mae': 0.03326902538537979} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002253190614283085 [7/15]\n",
      "train metrics: <<< {'mse': 0.002253190614283085, 'mae': 0.0382394939661026} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0019462737254798412 [8/15]\n",
      "train metrics: <<< {'mse': 0.0019462737254798412, 'mae': 0.034091271460056305} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014603965682908893 [9/15]\n",
      "train metrics: <<< {'mse': 0.0014603965682908893, 'mae': 0.030401157215237617} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001634702319279313 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0020059780217707157 [11/15]\n",
      "train metrics: <<< {'mse': 0.0020059780217707157, 'mae': 0.03709420561790466} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0015183568466454744 [12/15]\n",
      "train metrics: <<< {'mse': 0.0015183568466454744, 'mae': 0.03177492693066597} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014170529320836067 [13/15]\n",
      "train metrics: <<< {'mse': 0.0014170529320836067, 'mae': 0.030403027310967445} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0014770478010177612 [14/15]\n",
      "train metrics: <<< {'mse': 0.0014770478010177612, 'mae': 0.03770348057150841} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00014175761316437274 [1/5]\n",
      "val metrics: {'mse': 0.00014175761316437274, 'mae': 0.009114757180213928}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00012381035776343197 [2/5]\n",
      "val metrics: {'mse': 0.00012381035776343197, 'mae': 0.008062625303864479}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016402883920818567 [3/5]\n",
      "val metrics: {'mse': 0.00016402883920818567, 'mae': 0.01013926975429058}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 9.026879706652835e-05 [4/5]\n",
      "val metrics: {'mse': 9.026879706652835e-05, 'mae': 0.007708351127803326}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00022792693926021457 [5/5]\n",
      "val metrics: {'mse': 0.00022792693926021457, 'mae': 0.01128463540226221}\n",
      "\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012764774728566408 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014964852016419172 [1/15]\n",
      "train metrics: <<< {'mse': 0.0014964852016419172, 'mae': 0.030781548470258713} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0015257317572832108 [2/15]\n",
      "train metrics: <<< {'mse': 0.0015257317572832108, 'mae': 0.03135497123003006} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001420636661350727 [3/15]\n",
      "train metrics: <<< {'mse': 0.001420636661350727, 'mae': 0.030948756262660027} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001815475057810545 [4/15]\n",
      "train metrics: <<< {'mse': 0.001815475057810545, 'mae': 0.0348355695605278} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001691735815256834 [5/15]\n",
      "train metrics: <<< {'mse': 0.001691735815256834, 'mae': 0.03363409638404846} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.002188263460993767 [6/15]\n",
      "train metrics: <<< {'mse': 0.002188263460993767, 'mae': 0.03713320195674896} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0019588186405599117 [7/15]\n",
      "train metrics: <<< {'mse': 0.0019588186405599117, 'mae': 0.03507167845964432} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013201067922636867 [8/15]\n",
      "train metrics: <<< {'mse': 0.0013201067922636867, 'mae': 0.02896282449364662} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014029330341145396 [9/15]\n",
      "train metrics: <<< {'mse': 0.0014029330341145396, 'mae': 0.029356349259614944} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008605933981016278 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013184278504922986 [11/15]\n",
      "train metrics: <<< {'mse': 0.0013184278504922986, 'mae': 0.02771744504570961} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00129403593018651 [12/15]\n",
      "train metrics: <<< {'mse': 0.00129403593018651, 'mae': 0.029188673943281174} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0010888014221563935 [13/15]\n",
      "train metrics: <<< {'mse': 0.0010888014221563935, 'mae': 0.026647452265024185} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0010749248322099447 [14/15]\n",
      "train metrics: <<< {'mse': 0.0010749248322099447, 'mae': 0.024682506918907166} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006550612160935998 [1/5]\n",
      "val metrics: {'mse': 0.0006550612160935998, 'mae': 0.023775411769747734}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006284022238105536 [2/5]\n",
      "val metrics: {'mse': 0.0006284022238105536, 'mae': 0.023356445133686066}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0007603869307786226 [3/5]\n",
      "val metrics: {'mse': 0.0007603869307786226, 'mae': 0.025277238339185715}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0006315006758086383 [4/5]\n",
      "val metrics: {'mse': 0.0006315006758086383, 'mae': 0.02369595319032669}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0007792027317918837 [5/5]\n",
      "val metrics: {'mse': 0.0007792027317918837, 'mae': 0.025367015972733498}\n",
      "\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.00168348359875381 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016476456075906754 [1/15]\n",
      "train metrics: <<< {'mse': 0.0016476456075906754, 'mae': 0.03373664617538452} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012214245507493615 [2/15]\n",
      "train metrics: <<< {'mse': 0.0012214245507493615, 'mae': 0.029474716633558273} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016407447401434183 [3/15]\n",
      "train metrics: <<< {'mse': 0.0016407447401434183, 'mae': 0.032510146498680115} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013063752558082342 [4/15]\n",
      "train metrics: <<< {'mse': 0.0013063752558082342, 'mae': 0.02889721654355526} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012929291697219014 [5/15]\n",
      "train metrics: <<< {'mse': 0.0012929291697219014, 'mae': 0.028970766812562943} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014352869475260377 [6/15]\n",
      "train metrics: <<< {'mse': 0.0014352869475260377, 'mae': 0.031817726790905} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0019033077405765653 [7/15]\n",
      "train metrics: <<< {'mse': 0.0019033077405765653, 'mae': 0.03543463349342346} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0019008626695722342 [8/15]\n",
      "train metrics: <<< {'mse': 0.0019008626695722342, 'mae': 0.035808417946100235} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0011084959842264652 [9/15]\n",
      "train metrics: <<< {'mse': 0.0011084959842264652, 'mae': 0.02700633928179741} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001090566860511899 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013250207994133234 [11/15]\n",
      "train metrics: <<< {'mse': 0.0013250207994133234, 'mae': 0.029456932097673416} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016375374980270863 [12/15]\n",
      "train metrics: <<< {'mse': 0.0016375374980270863, 'mae': 0.03152695298194885} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012463238090276718 [13/15]\n",
      "train metrics: <<< {'mse': 0.0012463238090276718, 'mae': 0.02881685644388199} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0009598147589713335 [14/15]\n",
      "train metrics: <<< {'mse': 0.0009598147589713335, 'mae': 0.02874535322189331} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00017885779379867017 [1/5]\n",
      "val metrics: {'mse': 0.00017885779379867017, 'mae': 0.01007654145359993}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00016891570703592151 [2/5]\n",
      "val metrics: {'mse': 0.00016891570703592151, 'mae': 0.010551095008850098}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.000150462263263762 [3/5]\n",
      "val metrics: {'mse': 0.000150462263263762, 'mae': 0.009227674454450607}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00011237714352319017 [4/5]\n",
      "val metrics: {'mse': 0.00011237714352319017, 'mae': 0.008587295189499855}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00023678534489590675 [5/5]\n",
      "val metrics: {'mse': 0.00023678533034399152, 'mae': 0.010797574184834957}\n",
      "\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008031726465560496 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0011285843793302774 [1/15]\n",
      "train metrics: <<< {'mse': 0.0011285843793302774, 'mae': 0.027296032756567} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001076889573596418 [2/15]\n",
      "train metrics: <<< {'mse': 0.001076889573596418, 'mae': 0.025395400822162628} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013502168003469706 [3/15]\n",
      "train metrics: <<< {'mse': 0.0013502168003469706, 'mae': 0.030358359217643738} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012350459583103657 [4/15]\n",
      "train metrics: <<< {'mse': 0.0012350459583103657, 'mae': 0.029645651578903198} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0010376981226727366 [5/15]\n",
      "train metrics: <<< {'mse': 0.0010376981226727366, 'mae': 0.024595100432634354} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0011801380896940827 [6/15]\n",
      "train metrics: <<< {'mse': 0.0011801380896940827, 'mae': 0.026438718661665916} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0016431516269221902 [7/15]\n",
      "train metrics: <<< {'mse': 0.0016431516269221902, 'mae': 0.03182297945022583} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012762024998664856 [8/15]\n",
      "train metrics: <<< {'mse': 0.0012762024998664856, 'mae': 0.02984045445919037} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0006864003371447325 [9/15]\n",
      "train metrics: <<< {'mse': 0.0006864003371447325, 'mae': 0.02144707925617695} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0009730393649078906 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012990215327590704 [11/15]\n",
      "train metrics: <<< {'mse': 0.0012990215327590704, 'mae': 0.027905547991394997} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0015489405486732721 [12/15]\n",
      "train metrics: <<< {'mse': 0.0015489405486732721, 'mae': 0.031679667532444} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0009322297992184758 [13/15]\n",
      "train metrics: <<< {'mse': 0.0009322297992184758, 'mae': 0.02573014236986637} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0004590030002873391 [14/15]\n",
      "train metrics: <<< {'mse': 0.0004590030002873391, 'mae': 0.021293897181749344} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002795590553432703 [1/5]\n",
      "val metrics: {'mse': 0.0002795590553432703, 'mae': 0.014633248560130596}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002642855397425592 [2/5]\n",
      "val metrics: {'mse': 0.0002642855397425592, 'mae': 0.013561045750975609}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003656548506114632 [3/5]\n",
      "val metrics: {'mse': 0.0003656548506114632, 'mae': 0.016802046447992325}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00025128189008682966 [4/5]\n",
      "val metrics: {'mse': 0.00025128189008682966, 'mae': 0.013592557050287724}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0003848196065519005 [5/5]\n",
      "val metrics: {'mse': 0.0003848196065519005, 'mae': 0.016658829525113106}\n",
      "\n",
      ".................... End of epoch 19 ....................\n",
      "Epoch: <<< 20 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008022459223866463 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0005771432188339531 [1/15]\n",
      "train metrics: <<< {'mse': 0.0005771432188339531, 'mae': 0.020348433405160904} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0010266153840348125 [2/15]\n",
      "train metrics: <<< {'mse': 0.0010266153840348125, 'mae': 0.026932407170534134} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008245989447459579 [3/15]\n",
      "train metrics: <<< {'mse': 0.0008245989447459579, 'mae': 0.023530740290880203} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0009941307362169027 [4/15]\n",
      "train metrics: <<< {'mse': 0.0009941307362169027, 'mae': 0.02463037148118019} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0006446863408200443 [5/15]\n",
      "train metrics: <<< {'mse': 0.0006446863408200443, 'mae': 0.02017318457365036} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008843260002322495 [6/15]\n",
      "train metrics: <<< {'mse': 0.0008843260002322495, 'mae': 0.024541793391108513} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0012950198724865913 [7/15]\n",
      "train metrics: <<< {'mse': 0.0012950198724865913, 'mae': 0.028274403885006905} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001506848493590951 [8/15]\n",
      "train metrics: <<< {'mse': 0.001506848493590951, 'mae': 0.030722081661224365} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008750862907618284 [9/15]\n",
      "train metrics: <<< {'mse': 0.0008750862907618284, 'mae': 0.023320108652114868} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0007815583376213908 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001268566120415926 [11/15]\n",
      "train metrics: <<< {'mse': 0.001268566120415926, 'mae': 0.02882442995905876} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014487321022897959 [12/15]\n",
      "train metrics: <<< {'mse': 0.0014487321022897959, 'mae': 0.03157518431544304} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0007389999809674919 [13/15]\n",
      "train metrics: <<< {'mse': 0.0007389999809674919, 'mae': 0.020858395844697952} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.0010424550855532289 [14/15]\n",
      "train metrics: <<< {'mse': 0.0010424550855532289, 'mae': 0.029550105333328247} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0005597782437689602 [1/5]\n",
      "val metrics: {'mse': 0.0005597782437689602, 'mae': 0.021271347999572754}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0005684094503521919 [2/5]\n",
      "val metrics: {'mse': 0.0005684094503521919, 'mae': 0.02154109999537468}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0004632947966456413 [3/5]\n",
      "val metrics: {'mse': 0.0004632947966456413, 'mae': 0.0189635269343853}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.000477319466881454 [4/5]\n",
      "val metrics: {'mse': 0.000477319466881454, 'mae': 0.020354904234409332}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.0005853026523254812 [5/5]\n",
      "val metrics: {'mse': 0.0005853026523254812, 'mae': 0.02047082781791687}\n",
      "\n",
      ".................... End of epoch 20 ....................\n",
      "Epoch: <<< 21 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0013307755580171943 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001397836022078991 [1/15]\n",
      "train metrics: <<< {'mse': 0.001397836022078991, 'mae': 0.03092889115214348} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0010757828131318092 [2/15]\n",
      "train metrics: <<< {'mse': 0.0010757828131318092, 'mae': 0.025954265147447586} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008045873255468905 [3/15]\n",
      "train metrics: <<< {'mse': 0.0008045873255468905, 'mae': 0.02260889671742916} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0006112064002081752 [4/15]\n",
      "train metrics: <<< {'mse': 0.0006112064002081752, 'mae': 0.020659983158111572} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0009181241039186716 [5/15]\n",
      "train metrics: <<< {'mse': 0.0009181241039186716, 'mae': 0.024851413443684578} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0017513666534796357 [6/15]\n",
      "train metrics: <<< {'mse': 0.0017513666534796357, 'mae': 0.03457149863243103} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0022379879374057055 [7/15]\n",
      "train metrics: <<< {'mse': 0.0022379879374057055, 'mae': 0.040262430906295776} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0009452766971662641 [8/15]\n",
      "train metrics: <<< {'mse': 0.0009452766971662641, 'mae': 0.02570313960313797} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0007820039754733443 [9/15]\n",
      "train metrics: <<< {'mse': 0.0007820039754733443, 'mae': 0.02301642671227455} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0014233116526156664 [10/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.001356347929686308 [11/15]\n",
      "train metrics: <<< {'mse': 0.001356347929686308, 'mae': 0.029902171343564987} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0010030795820057392 [12/15]\n",
      "train metrics: <<< {'mse': 0.0010030795820057392, 'mae': 0.022230416536331177} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008550839847885072 [13/15]\n",
      "train metrics: <<< {'mse': 0.0008550839847885072, 'mae': 0.023051783442497253} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([4, 1])\n",
      "x_cat after embedding to hidden: torch.Size([4, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([4, 4, 500])\n",
      "Train-Loss: 0.001801593927666545 [14/15]\n",
      "train metrics: <<< {'mse': 0.001801593927666545, 'mae': 0.035902880132198334} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002562789886724204 [1/5]\n",
      "val metrics: {'mse': 0.0002562789886724204, 'mae': 0.013849563896656036}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0002389964647591114 [2/5]\n",
      "val metrics: {'mse': 0.0002389964647591114, 'mae': 0.01268102414906025}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.0003253947361372411 [3/5]\n",
      "val metrics: {'mse': 0.0003253947361372411, 'mae': 0.015793191269040108}\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Val-Loss: 0.00022230608738027513 [4/5]\n",
      "val metrics: {'mse': 0.00022230608738027513, 'mae': 0.012673143297433853}\n",
      "x.shape after fft.rfft2: torch.Size([44, 1])\n",
      "x_cat after embedding to hidden: torch.Size([44, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([44, 4, 500])\n",
      "Val-Loss: 0.00036036266828887165 [5/5]\n",
      "val metrics: {'mse': 0.00036036266828887165, 'mae': 0.015848441049456596}\n",
      "\n",
      ".................... End of epoch 21 ....................\n",
      "Epoch: <<< 22 >>>\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0005121540161781013 [0/15]\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0008483259007334709 [1/15]\n",
      "train metrics: <<< {'mse': 0.0008483259007334709, 'mae': 0.023911967873573303} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0007890956476330757 [2/15]\n",
      "train metrics: <<< {'mse': 0.0007890956476330757, 'mae': 0.021543681621551514} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n",
      "x_cat after embedding to hidden: torch.Size([64, 4, 500])\n",
      "x_cat after embedding plus relu: torch.Size([64, 4, 500])\n",
      "Train-Loss: 0.0005708189564757049 [3/15]\n",
      "train metrics: <<< {'mse': 0.0005708189564757049, 'mae': 0.020133480429649353} >>>\n",
      "\n",
      "x.shape after fft.rfft2: torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "import torch\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "batch_size = 64\n",
    "train_dataloader = get_loader(x=xtrain, y=ytrain, batch_size=batch_size, x_cat=df_train_cat.to_numpy())\n",
    "val_dataloader = get_loader(x=xval, y=yval, batch_size=batch_size, x_cat=df_val_cat.to_numpy())\n",
    "\n",
    "\n",
    "CAT_FEATURES = cat.shape[1]\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 10\n",
    "NO_EMBEDDING = 2 * len(df_train_cat)\n",
    "print('NO_EMBEDDING:', NO_EMBEDDING)\n",
    "\n",
    "# cat_features = cat_features * embedding_dim\n",
    "# print('in_features:', xtrain.shape[1] + cat_features)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=xtrain.shape[1], \n",
    "    units=500,\n",
    "    out_features=1, \n",
    "    categorical_dim=CAT_FEATURES,\n",
    "    no_embedding=NO_EMBEDDING, \n",
    "    emb_dim=EMBEDDING_DIM\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "trainer = Trainer(model, lr=3.3e-6)\n",
    "trainer.fit_epochs(\n",
    "    train_dataloader, \n",
    "    val_dataloader, \n",
    "    use_cyclic_lr=True, \n",
    "    x_cat=True, \n",
    "    epochs=25\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
