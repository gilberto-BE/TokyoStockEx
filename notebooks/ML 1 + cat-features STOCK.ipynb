{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split\n",
    ")\n",
    "from metrics import calc_spread_return_sharpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain.shape: (900, 1)\n",
      "[[-0.00145879]\n",
      " [ 0.00073046]\n",
      " [ 0.00291971]\n",
      " [-0.0010917 ]\n",
      " [-0.00510018]]\n",
      "\n",
      "ytrain.shape: (901, 1)\n",
      "[[ 0.00073046]\n",
      " [ 0.00291971]\n",
      " [-0.0010917 ]\n",
      " [-0.00510018]\n",
      " [-0.0032955 ]]\n",
      "df_train_cat.shape: (901, 3)\n",
      "            day_of_year  month  day_of_week\n",
      "Date                                       \n",
      "2017-01-04            4      1            4\n",
      "2017-01-05            5      1            5\n",
      "2017-01-06            6      1            6\n",
      "2017-01-10           10      1           10\n",
      "2017-01-11           11      1           11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' xtrain and df_train_cat have different shapes!!!!!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = 'c:/Users/gilbe/Documents/TokyoData'\n",
    "\n",
    "\n",
    "'/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv'\n",
    "'/train_files/trades.csv'\n",
    "\n",
    "train_df = pd.read_csv(f'{ROOT_PATH}/train_files/stock_prices.csv')\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date']) \n",
    "train_df.set_index('Date', inplace=True)\n",
    "# train_df = date_features(train_df)\n",
    "\n",
    "train_options = pd.read_csv(f'{ROOT_PATH}/train_files/options.csv', low_memory=False)\n",
    "train_financials = pd.read_csv(f'{ROOT_PATH}/train_files/financials.csv', low_memory=False)\n",
    "train_trades = pd.read_csv(f'{ROOT_PATH}/train_files/trades.csv', low_memory=False)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_1301 = train_df[train_df['SecuritiesCode'] == 1301].drop(['SecuritiesCode', 'Volume'], axis=1)\n",
    "\n",
    "df_1301 = date_features(df_1301)\n",
    "\n",
    "cont, cat = cont_cat_split(df_1301, 'int64')\n",
    "df_train_cat, df_val_cat = ts_split(cat)\n",
    "df_train, df_val = ts_split(cont)\n",
    "\n",
    "\n",
    "xtrain, ytrain = preprocess(df_train, 'Target', 1, continous_cols=['Close'])\n",
    "xval, yval = preprocess(df_val, 'Target', 1, continous_cols=['Close'])\n",
    "\n",
    "\n",
    "print('xtrain.shape:', xtrain.shape)\n",
    "print(xtrain[:5])\n",
    "print()\n",
    "print('ytrain.shape:', ytrain.shape)\n",
    "print(ytrain[:5])\n",
    "print('df_train_cat.shape:', df_train_cat.shape)\n",
    "print(df_train_cat.head())\n",
    "\n",
    "\"\"\" xtrain and df_train_cat have different shapes!!!!!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (embedding): Embedding(901, 10)\n",
      "  (embedding_to_hidden): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (embedding_output): Linear(in_features=2000, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=1, out_features=2000, bias=True)\n",
      "  (hidden_layer): Linear(in_features=2003, out_features=2003, bias=True)\n",
      "  (output_layer): Linear(in_features=2003, out_features=1, bias=True)\n",
      ")\n",
      "Using cpu-device\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:145: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:219.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Loss: 0.12390990555286407 [0/2]\n",
      "Train-Loss: 0.11511686444282532 [1/2]\n",
      "Val-Loss: 5.67128849029541 [1/1]\n",
      "Epoch: <<< 1 >>>\n",
      "Train-Loss: 5.667186260223389 [0/2]\n",
      "Train-Loss: 5.659433364868164 [1/2]\n",
      "Val-Loss: 0.6146745085716248 [1/1]\n",
      "Epoch: <<< 2 >>>\n",
      "Train-Loss: 0.6143888831138611 [0/2]\n",
      "Train-Loss: 0.5961077809333801 [1/2]\n",
      "Val-Loss: 1.3256756067276 [1/1]\n",
      "Epoch: <<< 3 >>>\n",
      "Train-Loss: 1.324882984161377 [0/2]\n",
      "Train-Loss: 1.3348729610443115 [1/2]\n",
      "Val-Loss: 1.1178869009017944 [1/1]\n",
      "Epoch: <<< 4 >>>\n",
      "Train-Loss: 1.1180245876312256 [0/2]\n",
      "Train-Loss: 1.1097993850708008 [1/2]\n",
      "Val-Loss: 0.0019656969234347343 [1/1]\n",
      "Epoch: <<< 5 >>>\n",
      "Train-Loss: 0.0020069479942321777 [0/2]\n",
      "Train-Loss: 0.0023781524505466223 [1/2]\n",
      "Val-Loss: 0.5268969535827637 [1/1]\n",
      "Epoch: <<< 6 >>>\n",
      "Train-Loss: 0.5262146592140198 [0/2]\n",
      "Train-Loss: 0.5260140895843506 [1/2]\n",
      "Val-Loss: 0.1606930047273636 [1/1]\n",
      "Epoch: <<< 7 >>>\n",
      "Train-Loss: 0.16054362058639526 [0/2]\n",
      "Train-Loss: 0.15724386274814606 [1/2]\n",
      "Val-Loss: 0.15667180716991425 [1/1]\n",
      "Epoch: <<< 8 >>>\n",
      "Train-Loss: 0.1567094624042511 [0/2]\n",
      "Train-Loss: 0.15923559665679932 [1/2]\n",
      "Val-Loss: 0.31513288617134094 [1/1]\n",
      "Epoch: <<< 9 >>>\n",
      "Train-Loss: 0.3151216506958008 [0/2]\n",
      "Train-Loss: 0.3141306936740875 [1/2]\n",
      "Val-Loss: 0.0022139574866741896 [1/1]\n",
      "Epoch: <<< 10 >>>\n",
      "Train-Loss: 0.0022943506482988596 [0/2]\n",
      "Train-Loss: 0.002055238001048565 [1/2]\n",
      "Val-Loss: 0.21042032539844513 [1/1]\n",
      "Epoch: <<< 11 >>>\n",
      "Train-Loss: 0.2100679576396942 [0/2]\n",
      "Train-Loss: 0.21026748418807983 [1/2]\n",
      "Val-Loss: 0.11200490593910217 [1/1]\n",
      "Epoch: <<< 12 >>>\n",
      "Train-Loss: 0.1118156686425209 [0/2]\n",
      "Train-Loss: 0.11013849079608917 [1/2]\n",
      "Val-Loss: 0.01737229898571968 [1/1]\n",
      "Epoch: <<< 13 >>>\n",
      "Train-Loss: 0.017473842948675156 [0/2]\n",
      "Train-Loss: 0.01811782829463482 [1/2]\n",
      "Val-Loss: 0.12829960882663727 [1/1]\n",
      "Epoch: <<< 14 >>>\n",
      "Train-Loss: 0.12843264639377594 [0/2]\n",
      "Train-Loss: 0.1287020891904831 [1/2]\n",
      "Val-Loss: 0.03118019364774227 [1/1]\n",
      "Epoch: <<< 15 >>>\n",
      "Train-Loss: 0.03129717707633972 [0/2]\n",
      "Train-Loss: 0.03090083971619606 [1/2]\n",
      "Val-Loss: 0.019018052145838737 [1/1]\n",
      "Epoch: <<< 16 >>>\n",
      "Train-Loss: 0.018988803029060364 [0/2]\n",
      "Train-Loss: 0.019165491685271263 [1/2]\n",
      "Val-Loss: 0.0625397339463234 [1/1]\n",
      "Epoch: <<< 17 >>>\n",
      "Train-Loss: 0.06242680549621582 [0/2]\n",
      "Train-Loss: 0.062062837183475494 [1/2]\n",
      "Val-Loss: 0.012710237875580788 [1/1]\n",
      "Epoch: <<< 18 >>>\n",
      "Train-Loss: 0.012704695574939251 [0/2]\n",
      "Train-Loss: 0.01234458852559328 [1/2]\n",
      "Val-Loss: 0.011236244812607765 [1/1]\n",
      "Epoch: <<< 19 >>>\n",
      "Train-Loss: 0.011320347897708416 [0/2]\n",
      "Train-Loss: 0.011570071801543236 [1/2]\n",
      "Val-Loss: 0.029596814885735512 [1/1]\n",
      "Epoch: <<< 20 >>>\n",
      "Train-Loss: 0.02969738468527794 [0/2]\n",
      "Train-Loss: 0.0297640822827816 [1/2]\n",
      "Val-Loss: 0.004746716003865004 [1/1]\n",
      "Epoch: <<< 21 >>>\n",
      "Train-Loss: 0.0048294877633452415 [0/2]\n",
      "Train-Loss: 0.004778396338224411 [1/2]\n",
      "Val-Loss: 0.00495584961026907 [1/1]\n",
      "Epoch: <<< 22 >>>\n",
      "Train-Loss: 0.0049789706245064735 [0/2]\n",
      "Train-Loss: 0.004969603847712278 [1/2]\n",
      "Val-Loss: 0.013890757225453854 [1/1]\n",
      "Epoch: <<< 23 >>>\n",
      "Train-Loss: 0.013887569308280945 [0/2]\n",
      "Train-Loss: 0.013736728578805923 [1/2]\n",
      "Val-Loss: 0.00303508248180151 [1/1]\n",
      "Epoch: <<< 24 >>>\n",
      "Train-Loss: 0.0030677802860736847 [0/2]\n",
      "Train-Loss: 0.0029498750809580088 [1/2]\n",
      "Val-Loss: 0.002004365436732769 [1/1]\n",
      "Epoch: <<< 25 >>>\n",
      "Train-Loss: 0.002077862387523055 [0/2]\n",
      "Train-Loss: 0.0021369934547692537 [1/2]\n",
      "Val-Loss: 0.00708294240757823 [1/1]\n",
      "Epoch: <<< 26 >>>\n",
      "Train-Loss: 0.0071668606251478195 [0/2]\n",
      "Train-Loss: 0.007223288528621197 [1/2]\n",
      "Val-Loss: 0.0020374057348817587 [1/1]\n",
      "Epoch: <<< 27 >>>\n",
      "Train-Loss: 0.002110507572069764 [0/2]\n",
      "Train-Loss: 0.0021059068385511637 [1/2]\n",
      "Val-Loss: 0.0008355560130439699 [1/1]\n",
      "Epoch: <<< 28 >>>\n",
      "Train-Loss: 0.0008830362930893898 [0/2]\n",
      "Train-Loss: 0.0008589041535742581 [1/2]\n",
      "Val-Loss: 0.0037629110738635063 [1/1]\n",
      "Epoch: <<< 29 >>>\n",
      "Train-Loss: 0.003795821452513337 [0/2]\n",
      "Train-Loss: 0.003725014626979828 [1/2]\n",
      "Val-Loss: 0.0014199153520166874 [1/1]\n",
      "Epoch: <<< 30 >>>\n",
      "Train-Loss: 0.0014640006702393293 [0/2]\n",
      "Train-Loss: 0.0013996704947203398 [1/2]\n",
      "Val-Loss: 0.00036117862327955663 [1/1]\n",
      "Epoch: <<< 31 >>>\n",
      "Train-Loss: 0.000423332181526348 [0/2]\n",
      "Train-Loss: 0.0004294246609788388 [1/2]\n",
      "Val-Loss: 0.0019227095181122422 [1/1]\n",
      "Epoch: <<< 32 >>>\n",
      "Train-Loss: 0.001991762313991785 [0/2]\n",
      "Train-Loss: 0.00201787194237113 [1/2]\n",
      "Val-Loss: 0.0008655295823700726 [1/1]\n",
      "Epoch: <<< 33 >>>\n",
      "Train-Loss: 0.0009302777471020818 [0/2]\n",
      "Train-Loss: 0.0009318114607594907 [1/2]\n",
      "Val-Loss: 0.00023782506468705833 [1/1]\n",
      "Epoch: <<< 34 >>>\n",
      "Train-Loss: 0.0002917797537520528 [0/2]\n",
      "Train-Loss: 0.00027187028899788857 [1/2]\n",
      "Val-Loss: 0.0010994132608175278 [1/1]\n",
      "Epoch: <<< 35 >>>\n",
      "Train-Loss: 0.0011463311966508627 [0/2]\n",
      "Train-Loss: 0.0011051459005102515 [1/2]\n",
      "Val-Loss: 0.0005687042721547186 [1/1]\n",
      "Epoch: <<< 36 >>>\n",
      "Train-Loss: 0.0006191825959831476 [0/2]\n",
      "Train-Loss: 0.0005818040808662772 [1/2]\n",
      "Val-Loss: 0.00018066365737468004 [1/1]\n",
      "Epoch: <<< 37 >>>\n",
      "Train-Loss: 0.0002390568988630548 [0/2]\n",
      "Train-Loss: 0.00023235789558384567 [1/2]\n",
      "Val-Loss: 0.0006166520761325955 [1/1]\n",
      "Epoch: <<< 38 >>>\n",
      "Train-Loss: 0.0006788414320908487 [0/2]\n",
      "Train-Loss: 0.0006851413636468351 [1/2]\n",
      "Val-Loss: 0.00033984979381784797 [1/1]\n",
      "Epoch: <<< 39 >>>\n",
      "Train-Loss: 0.00040010170778259635 [0/2]\n",
      "Train-Loss: 0.0003963399794884026 [1/2]\n",
      "Val-Loss: 0.00017502503760624677 [1/1]\n",
      "Epoch: <<< 40 >>>\n",
      "Train-Loss: 0.00023017886269371957 [0/2]\n",
      "Train-Loss: 0.00021242958609946072 [1/2]\n",
      "Val-Loss: 0.0004182053089607507 [1/1]\n",
      "Epoch: <<< 41 >>>\n",
      "Train-Loss: 0.0004703219747170806 [0/2]\n",
      "Train-Loss: 0.0004422371566761285 [1/2]\n",
      "Val-Loss: 0.0002439858508296311 [1/1]\n",
      "Epoch: <<< 42 >>>\n",
      "Train-Loss: 0.0002980284334626049 [0/2]\n",
      "Train-Loss: 0.0002743651857599616 [1/2]\n",
      "Val-Loss: 0.00016296513786073774 [1/1]\n",
      "Epoch: <<< 43 >>>\n",
      "Train-Loss: 0.00022078842448536307 [0/2]\n",
      "Train-Loss: 0.00021183080389164388 [1/2]\n",
      "Val-Loss: 0.0002770785358734429 [1/1]\n",
      "Epoch: <<< 44 >>>\n",
      "Train-Loss: 0.0003365171723999083 [0/2]\n",
      "Train-Loss: 0.00033303830423392355 [1/2]\n",
      "Val-Loss: 0.0001744089531712234 [1/1]\n",
      "Epoch: <<< 45 >>>\n",
      "Train-Loss: 0.00023249119112733752 [0/2]\n",
      "Train-Loss: 0.0002232884435215965 [1/2]\n",
      "Val-Loss: 0.00016755401156842709 [1/1]\n",
      "Epoch: <<< 46 >>>\n",
      "Train-Loss: 0.00022309496125672013 [0/2]\n",
      "Train-Loss: 0.00020569287880789489 [1/2]\n",
      "Val-Loss: 0.00022389226069208235 [1/1]\n",
      "Epoch: <<< 47 >>>\n",
      "Train-Loss: 0.0002784731623250991 [0/2]\n",
      "Train-Loss: 0.0002571860095486045 [1/2]\n",
      "Val-Loss: 0.00015412639186251909 [1/1]\n",
      "Epoch: <<< 48 >>>\n",
      "Train-Loss: 0.0002100628480548039 [0/2]\n",
      "Train-Loss: 0.00019345953478477895 [1/2]\n",
      "Val-Loss: 0.00015890247595962137 [1/1]\n",
      "Epoch: <<< 49 >>>\n",
      "Train-Loss: 0.00021655271120835096 [0/2]\n",
      "Train-Loss: 0.00020701672474388033 [1/2]\n",
      "Val-Loss: 0.0001749799121171236 [1/1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "batch_size = 512\n",
    "train_dataloader = get_loader(x=xtrain, y=ytrain, batch_size=batch_size, x_cat=df_train_cat.to_numpy())\n",
    "val_dataloader = get_loader(x=xval, y=yval, batch_size=batch_size, x_cat=df_val_cat.to_numpy())\n",
    "\n",
    "\n",
    "cat_features = 3 \n",
    "embedding_dim = 10\n",
    "# cat_features = cat_features * embedding_dim\n",
    "# print('in_features:', xtrain.shape[1] + cat_features)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=xtrain.shape[1], \n",
    "    units=2000,\n",
    "    out_features=1, \n",
    "    categorical_dim=cat_features,\n",
    "    no_embedding=len(df_train_cat), \n",
    "    emb_dim=embedding_dim\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "trainer = Trainer(model, lr=3e-7)\n",
    "trainer.fit_epochs(train_dataloader, val_dataloader, use_cyclic_lr=True, x_cat=True, epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
