{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtrain.shape: (900, 1)\n",
      "[[-0.00145879]\n",
      " [ 0.00073046]\n",
      " [ 0.00291971]\n",
      " [-0.0010917 ]\n",
      " [-0.00510018]]\n",
      "\n",
      "ytrain.shape: (901, 1)\n",
      "df_train_cat.shape: (901, 3)\n",
      "            day_of_year  month  day_of_week\n",
      "Date                                       \n",
      "2017-01-04            4      1            4\n",
      "2017-01-05            5      1            5\n",
      "2017-01-06            6      1            6\n",
      "2017-01-10           10      1           10\n",
      "2017-01-11           11      1           11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' xtrain and df_train_cat have different shapes!!!!!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_PATH = 'c:/Users/gilbe/Documents/TokyoData'\n",
    "\n",
    "\n",
    "'/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv'\n",
    "'/train_files/trades.csv'\n",
    "\n",
    "train_df = pd.read_csv(f'{ROOT_PATH}/train_files/stock_prices.csv')\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date']) \n",
    "train_df.set_index('Date', inplace=True)\n",
    "# train_df = date_features(train_df)\n",
    "\n",
    "train_options = pd.read_csv(f'{ROOT_PATH}/train_files/options.csv', low_memory=False)\n",
    "train_financials = pd.read_csv(f'{ROOT_PATH}/train_files/financials.csv', low_memory=False)\n",
    "train_trades = pd.read_csv(f'{ROOT_PATH}/train_files/trades.csv', low_memory=False)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_1301 = train_df[train_df['SecuritiesCode'] == 1301].drop(['SecuritiesCode', 'Volume'], axis=1)\n",
    "\n",
    "df_1301 = date_features(df_1301)\n",
    "\n",
    "cont, cat = cont_cat_split(df_1301, 'int64')\n",
    "df_train_cat, df_val_cat = ts_split(cat)\n",
    "df_train, df_val = ts_split(cont)\n",
    "\n",
    "\n",
    "xtrain, ytrain = preprocess(df_train, 'Target', 1, continous_cols=['Close'])\n",
    "xval, yval = preprocess(df_val, 'Target', 1, continous_cols=['Close'])\n",
    "\n",
    "\n",
    "print('xtrain.shape:', xtrain.shape)\n",
    "print(xtrain[:5])\n",
    "print()\n",
    "print('ytrain.shape:', ytrain.shape)\n",
    "print(ytrain[:5]\n",
    "print('df_train_cat.shape:', df_train_cat.shape)\n",
    "print(df_train_cat.head())\n",
    "\n",
    "\"\"\" xtrain and df_train_cat have different shapes!!!!!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (embedding): Embedding(901, 10)\n",
      "  (emb_input): Linear(in_features=10, out_features=2000, bias=True)\n",
      "  (emb_output): Linear(in_features=2000, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=1, out_features=2000, bias=True)\n",
      "  (hidden_layer): Linear(in_features=2003, out_features=2003, bias=True)\n",
      "  (output_layer): Linear(in_features=2003, out_features=1, bias=True)\n",
      ")\n",
      "Using cpu-device\n",
      "Epoch: <<< 0 >>>\n",
      "Train-Loss: 0.001410624710842967 [0/2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:145: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  ..\\aten\\src\\ATen\\native\\Copy.cpp:219.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train-Loss: 0.0004964582622051239 [1/2]\n",
      "Val-Loss: 9.502199172973633 [1/1]\n",
      "Epoch: <<< 1 >>>\n",
      "Train-Loss: 9.50171184539795 [0/2]\n",
      "Train-Loss: 9.515542984008789 [1/2]\n",
      "Val-Loss: 4.173070907592773 [1/1]\n",
      "Epoch: <<< 2 >>>\n",
      "Train-Loss: 4.171909332275391 [0/2]\n",
      "Train-Loss: 4.126032829284668 [1/2]\n",
      "Val-Loss: 0.10173272341489792 [1/1]\n",
      "Epoch: <<< 3 >>>\n",
      "Train-Loss: 0.10225516557693481 [0/2]\n",
      "Train-Loss: 0.10854484140872955 [1/2]\n",
      "Val-Loss: 1.2115488052368164 [1/1]\n",
      "Epoch: <<< 4 >>>\n",
      "Train-Loss: 1.2131855487823486 [0/2]\n",
      "Train-Loss: 1.2163621187210083 [1/2]\n",
      "Val-Loss: 0.6355776786804199 [1/1]\n",
      "Epoch: <<< 5 >>>\n",
      "Train-Loss: 0.6365172266960144 [0/2]\n",
      "Train-Loss: 0.6316795945167542 [1/2]\n",
      "Val-Loss: 0.006435192655771971 [1/1]\n",
      "Epoch: <<< 6 >>>\n",
      "Train-Loss: 0.0064803361892700195 [0/2]\n",
      "Train-Loss: 0.007263641804456711 [1/2]\n",
      "Val-Loss: 0.4949086010456085 [1/1]\n",
      "Epoch: <<< 7 >>>\n",
      "Train-Loss: 0.4950636327266693 [0/2]\n",
      "Train-Loss: 0.49819087982177734 [1/2]\n",
      "Val-Loss: 0.4497569799423218 [1/1]\n",
      "Epoch: <<< 8 >>>\n",
      "Train-Loss: 0.44926440715789795 [0/2]\n",
      "Train-Loss: 0.4474680721759796 [1/2]\n",
      "Val-Loss: 0.05484907701611519 [1/1]\n",
      "Epoch: <<< 9 >>>\n",
      "Train-Loss: 0.05476890504360199 [0/2]\n",
      "Train-Loss: 0.053269848227500916 [1/2]\n",
      "Val-Loss: 0.12483006715774536 [1/1]\n",
      "Epoch: <<< 10 >>>\n",
      "Train-Loss: 0.12502682209014893 [0/2]\n",
      "Train-Loss: 0.12706314027309418 [1/2]\n",
      "Val-Loss: 0.3290883004665375 [1/1]\n",
      "Epoch: <<< 11 >>>\n",
      "Train-Loss: 0.32932305335998535 [0/2]\n",
      "Train-Loss: 0.3296167850494385 [1/2]\n",
      "Val-Loss: 0.10722119361162186 [1/1]\n",
      "Epoch: <<< 12 >>>\n",
      "Train-Loss: 0.10739260911941528 [0/2]\n",
      "Train-Loss: 0.10629865527153015 [1/2]\n",
      "Val-Loss: 0.012481050565838814 [1/1]\n",
      "Epoch: <<< 13 >>>\n",
      "Train-Loss: 0.012480863370001316 [0/2]\n",
      "Train-Loss: 0.012879390269517899 [1/2]\n",
      "Val-Loss: 0.155246764421463 [1/1]\n",
      "Epoch: <<< 14 >>>\n",
      "Train-Loss: 0.1550138145685196 [0/2]\n",
      "Train-Loss: 0.15526898205280304 [1/2]\n",
      "Val-Loss: 0.11301979422569275 [1/1]\n",
      "Epoch: <<< 15 >>>\n",
      "Train-Loss: 0.11283427476882935 [0/2]\n",
      "Train-Loss: 0.11187256127595901 [1/2]\n",
      "Val-Loss: 0.0017582897562533617 [1/1]\n",
      "Epoch: <<< 16 >>>\n",
      "Train-Loss: 0.0017944695428013802 [0/2]\n",
      "Train-Loss: 0.0016170606249943376 [1/2]\n",
      "Val-Loss: 0.05511680617928505 [1/1]\n",
      "Epoch: <<< 17 >>>\n",
      "Train-Loss: 0.055287376046180725 [0/2]\n",
      "Train-Loss: 0.05592434108257294 [1/2]\n",
      "Val-Loss: 0.08166558295488358 [1/1]\n",
      "Epoch: <<< 18 >>>\n",
      "Train-Loss: 0.08185479044914246 [0/2]\n",
      "Train-Loss: 0.08188683539628983 [1/2]\n",
      "Val-Loss: 0.014383790083229542 [1/1]\n",
      "Epoch: <<< 19 >>>\n",
      "Train-Loss: 0.014509477652609348 [0/2]\n",
      "Train-Loss: 0.014319220557808876 [1/2]\n",
      "Val-Loss: 0.010572210885584354 [1/1]\n",
      "Epoch: <<< 20 >>>\n",
      "Train-Loss: 0.010569912381470203 [0/2]\n",
      "Train-Loss: 0.010674257762730122 [1/2]\n",
      "Val-Loss: 0.0433855876326561 [1/1]\n",
      "Epoch: <<< 21 >>>\n",
      "Train-Loss: 0.04331636056303978 [0/2]\n",
      "Train-Loss: 0.043206583708524704 [1/2]\n",
      "Val-Loss: 0.020819084718823433 [1/1]\n",
      "Epoch: <<< 22 >>>\n",
      "Train-Loss: 0.020796293392777443 [0/2]\n",
      "Train-Loss: 0.020496997982263565 [1/2]\n",
      "Val-Loss: 0.00026949637685902417 [1/1]\n",
      "Epoch: <<< 23 >>>\n",
      "Train-Loss: 0.00033568229991942644 [0/2]\n",
      "Train-Loss: 0.0003509938542265445 [1/2]\n",
      "Val-Loss: 0.016857659444212914 [1/1]\n",
      "Epoch: <<< 24 >>>\n",
      "Train-Loss: 0.01697302609682083 [0/2]\n",
      "Train-Loss: 0.01714356243610382 [1/2]\n",
      "Val-Loss: 0.016785742715001106 [1/1]\n",
      "Epoch: <<< 25 >>>\n",
      "Train-Loss: 0.016900891438126564 [0/2]\n",
      "Train-Loss: 0.01690620929002762 [1/2]\n",
      "Val-Loss: 0.001241746125742793 [1/1]\n",
      "Epoch: <<< 26 >>>\n",
      "Train-Loss: 0.0013178623048588634 [0/2]\n",
      "Train-Loss: 0.0012876593973487616 [1/2]\n",
      "Val-Loss: 0.0048998380079865456 [1/1]\n",
      "Epoch: <<< 27 >>>\n",
      "Train-Loss: 0.004923860542476177 [0/2]\n",
      "Train-Loss: 0.004918660968542099 [1/2]\n",
      "Val-Loss: 0.010283304378390312 [1/1]\n",
      "Epoch: <<< 28 >>>\n",
      "Train-Loss: 0.010288984514772892 [0/2]\n",
      "Train-Loss: 0.010198308154940605 [1/2]\n",
      "Val-Loss: 0.002739890478551388 [1/1]\n",
      "Epoch: <<< 29 >>>\n",
      "Train-Loss: 0.0027736960910260677 [0/2]\n",
      "Train-Loss: 0.002687735017389059 [1/2]\n",
      "Val-Loss: 0.0008817403577268124 [1/1]\n",
      "Epoch: <<< 30 >>>\n",
      "Train-Loss: 0.0009553129784762859 [0/2]\n",
      "Train-Loss: 0.0009804866276681423 [1/2]\n",
      "Val-Loss: 0.005000808276236057 [1/1]\n",
      "Epoch: <<< 31 >>>\n",
      "Train-Loss: 0.005093547981232405 [0/2]\n",
      "Train-Loss: 0.005137343890964985 [1/2]\n",
      "Val-Loss: 0.0026184995658695698 [1/1]\n",
      "Epoch: <<< 32 >>>\n",
      "Train-Loss: 0.002702816389501095 [0/2]\n",
      "Train-Loss: 0.002701052464544773 [1/2]\n",
      "Val-Loss: 0.00015461524890270084 [1/1]\n",
      "Epoch: <<< 33 >>>\n",
      "Train-Loss: 0.00021228914556559175 [0/2]\n",
      "Train-Loss: 0.00019738211994990706 [1/2]\n",
      "Val-Loss: 0.002260856330394745 [1/1]\n",
      "Epoch: <<< 34 >>>\n",
      "Train-Loss: 0.0022963418159633875 [0/2]\n",
      "Train-Loss: 0.00226086494512856 [1/2]\n",
      "Val-Loss: 0.0019863389898091555 [1/1]\n",
      "Epoch: <<< 35 >>>\n",
      "Train-Loss: 0.002023364184424281 [0/2]\n",
      "Train-Loss: 0.001969611272215843 [1/2]\n",
      "Val-Loss: 0.00016981037333607674 [1/1]\n",
      "Epoch: <<< 36 >>>\n",
      "Train-Loss: 0.0002268104290124029 [0/2]\n",
      "Train-Loss: 0.00020547668100334704 [1/2]\n",
      "Val-Loss: 0.0009077630238607526 [1/1]\n",
      "Epoch: <<< 37 >>>\n",
      "Train-Loss: 0.0009826977038756013 [0/2]\n",
      "Train-Loss: 0.0009946385398507118 [1/2]\n",
      "Val-Loss: 0.0012032468803226948 [1/1]\n",
      "Epoch: <<< 38 >>>\n",
      "Train-Loss: 0.0012807325692847371 [0/2]\n",
      "Train-Loss: 0.001285795122385025 [1/2]\n",
      "Val-Loss: 0.00021518590801861137 [1/1]\n",
      "Epoch: <<< 39 >>>\n",
      "Train-Loss: 0.0002807360142469406 [0/2]\n",
      "Train-Loss: 0.0002699318574741483 [1/2]\n",
      "Val-Loss: 0.00043975349399261177 [1/1]\n",
      "Epoch: <<< 40 >>>\n",
      "Train-Loss: 0.0004906386020593345 [0/2]\n",
      "Train-Loss: 0.0004672688082791865 [1/2]\n",
      "Val-Loss: 0.0007630212348885834 [1/1]\n",
      "Epoch: <<< 41 >>>\n",
      "Train-Loss: 0.0008096746169030666 [0/2]\n",
      "Train-Loss: 0.0007764497422613204 [1/2]\n",
      "Val-Loss: 0.00023434824834112078 [1/1]\n",
      "Epoch: <<< 42 >>>\n",
      "Train-Loss: 0.0002892611955758184 [0/2]\n",
      "Train-Loss: 0.00026541866827756166 [1/2]\n",
      "Val-Loss: 0.0002285357768414542 [1/1]\n",
      "Epoch: <<< 43 >>>\n",
      "Train-Loss: 0.00029450556030496955 [0/2]\n",
      "Train-Loss: 0.00028888636734336615 [1/2]\n",
      "Val-Loss: 0.0004362932813819498 [1/1]\n",
      "Epoch: <<< 44 >>>\n",
      "Train-Loss: 0.0005061904084868729 [0/2]\n",
      "Train-Loss: 0.000503852847032249 [1/2]\n",
      "Val-Loss: 0.00018950176308862865 [1/1]\n",
      "Epoch: <<< 45 >>>\n",
      "Train-Loss: 0.000254314043559134 [0/2]\n",
      "Train-Loss: 0.0002441413525957614 [1/2]\n",
      "Val-Loss: 0.00017900111561175436 [1/1]\n",
      "Epoch: <<< 46 >>>\n",
      "Train-Loss: 0.0002356412005610764 [0/2]\n",
      "Train-Loss: 0.0002169111103285104 [1/2]\n",
      "Val-Loss: 0.00030941737350076437 [1/1]\n",
      "Epoch: <<< 47 >>>\n",
      "Train-Loss: 0.0003626351826824248 [0/2]\n",
      "Train-Loss: 0.0003386751632206142 [1/2]\n",
      "Val-Loss: 0.00017365902021992952 [1/1]\n",
      "Epoch: <<< 48 >>>\n",
      "Train-Loss: 0.00023051098105497658 [0/2]\n",
      "Train-Loss: 0.00021058539277873933 [1/2]\n",
      "Val-Loss: 0.0001449850242352113 [1/1]\n",
      "Epoch: <<< 49 >>>\n",
      "Train-Loss: 0.00020783186482731253 [0/2]\n",
      "Train-Loss: 0.0001968848519027233 [1/2]\n",
      "Val-Loss: 0.00020789641712326556 [1/1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "batch_size = 512\n",
    "train_dataloader = get_loader(x=xtrain, y=ytrain, batch_size=batch_size, x_cat=df_train_cat.to_numpy())\n",
    "val_dataloader = get_loader(x=xval, y=yval, batch_size=batch_size, x_cat=df_val_cat.to_numpy())\n",
    "\n",
    "\n",
    "cat_features = 3 \n",
    "embedding_dim = 10\n",
    "# cat_features = cat_features * embedding_dim\n",
    "# print('in_features:', xtrain.shape[1] + cat_features)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=xtrain.shape[1], \n",
    "    units=2000,\n",
    "    out_features=1, \n",
    "    categorical_dim=cat_features,\n",
    "    no_embedding=len(df_train_cat), \n",
    "    emb_dim=embedding_dim\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "trainer = Trainer(model, lr=3e-7)\n",
    "trainer.fit_epochs(train_dataloader, val_dataloader, use_cyclic_lr=True, x_cat=True, epochs=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
