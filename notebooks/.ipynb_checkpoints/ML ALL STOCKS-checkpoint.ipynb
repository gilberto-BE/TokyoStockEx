{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "# pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_train_data\n",
    ")\n",
    "from metrics import calc_spread_return_sharpe\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, True, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.version.cuda), torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "computer_name1 = 'gilbe'\n",
    "computer_name2 = 'Gilberto-BE'\n",
    "\n",
    "ROOT_PATH = f'c:/Users/{computer_name1}/Documents/TokyoData'\n",
    "\n",
    "\n",
    "'/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv'\n",
    "'/train_files/trades.csv'\n",
    "\n",
    "train_df = pd.read_csv(f'{ROOT_PATH}/train_files/stock_prices.csv')\n",
    "train_df['Date'] = pd.to_datetime(train_df['Date']) \n",
    "train_df.set_index('Date', inplace=True)\n",
    "# train_df = date_features(train_df)\n",
    "print(train_df.head(2))\n",
    "\n",
    "train_options = pd.read_csv(f'{ROOT_PATH}/train_files/options.csv', low_memory=False)\n",
    "train_financials = pd.read_csv(f'{ROOT_PATH}/train_files/financials.csv', low_memory=False)\n",
    "train_trades = pd.read_csv(f'{ROOT_PATH}/train_files/trades.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_stocks = train_df.SecuritiesCode.nunique()\n",
    "# n_stocks = train_df.SecuritiesCode.unique()\n",
    "# for n in n_stocks:\n",
    "#     print(train_df[train_df['SecuritiesCode'] == n].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the unique security codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique adjustment factor: [ 1.          0.5         5.          0.33333333  0.83333333  0.25\n",
      "  0.90909091  0.1        10.          0.2         0.95238095  2.\n",
      "  0.14285714  0.66666667  0.86956522  0.76923077  0.8         4.\n",
      " 20.        ]\n",
      "Date\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "             ... \n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "Name: AdjustmentFactor, Length: 2332531, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>1333</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>1376</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>1377</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RowId  SecuritiesCode    Open    High     Low   Close  \\\n",
       "Date                                                                        \n",
       "2017-01-04  20170104_1301            1301  2734.0  2755.0  2730.0  2742.0   \n",
       "2017-01-04  20170104_1332            1332   568.0   576.0   563.0   571.0   \n",
       "2017-01-04  20170104_1333            1333  3150.0  3210.0  3140.0  3210.0   \n",
       "2017-01-04  20170104_1376            1376  1510.0  1550.0  1510.0  1550.0   \n",
       "2017-01-04  20170104_1377            1377  3270.0  3350.0  3270.0  3330.0   \n",
       "\n",
       "             Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "Date                                                                       \n",
       "2017-01-04    31400               1.0               NaN            False   \n",
       "2017-01-04  2798500               1.0               NaN            False   \n",
       "2017-01-04   270800               1.0               NaN            False   \n",
       "2017-01-04    11300               1.0               NaN            False   \n",
       "2017-01-04   150800               1.0               NaN            False   \n",
       "\n",
       "              Target  \n",
       "Date                  \n",
       "2017-01-04  0.000730  \n",
       "2017-01-04  0.012324  \n",
       "2017-01-04  0.006154  \n",
       "2017-01-04  0.011053  \n",
       "2017-01-04  0.003026  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_train_data()\n",
    "print('Unique adjustment factor:', train_df['AdjustmentFactor'].unique())\n",
    "print(train_df['AdjustmentFactor'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_FEATURES: 4\n",
      "NO_EMBEDDING: 2000\n",
      "NeuralNetwork(\n",
      "  (embedding): Embedding(2000, 24)\n",
      "  (embedding_to_hidden): Linear(in_features=24, out_features=1024, bias=True)\n",
      "  (embedding_output): Linear(in_features=1024, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=1, out_features=1024, bias=True)\n",
      "  (hidden_layer): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "  (output_layer): Linear(in_features=1028, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (stacks): ModuleList(\n",
      "    (0): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer2): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer3): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer4): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer5): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer2): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer3): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer4): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer5): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layer): Linear(in_features=1028, out_features=1, bias=True)\n",
      "    )\n",
      "    (1): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer2): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer3): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer4): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer5): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer2): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer3): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer4): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "          (layer5): Linear(in_features=1028, out_features=1028, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layer): Linear(in_features=1028, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "TS_IN_FEATURES = 1\n",
    "\n",
    "CAT_FEATURES = 4 #cat.shape[1]\n",
    "\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 24\n",
    "NO_EMBEDDING = 2000 #2 * len(df_train_cat)\n",
    "print('NO_EMBEDDING:', NO_EMBEDDING)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=TS_IN_FEATURES, \n",
    "    units=1024,\n",
    "    out_features=1, \n",
    "    categorical_dim=CAT_FEATURES,\n",
    "    no_embedding=NO_EMBEDDING, \n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    n_blocks=8,\n",
    "    n_stacks=4,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop throug each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for stock: 1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['RowId'] = np.squeeze(enc.fit_transform(df['RowId'].to_numpy().reshape(-1, 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuos shape: (1202, 8)  categorical shape: (1202, 4)\n",
      "Using cuda-device\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\tokyo\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:239.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 6.845815658569336, 'mae': 2.6102724075317383}\n",
      "Validation metrics: {'mse': 0.16677841544151306, 'mae': 0.3778696358203888}\n",
      "Average train loss: 0.0016339194029569627 | Average val loss: 0.48280057311058044\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.06539556384086609, 'mae': 0.24994440376758575}\n",
      "Validation metrics: {'mse': 1.440855860710144, 'mae': 0.7642908692359924}\n",
      "Average train loss: 0.034791669249534606 | Average val loss: 1.6764425039291382\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.00568754319101572, 'mae': 0.06239183619618416}\n",
      "Validation metrics: {'mse': 5.488706588745117, 'mae': 1.9211140871047974}\n",
      "Average train loss: 0.1297887921333313 | Average val loss: 4.638171195983887\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.9557415843009949, 'mae': 0.9757185578346252}\n",
      "Validation metrics: {'mse': 0.05644587427377701, 'mae': 0.18324002623558044}\n",
      "Average train loss: 0.34076461791992185 | Average val loss: 0.06935837864875793\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.46360671520233154, 'mae': 0.6721510291099548}\n",
      "Validation metrics: {'mse': 8.52892017364502, 'mae': 2.5068202018737793}\n",
      "Average train loss: 0.004896019771695137 | Average val loss: 7.5235748291015625\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 1.6905572414398193, 'mae': 1.2955647706985474}\n",
      "Validation metrics: {'mse': 0.0750989094376564, 'mae': 0.24167078733444214}\n",
      "Average train loss: 0.5281484127044678 | Average val loss: 0.10068738460540771\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 0.25071635842323303, 'mae': 0.4963630437850952}\n",
      "Validation metrics: {'mse': 0.045875802636146545, 'mae': 0.15559513866901398}\n",
      "Average train loss: 0.008939646184444427 | Average val loss: 0.07983481884002686\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 0.09873536974191666, 'mae': 0.3075656592845917}\n",
      "Validation metrics: {'mse': 0.007357036229223013, 'mae': 0.04542477801442146}\n",
      "Average train loss: 0.006336718052625656 | Average val loss: 0.012551764026284218\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.21317298710346222, 'mae': 0.45606258511543274}\n",
      "Validation metrics: {'mse': 0.030041424557566643, 'mae': 0.14143472909927368}\n",
      "Average train loss: 0.0006983667146414519 | Average val loss: 0.03710464760661125\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.005075396038591862, 'mae': 0.06020357459783554}\n",
      "Validation metrics: {'mse': 0.011491813696920872, 'mae': 0.08043207973241806}\n",
      "Average train loss: 0.0032881032675504684 | Average val loss: 0.013541625812649727\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.06163698807358742, 'mae': 0.24073894321918488}\n",
      "Validation metrics: {'mse': 0.002709917491301894, 'mae': 0.0432235486805439}\n",
      "Average train loss: 0.001122208684682846 | Average val loss: 0.007945271208882332\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.0042190453968942165, 'mae': 0.049972470849752426}\n",
      "Validation metrics: {'mse': 0.0012964814668521285, 'mae': 0.027287665754556656}\n",
      "Average train loss: 0.0006160041783004999 | Average val loss: 0.0013693918008357286\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "Train metrics: {'mse': 0.023170575499534607, 'mae': 0.13877974450588226}\n",
      "Validation metrics: {'mse': 0.0029905145056545734, 'mae': 0.03835410997271538}\n",
      "Average train loss: 0.0002368423854932189 | Average val loss: 0.002566856797784567\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "Train metrics: {'mse': 0.00398856308311224, 'mae': 0.05070577561855316}\n",
      "Validation metrics: {'mse': 0.00206127786077559, 'mae': 0.035509467124938965}\n",
      "Average train loss: 0.00028483050409704446 | Average val loss: 0.002344113541767001\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "Train metrics: {'mse': 0.007607359439134598, 'mae': 0.07530466467142105}\n",
      "Validation metrics: {'mse': 0.0011510620824992657, 'mae': 0.02790691889822483}\n",
      "Average train loss: 0.00021785011049360036 | Average val loss: 0.0013057341566309333\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "Train metrics: {'mse': 0.005171678960323334, 'mae': 0.05646492913365364}\n",
      "Validation metrics: {'mse': 0.0009900726145133376, 'mae': 0.023298116400837898}\n",
      "Average train loss: 0.0001176313846372068 | Average val loss: 0.0007470116834156215\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "Train metrics: {'mse': 0.005666006822139025, 'mae': 0.05962008237838745}\n",
      "Validation metrics: {'mse': 0.0010139091173186898, 'mae': 0.023741817101836205}\n",
      "Average train loss: 0.00012173929717391729 | Average val loss: 0.0007985568372532725\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "Train metrics: {'mse': 0.0038509259466081858, 'mae': 0.05156351625919342}\n",
      "Validation metrics: {'mse': 0.0008830992155708373, 'mae': 0.0231205765157938}\n",
      "Average train loss: 0.00010612871265038847 | Average val loss: 0.0008748175459913909\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "Train metrics: {'mse': 0.0022220539394766092, 'mae': 0.03769015893340111}\n",
      "Validation metrics: {'mse': 0.0006977321463637054, 'mae': 0.01993364840745926}\n",
      "Average train loss: 8.753305301070213e-05 | Average val loss: 0.0005594677058979869\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "Train metrics: {'mse': 0.003759735031053424, 'mae': 0.04719856008887291}\n",
      "Validation metrics: {'mse': 0.0006106182700023055, 'mae': 0.018065014854073524}\n",
      "Average train loss: 8.765823440626264e-05 | Average val loss: 0.0004786641802638769\n",
      ".................... End of epoch 19 ....................\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEGCAYAAABM7t/CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsoElEQVR4nO3deXxcdbn48c+TpVm7ZOvemhZqWUo30lYKlBZEEBBkEa38hMpFLoiA+hNked0rl6tXRbwq/rhgURYVKSiFq0JBULBsAm2alhaKpaXQJG1J0j1p1nl+f5xzkmk6SSaZOTOTOc/79cprZs6c5ck0ffLNc77nOaKqGGOMSV0ZyQ7AGGNM7yxRG2NMirNEbYwxKc4StTHGpDhL1MYYk+Ky/NhpaWmplpeX+7FrY4xJS6tXr65X1bJI7/mSqMvLy1m1apUfuzbGmLQkIh/09J6VPowxJsVZojbGmBRnidoYY1KcLzVqY0z6aWtro7q6mubm5mSHMqjl5uYyfvx4srOzo97GErUxJirV1dUMHTqU8vJyRCTZ4QxKqkpDQwPV1dVMmjQp6u2s9GGMiUpzczMlJSWWpGMgIpSUlPT7rxJL1MaYqFmSjt1APkNL1Klky4tQvynZURhjUowl6lSy/F9h5Y+SHYUxKamhoYGZM2cyc+ZMRo8ezbhx4zpft7a29rrtqlWruO666/p1vAcffJCvfe1rsYQcN3YyMVWEQtBYBwc+SnYkxqSkkpISqqqqALjtttsoLCzkW9/6Vuf77e3tZGVFTmkVFRVUVFQkIkxf2Ig6VTTvAe2ApvpkR2LMoLFkyRKuuuoq5s2bx4033sgbb7zBCSecwKxZs5g/fz7vvvsuAC+++CLnnHMO4CT5yy+/nIULFzJ58mTuuuuuPo+zdetWTj31VKZPn85pp53Ghx9+CMDvf/97pk2bxowZM1iwYAEAGzZsYO7cucycOZPp06ezaVPs5UwbUaeKpgbnsbEhuXEYE4X/+NMG3q7dF9d9HjN2GN/5zLH93q66uppXX32VzMxM9u3bx0svvURWVhbPP/88t9xyC48//vhh22zcuJEXXniB/fv3M3XqVK6++upe5zVfe+21XHbZZVx22WXcf//9XHfddTz55JPcfvvtPPvss4wbN449e/YAcO+993L99ddzySWX0NraSkdHR7+/p+4sUaeKRnck3VQPqmBn142Jyuc+9zkyMzMB2Lt3L5dddhmbNm1CRGhra4u4zdlnn01OTg45OTmMHDmSnTt3Mn78+B6P8dprr7F8+XIAvvSlL3HjjTcCcOKJJ7JkyRIuvvhiLrjgAgBOOOEEvve971FdXc0FF1zAlClTYv4eLVGnCq/k0dEKLfshd1hy4zGmFwMZ+fqloKCg8/m//du/sWjRIp544gm2bt3KwoULI26Tk5PT+TwzM5P29nbuvvtu7rvvPgCefvrpqI5977338vrrr/PUU09x/PHHs3r1ar74xS8yb948nnrqKc466yx+8YtfcOqppw78G8Rq1KmjMaw2bXVqYwZk7969jBs3DnBmbfTHNddcQ1VVFVVVVYwdO/aQ9+bPn8+yZcsAePjhhzn55JMB2Lx5M/PmzeP222+nrKyMbdu2sWXLFiZPnsx1113Heeedx7p162L+vixRp4rw5Gx1amMG5MYbb+Tmm29m1qxZtLe3x22/P//5z3nggQeYPn06v/nNb/jZz34GwA033MBxxx3HtGnTmD9/PjNmzOCxxx5j2rRpzJw5k/Xr13PppZfGfHxR1Zh30l1FRYXajQP6acVN8Po9zvPFy2Dqp5MbjzHdvPPOOxx99NHJDiMtRPosRWS1qkacQ2gj6lTRVA+ZQ5znjVb6MMZ0sUSdKhrroeRI57nVqI0xYfpM1CIyVUSqwr72icjXExBbsDTVw/AJkJVnI2pjzCH6nJ6nqu8CMwFEJBOoAZ7wN6wAamyA0dOhoLTr4hdjjKH/pY/TgM2q2uPdcs0AqDoj6vwS58tG1MaYMP1N1F8AHon0hohcKSKrRGRVXV1d7JEFSct+50KXglJ3RG2J2hjTJepELSJDgHOB30d6X1WXqmqFqlaUlZXFK75g8BJzfqnzZfOojTnMokWLePbZZw9Z9tOf/pSrr7464voLFy7EmyZ81llndfbiCHfbbbdx5513Rty+sLAwtoDjqD8j6k8Dlaq6069gAstLzDaiNqZHixcv7rw60LNs2TIWL17c57ZPP/00I0aM8Cky//UnUS+mh7KHidEhI+oSaGuC1qbkxmRMirnooot46qmnOm8SsHXrVmpra3nkkUeoqKjg2GOP5Tvf+U7EbcvLy6mvd/6ffe973+PjH/84J510Umcb1N6oKjfccAPTpk3juOOO49FHHwVg+/btLFiwgJkzZzJt2jReeuklOjo6WLJkSee6P/nJT+LyvUfVlElECoDTgX+Ny1HNobxZHgUlzoganOQ9ZGLyYjKmNytugh1vxXefo4+DT/+gx7eLi4uZO3cuK1as4LzzzmPZsmVcfPHF3HLLLRQXF9PR0cFpp53GunXrmD59esR9rF69mmXLllFVVUV7ezuzZ8/m+OOP7zWs5cuXU1VVxdq1a6mvr2fOnDksWLCA3/3ud5xxxhnceuutdHR00NTURFVVFTU1Naxfvx4gYrllIKIaUatqo6qWqOreuBzVHKqxW406fJkxplN4+cMrezz22GPMnj2bWbNmsWHDBt5+++0et3/ppZc4//zzyc/PZ9iwYZx77rl9HvPll19m8eLFZGZmMmrUKE455RTefPNN5syZwwMPPMBtt93GW2+9xdChQ5k8eTJbtmzh2muv5ZlnnmHYsPh0wbQ2p6mgqR6ycmFIQdiI2k4omhTWy8jXT+eddx7f+MY3qKyspKmpieLiYu68807efPNNioqKWLJkCc3Nzf3e77Zt2/jMZz4DwFVXXcVVV13V5zYLFixg5cqVPPXUUyxZsoRvfvObXHrppaxdu5Znn32We++9l8cee4z777+/3/F0Z5eQp4LGBmckLeLUqMFG1MZEUFhYyKJFi7j88stZvHgx+/bto6CggOHDh7Nz505WrFjR6/YLFizgySef5ODBg+zfv58//elPAEyYMKGzxWn3JH3yySfz6KOP0tHRQV1dHStXrmTu3Ll88MEHjBo1iq985StcccUVVFZWUl9fTygU4sILL+S73/0ulZWVcfm+bUSdCprqnfo0HFqjNsYcZvHixZx//vksW7aMo446ilmzZnHUUUcxYcIETjzxxF63nT17Np///OeZMWMGI0eOZM6cOX0e7/zzz+e1115jxowZiAh33HEHo0eP5qGHHuJHP/oR2dnZFBYW8utf/5qamhq+/OUvEwqFAPj+978fl+/Z2pymgqWLIK8IvrTcuUrxP8vghGvg9P9IdmTGdLI2p/FjbU4Ho6b6rpG0iM2lNsYcwhJ1KvBq1B67OtEYE8YSdbK1HYS2xq4aNTjPbURtUpAfpdKgGchnaIk62TrnUIcl6vxSm/VhUk5ubi4NDQ2WrGOgqjQ0NJCbm9uv7WzWR7KFXz7usZ7UJgWNHz+e6upqrDtmbHJzcxk/fny/trFEnWzhDZk8+aXQsg/aWyArJzlxGdNNdnY2kyZNSnYYgWSlj2SLOKJ2yyA2qjbGYIk6+bxadEG3GnX4e8aYQLNEnWxN9ZCRBbkjupZ5ZZBGqwUaYyxRJ1+je69Eka5l+daYyRjTxRJ1sjXtOrQ+DWEjait9GGMsUSdfeEMmT+4IkEy76MUYA1iiTr7G+sNH1BkZkF9sI2pjDBBlohaRESLyBxHZKCLviMgJfgcWGOENmcLl20UvxhhHtBe8/Ax4RlUvEpEhQL6PMQVHRxs07z18RA1O8rYRtTGGKEbUIjIcWAD8CkBVW1V1j89xBUP4TW27y7fGTMYYRzSlj0lAHfCAiKwRkV+6dyU/hIhcKSKrRGSV9QKIUmOEqxI9NqI2xriiSdRZwGzgHlWdBTQCN3VfSVWXqmqFqlaUlZXFOcw05Y2Ye6pRN+9xyiPGmECLJlFXA9Wq+rr7+g84idvEqq8RNTjzrI0xgdZnolbVHcA2EZnqLjoNeNvXqIKiKULnPI/Xn9rq1MYEXrSzPq4FHnZnfGwBvuxfSAHSWA+Ic2Pb7uzqRGOMK6pErapVQMS745oYNNU7SToj8/D3Csq61jHGBJpdmZhMjT1c7AJhrU7tohdjgs4SdTI1NUQ+kQjOJeSIjaiNMZaok6oxQkMmT0amUxaxGrUxgWeJOpl6G1GDe5NbS9TGBJ0l6mQJheDgrp5r1OAkcatRGxN4lqiT5eBu0FAfI2rr92GMsUSdPL1dPu7Jt34fxhhL1MnTefl4DycTwUniB3c5ZRJjTGBZok6WaEfUGnLKJMaYwLJEnSy9NWTydDZmsvKHMUFmiTpZvIZMvZU+vPesTm1MoFmiTpbGesgZDllDel7HRtTGGCxRJ09TL1clevKtg54xxhJ18jTW916fhrCe1HbRizFBZok6WZoaeq9Pg1MWyRluI2pjAs4SdbL01pApnF2daEzgWaJOBtW+GzJ57OpEYwIvqju8iMhWYD/QAbSrqt3tJRbNeyHU1vvFLp6CUtjzof8xGWNSVrT3TARYpKo2tIuHzjnU0YyoS6Cm0t94jDEpzUofydDb3ce7Kyh11lf1NyZjTMqKNlEr8BcRWS0iV/oZUCBE05DJk1/qlEma9/obkzEmZUVb+jhJVWtEZCTwnIhsVNWV4Su4CfxKgIkTJ8Y5zDQTTUMmT+fViQ2QN8K3kIwxqSuqEbWq1riPHwFPAHMjrLNUVStUtaKsrCy+UaabaBoyeTqvTqzzLx5jTErrM1GLSIGIDPWeA58C1vsdWFpraoDsfBiS3/e6BdaYyZigi6b0MQp4QkS89X+nqs/4GlW6i+bycU++NWYyJuj6TNSqugWYkYBYgiOahkyeAmvMZEzQ2fS8ZOjPiDo7D7ILrDGTMQFmiToZmhqim/HhKSixEbUxAWaJOhka66ObQ+3JL7UatTEBZok63Ct3wdZX/D1GayO0H+zniNoaMxkTZJaoPa2N8Px3YPUD/h6nP3OoPfmlVqM2JsAsUXu2rwMNwe6t/h6nqR+Xj3u8GrX1+zAmkCxRe2rdDnV+J+rGfjRk8uSXQkcLtB7wJyZjTEqzRO2pXeM8NtZBy37/jjOgEbXNpTYmyCxRe2oqISvXeb77A/+O09iPhkye/LDGTMaYwLFEDXBwD+zaDFNOd177Wf5oaoCMbMgZFv02NqI2JtAsUUNX2ePY851HXxN1vZN4nd4p0fHKJDaX2phAskQNXYn6iFMhZ7i/iboxypvahitw28baiNqYQLJEDc6Mj+LJkFcExeUJGFH340QiwJACp35uI2pjAskSNUDNGhg7y3leVA673/fvWP1pyOQRcbZptJOJxgSRJeoDH8G+ahg723ldVA57PoRQhz/H629DJk9BiY2ojQkoS9RefXpcWKLuaIX92+N/rPYWaNnX/xE1uCNqS9TGBJEl6ppKkAwYPd15XVTuPPpRp/bmQfe3Rg3OKNxG1MYEkiXq2jVQOhVyCp3XfibqgTRk8liN2pjAijpRi0imiKwRkT/7GVBCqTozPryyB8DwCSCZPo2oB3BVoqegBNoaoe1gfGMyxqS8/oyorwfe8SuQpNhb7fT28GZ8AGRmw/DxsMuHmR/eiHigI2qwOrUxARRVohaR8cDZwC/9DSfBvI55Y2cfuryoPAVH1HY3cmOCKtoR9U+BG4FQTyuIyJUiskpEVtXV1cUjNv/VrnH6boyeduhyvxJ1Y71z4jJ3RP+37RxRW53amKDpM1GLyDnAR6q6urf1VHWpqlaoakVZWVncAvRVTSWMOhaycg5dXlTujFzj3e60qR7yiiFjAOdwbURtTGBFkzFOBM4Vka3AMuBUEfmtr1ElQigEtVWH1qc9nTM/4tzutLF+YGUP6GrMZDVqYwKnz0Stqjer6nhVLQe+APxNVf+P75H5bff70LL30BkfnuJJ7jpb43vMpgE0ZPLkDnfKNDaiNiZwgjuPuqaHE4kQNqKO88yPpoaBXewCbr+PEhtRGxNAWf1ZWVVfBF70JZJEq62ErDwoO+rw9/KKnBFsvEfUA2nIFK7A7kZuTBAFe0Q9Zjpk9vC7Kt4zP0IdcHD3wGvUYCNqYwIqmIm6ox12rItc9vDEO1E37QI0DiNqS9TGBE0wE3X9u9DWFHnGhyfe7U47L3YZYI0arN+HMQEVzETtnUiMNOPDUzQpvu1OY2nI5CkodWaqtLfGJyZjzKAQzERdu8a5C3jxET2v4838iFfPj1guH/d03uTWRtXGBElAE3UljJ3Z+xWC8W53Gq8RNTiNpIwxgRG8RN3eAjvW916fBqeDXjzbnXqj4Pzige8j3y4jNyaIgpeod26AUFvvMz6gq91pPEfUuSOc/Q5UgTVmMiaIgpeoa6M4keiJ5xS9phj6fHhsRG1MIAUvUdescU7KDZ/Q97rFk+I7oo6lPg3OFZOSYRe9GBMwwUvUtZVO2UOk73Xj2e60qSH2EXVGhtMm1UbUxgRKsBJ1ayPUbYyu7AHxnfnRWB/biURPQamNqI0JmGAl6u3rQEN9z/jwxCtRh0KxtTgNl2+NmYwJmmAl6p7ukdiTeCXq5j2gHbGXPsC5BN1G1MYESsAS9RoYNg6Gjopu/Xi1O23a5TzGbURtidqYIAlWoq6pjL7s4YnHFL14NGTyFJQ67VI72mPflzFmUAhOoj64B3ZtHkCinhR7v494XD7u8fZxcFfs+zLGDArR3IU8V0TeEJG1IrJBRP4jEYHF3fYq5zHaGR+eeLQ7jUdDJk+B3eTWmKCJZkTdApyqqjOAmcCZIvIJX6PyQ+c9EgdQ+gi1wb7agR/bjxG11amNCYxo7kKuqnrAfZntfqmvUfmhttIpY+QV9W+7eMz8aGqAIYWQnTvwfXg6+31YojYmKKKqUYtIpohUAR8Bz6nq6xHWuVJEVonIqrq6FGzDWbOm/2UPiE+ibqzv6iUdq84Rtc2lNiYookrUqtqhqjOB8cBcEZkWYZ2lqlqhqhVlZWVxDjNGBz6CfdXRz58OF492p/FoyOTxrm60EbUxgdGvWR+qugd4ATjTl2j8UrvGeexvfRqctqQjJsDuGGZ+xKMhU3g8eUVWozYmQKKZ9VEmIiPc53nA6cBGn+OKr5pKp+vcmBkD2z7WudTxaMgULt/6fRgTJNGMqMcAL4jIOuBNnBr1n/0NK85q10DpVMgpHNj2sSRq1fjWqMFJ+lajNiYwsvpaQVXXAQOoGaQIVWfGx5GnD3wfReVOYmzeB7nD+rdt6wHoaInziLoEGjbHb3/GmJSW/lcm7q12bgY7kBkfHm/mx54P+r9tPOdQewqs34cxQZL+ibrzRGIcEvVAyh+dN7WNY+kjv9Rp9BQKxW+fxpiUFYBEXQkZ2TD6sBmF0Sua5DwOpOdHYxwvH/cUlDptU5v3xG+fxpiUlf6JuqYSRh0DWTkD30feCOcO4qk0ogab+WFMQKR3og6FoLYqtrKHZ6AzP+LZkMnjNWayOrUxgZDeiXr3+9CyN7YTiZ6BJurGesjMcXp9xIuNqI0JlPRO1APtmBfJQNudehe7RHPX82gVWAc9Y4IkvRN1bSVk5UHZ0bHva6DtTuN9sQt07a/RLnoxJgjSPFGvgTHTIbPP63r6VuzO/Ohvz494NmTyZOVAzjAbURsTEOmbqDvaYfva+JQ9YOBzqePZkClcvt2N3JigSN9EXf8utDXFZ8YHwLABtjuNd0Mmj12daExgpG+i9k4kxmPGBzjlkxET+peo25qdXh/xrlGD20HPatTGBEH6JuraNU4dt/iI+O2zv1P0/JhD7SkosRG1MQGRxom60uk/nRHHb7G/idqPhkwerye1Dr7bVxpj+ic9E3V7C+xYH7+yh6doUle702j4OqIudaYLtkQZizFm0ErPRL1zg5PE4nUi0dPfmR9eDdmvETXYzA9jAiA9E3VtHK9IDNffRN05ovbhZGKBJWpjgiKaeyZOEJEXRORtEdkgItcnIrCY1KxxZlqMmBjf/fZ7RF3vTOnLHRHfOKBrJomdUDQm7UVzyV478H9VtVJEhgKrReQ5VX3b59gGrnaNU/aIZ38N6H+70yb38vF4xwE2ojYmQPocUavqdlWtdJ/vB94Bxvkd2IC1NkLdO/Eve3j6M/OjaZc/JxKhq0ZtI2pj0l6/atQiUo5zo9vXI7x3pYisEpFVdXV1cQpvALavAw3Ff8aHp3hS/0offlzsAjAkH7Lz7aIXYwIg6kQtIoXA48DXVfWwOWGqulRVK1S1oqysLJ4x9o9fJxI9/Wl36kdDpnD5dhm5MUEQVaIWkWycJP2wqi73N6QY1a6BoWNh6Gh/9t/Z7rSm73X9asjkKbDGTMYEQTSzPgT4FfCOqv63/yHFqKbSv7IHRD/zo6PNufmsjaiNMTGKZkR9IvAl4FQRqXK/zvI5roE5uAd2bfav7AHRJ+qmXc6jXzVqcH4JWI3amLTX5/Q8VX0Z8GF+mQ+2VzmPfibqYeMhIyuKRO3j5eOefLcxk6o/UwCNMSkhva5MjOc9EnuSmQXDo2h36mdDJk9BKbQ3O1MSjTFpK70SdW2l0zgpv9jf4xSVw64+bsmVkBG1zaU2JgjSJ1GHOqB6lb8nEj3RXPTiZ0MmT+fViVanNiadpU+iXv847N8OR5/r/7GKyuHgLmje2/M6TfWA+Du6txG1MYGQHom6ox1e/AGMmpa4RA2w+4Oe12msh7wiyMj0Lw6vK5/NpTYmraVHol73qDMtb+HN8b2jS0+imaLn91WJYCNqYwJi8Cfqjjb4+w9hzEw46uzEHDOaRN3Y4G99GiBnKGQOsRG1MWlu8CfqNb+FPR/AolsTN5c4b4RT1tjdy8yPpnp/bhgQTsS9OtFOJhqTzgZ3om5vgZV3wvg5MOX0xB67r5kffnbOC1dQaiNqY9Lc4E7Ulb+GfdWw6JbEX5nXW6IOhZxZIX6XPsBJ1FajNiatDd5E3XbQGU1PnA+TFyX++L21O23e4/TE9vtkIji/DGxEbUxaG7yJetX9cGAHnJrA2nS4onIItUdud5qIy8c9BVajNibdDc5E3doIL/8EJp0C5SclJ4beZn74effx7vJLoPUAtDX7fyxjTFIMzkT9xn3QWOfM9EiWoknOY6SeH4keUYPVqY1JY4MvUbfsh1d+Bkd+EibOS14cw8b13O40EQ2ZPN4vA6tTG5O2Bl+i/se9zoyKRbckN47e2p12NmRK0PQ8sBG1MWlscCXqg3vgtZ/D1LNg3PHJjqbnKXpN9ZAzDLJy/I8h3zroGZPuorln4v0i8pGIrE9EQL36x/84HesW3pzsSBw9JepEXewCXScsbURtTNqKZkT9IHCmz3H0rWkXvPY/Tne8MdOTHY2jp3aniWjI5Mkd4dTKrUZtTNrqM1Gr6kpgVwJi6d2rdznT0JJdmw5X7M786D6qTkRDJo9I170TjTFpaXDUqA/Uweu/gGkXwsijkx1Nl57mUieiIVO4fLsbuTHpLG6JWkSuFJFVIrKqrq4uXrt1vPJT5yauC2+K735jFSlRq7o16gSNqMH5pWAjamPSVtwStaouVdUKVa0oKyuL125h/w5485cw/fNQOiV++42H3OFuu9OtXcta9kGoLXE1arB+H8akudQvfbz0387NAU65MdmRRNZ95kcir0r0WAc9Y9JaNNPzHgFeA6aKSLWI/Iv/Ybn2VsPqB2DWJVA8OWGH7ZfuidprkJToEXXzXmhvTdwxjTEJk9XXCqq6OBGBRPTSj52a74IbkhZCn4omwTt/cm6wm5nVlaj9vPt4d51zqRtg2JjEHdcYkxCpW/rY/QFU/gZmXwojJiY7mp51b3eajNKH3eTWmLSWuol65R0gGbDgW8mOpHfdZ34ksiGTp8AaMxmTzlIzUTdshqpHoOJyGDY22dH0rnuibqyHrDwYUpC4GDpH1DaX2ph0lJqJ+u93QOYQOOkbyY6kb93bnTY1JHY0DTaiNibNpV6irvsnvPUYzL0Cho5KdjR9697uNJENmTx5RYBYjdqYNJV6ifrF7zulgxO/nuxIolc8CXa7d3pJZEMmT0amM8vERtTGpKXUStQ7N8CG5fCJqxKf7GIRPpc6kQ2Zwmh+Ke++/z7L3vgw4cc2xvgrtRL1i993Gu6f8LVkR9I/ReVwcLdzY4MkjKj3Hmxj474h7KnfwU3L3+K2P26gvSOU0BiMMf5JnUTdvBeqV8MnvprYi0XiwZv5UbcR2poSWqPetquJC+95lQ+a8zh6WAtfOXkSD766la/8ehUHWtoTFocxxj+pk6hzh8N1lXDidcmOpP+8RF29ynlM0Ii68sPdfPbuV6jb38Kso45kWMdebj37GL53/jRWbqrnontepWbPwYTEYozxT+okaoDsBM8/jhcvUde4iToBNeqn1m1n8dJ/UJibxfKvzmfU6PFO+SXUwSXzPsaDX55Dze6DfPbuV1i7bY/v8Rhj/JNaiXqQ2k8+LUNG0PDuqwAcyBrh27FUlXte3Mw1v6vkuHHDeeKrJ3JEWaE7ilfnlmXAyVPKWP7V+eRkZfD5pa/xzPrtvsVkjPGXJeoBam7rYMVb27n6t6up+O7zvNNcTEn7TgC++PAm7n/5fVrb43tCr60jxM3L3+KHz2zkMzPG8tsr5lFcMMR5M//wm9xOGTWUJ685kaPHDOOq31Zy7983o6pxjckY478+u+eZLm0dIV7eVM+f1tbyl7d3cqClndLCHBbPncjE3cfA+1sAGDVmArf/+W0eem0rN55xFGcdNxoRienYew+2cc3Dlbz8Xj3Xnnok3/jkx8nICNtnD1cnlhbm8MhXPsG3fr+WH6zYyPt1jfznZ6cxJMt+RxszWFii7kNHSHnj/V38cW0tK9ZvZ09TG8Nyszj7uDGcO3Msn5hcQmaGwPMfh/eBjGyWXrGQv2+q5wcrNnLN7yqZNXEEt551NBXlA5vNsm1XE5c/+CZbGxq583MzuOj48Yev1EsHvdzsTO76wiwmlxZw19/eY9vuJu655HiG52cPKB5jTGJZoo5AVVlbvZc/VtXy1Fu17NzXQl52JqcfM4pzZ4xlwcfLDh+ReicU80uQjAwWTh3JyVPKeHx1NT9+7l0uuvc1zjh2FN8+8ygmlxVGHUvVtj1c8dCbtLaHeOjyucw/oocTlX30+8jIEL75qamUlxbw7cfXcf49r/DAkjl8rGQQnrw1JmAsUbsOtLSzaed+nn9nJ39au50PdzUxJDODU6aWce6MsZx29Ejyh/TycXmJOmxqXmaGcPGcCZwzYwy/eul97v37Zv76zkq+OG8i1582hZLCnF5jWvHWdr7+aBUjh+Ww7MoTOHJkLwk+P+zmAb24YPZ4xo3I419/u5rP3v0KSy+tYM4AR/rGmMQQP04uVVRU6KpVq+K+31ipKjv2NbP5o0Y21x3o+vqokR37mgHIEDjxyFI+M2MsZxw7muF5UZYH9nwIPz0OJp0Cl/0x4ip1+1v42V//ySNvbCMvO5OrFx7B5SdOIm9I5mFxLl25he+v2MjsiSO479KKPpM6AD+YCCOPhWM/C1m5znTHrFz3ea7TQyXbeb1tf4jr/rCR9/eEuO3C4/ns7BS+OYMxASAiq1W1IuJ70SRqETkT+BmQCfxSVX/Q2/rJTtTNbR1sbWg8LCFvqWukqbWjc72hOVlMHlnIEWUFHFHmPB7/sWLKhkaRFLsLdcB3R8Ix58FF9/e66nsfHeCHz2zkubd3MmZ4Lt88/eNcMHs8mRlCW0eIf//fDTzyxoecM30Md35uBrnZmb3ur9Ovz4MtL/Y/dqBDMsnIzkfyi53WrcPGul/jYPi4rucFIyHDTkQaE28xJWoRyQT+CZwOVANvAotV9e2etolHom5tD3GgpZ0Dze3sb2njQHO787qlnf3e87Bl3nrbdh1k2+4mwr+tcSPyOMJNyJPdhHxkWSFlQ3Nino1xiKdvhInzYNqFUa3++pYG/mvFRtZu28PRY4bxjU9O4Tf/+ICXNtVzzaIj+L+nTz10ZkdfQiFoPwhtzWGP7lfbwbDnXe+3tzbx13Uf8t72Oo4pG8L80Urmge1k7N+O7K9FOloOOYRmZEHhaHRYWPJ2H2X4OCQrx7mMvq3JOWZr2PO2RvfxoLPskPfc5whk5zt/DWTndXvefVn3xzynj7lkuF+Z7qM4HQYPWZYRtky6loevl5HpvGdMAsSaqE8AblPVM9zXNwOo6vd72magifq0H7/InqY29re0RzUHOUOgMCeLobnZFOZkUZCTydgRec7o2E3Mk0oLeq8tJ5mq8ud127nj2Y1s23WQrAzhv84/jovnTEhoDPf8fTN3PPNu93coZj9jZBejpYExsosx0sBo2cVYupblSlvUxwohNJNDM0OcR8mlhRxaZAgtkgtAjraQQwu57mOOtpJLC7m0kElim02FEPcrI/KXhL+Xife/STofvSV6yOue3o8PcffoPXLI697WCX/Po4e9PpQe9sssll9uiZjn33t83b/f/mjMHM5Rt742oG17S9TRZLBxwLaw19XAvAgHuRK4EmDixIHVO+dOKiEzAwpzshmam0VhjvuVm8XQnCwKwp4X5maRl50Z3xFxEogIn5kxlk8dO4rHV9cwZVRhwk/uiQhfXXgksycWsaF2X+dFMaqgqPvovA6psgPYru5yVXLa9lLYsoP8lo/IDLXRmpFLs+TSmpFDmzjPWySHVsmllWw6FELuth0h7XquXUlMRJz/LgKCOINeVbJoZ4i2MERbyNFmskMtZHuvQwfJ1A4ghGgHogoaIoMOUEU0hGgI1E2/GgJCZHjL1Em33mOGdiCok6a1w31UhI4I63opXSMktsgJU8PSNYCKu1IMP9LSmee6/2I4PAFG+iUh2lvKPnTdiPuNxzkvP/9P9xlfbPF3DBkW0/Y9iWZEfRFwpqpe4b7+EjBPVXvsRZrsGrUxxgw2vY2oozkrVAOE/x0+3l1mjDEmAaJJ1G8CU0RkkogMAb4ARJ5/ZowxJu76rFGraruIfA14Fmd63v2qusH3yIwxxgBRXpmoqk8DT/scizHGmAjsygVjjElxlqiNMSbFWaI2xpgUZ4naGGNSnC/d80SkDvhggJuXApGbKqcGiy82Fl9sLL7YpHJ8H1PVskhv+JKoYyEiq3q6OicVWHyxsfhiY/HFJtXj64mVPowxJsVZojbGmBSXiol6abID6IPFFxuLLzYWX2xSPb6IUq5GbYwx5lCpOKI2xhgTxhK1McakuKQlahE5U0TeFZH3ROSmCO/niMij7vuvi0h5AmObICIviMjbIrJBRK6PsM5CEdkrIlXu178nKj73+FtF5C332IfdpUEcd7mf3zoRmZ3A2KaGfS5VIrJPRL7ebZ2Efn4icr+IfCQi68OWFYvIcyKyyX0s6mHby9x1NonIZQmM70cistH993tCREb0sG2vPws+xnebiNSE/Rue1cO2vf5f9zG+R8Ni2yoiVT1s6/vnFzNVTfgXTrvUzcBkYAiwFjim2zpfBe51n38BeDSB8Y0BZrvPh+Lc3Ld7fAuBPyfj83OPvxUo7eX9s4AVOHdT+gTwehL/rXfgTOZP2ucHLABmA+vDlt0B3OQ+vwn4YYTtioEt7mOR+7woQfF9Cshyn/8wUnzR/Cz4GN9twLei+Pfv9f+6X/F1e//HwL8n6/OL9StZI+q5wHuqukVVW4FlwHnd1jkPeMh9/gfgNEnQDRJVdbuqVrrP9wPv4Nw7cjA5D/i1Ov4BjBCRMUmI4zRgs6oO9ErVuFDVlcCubovDf8YeAj4bYdMzgOdUdZeq7gaeA85MRHyq+hdVbXdf/gPn7kpJ0cPnF41o/q/HrLf43LxxMfBIvI+bKMlK1JFumNs9EXau4/6w7gVKEhJdGLfkMgt4PcLbJ4jIWhFZISLHJjYyFPiLiKx2byzcXTSfcSJ8gZ7/gyTz8wMYparb3ec7gFER1kmVz/FynL+QIunrZ8FPX3NLM/f3UDpKhc/vZGCnqm7q4f1kfn5RsZOJvRCRQuBx4Ouquq/b25U4f87PAH4OPJng8E5S1dnAp4FrRGRBgo/fJ/fWbecCv4/wdrI/v0Oo8zdwSs5VFZFbgXbg4R5WSdbPwj3AEcBMYDtOeSEVLab30XTK/19KVqKO5oa5neuISBYwHGhISHTOMbNxkvTDqrq8+/uquk9VD7jPnwayRaQ0UfGpao37+BHwBM6fmOFS4abEnwYqVXVn9zeS/fm5dnrlIPfxowjrJPVzFJElwDnAJe4vk8NE8bPgC1XdqaodqhoC7uvhuMn+/LKAC4BHe1onWZ9ffyQrUUdzw9w/At4Z9ouAv/X0gxpvbk3rV8A7qvrfPawz2quZi8hcnM8yIb9IRKRARIZ6z3FOOq3vttofgUvd2R+fAPaG/ZmfKD2OZJL5+YUJ/xm7DPjfCOs8C3xKRIrcP+0/5S7znYicCdwInKuqTT2sE83Pgl/xhZ/zOL+H4yb75tifBDaqanWkN5P5+fVLss5i4sxK+CfOGeFb3WW34/xQAuTi/Mn8HvAGMDmBsZ2E82fwOqDK/ToLuAq4yl3na8AGnLPY/wDmJzC+ye5x17oxeJ9feHwC3O1+vm8BFQn+9y3ASbzDw5Yl7fPD+YWxHWjDqZP+C845j78Cm4DngWJ33Qrgl2HbXu7+HL4HfDmB8b2HU9/1fga9WVBjgad7+1lIUHy/cX+21uEk3zHd43NfH/Z/PRHxucsf9H7mwtZN+OcX65ddQm6MMSnOTiYaY0yKs0RtjDEpzhK1McakOEvUxhiT4ixRG2NMirNEbQYNEemQQ7vyxa0Tm4iUh3deMyaVZCU7AGP64aCqzkx2EMYkmo2ozaDn9hO+w+0p/IaIHOkuLxeRv7lNg/4qIhPd5aPc/s5r3a/57q4yReQ+cXqQ/0VE8tz1rxOnN/k6EVmWpG/TBJglajOY5HUrfXw+7L29qnoc8P+An7rLfg48pKrTcRoa3eUuvwv4uzoNoWbjXJEGMAW4W1WPBfYAF7rLbwJmufu5yp9vzZie2ZWJZtAQkQOqWhhh+VbgVFXd4jbT2qGqJSJSj3NZc5u7fLuqlopIHTBeVVvC9lGO03d6ivv620C2qn5XRJ4BDuB0+HtS3WZSxiSKjahNutAenvdHS9jzDrrO4ZyN0zdlNvCm25HNmISxRG3SxefDHl9zn7+K060N4BLgJff5X4GrAUQkU0SG97RTEckAJqjqC8C3cdrtHjaqN8ZPNjIwg0letxuUPqOq3hS9IhFZhzMqXuwuuxZ4QERuAOqAL7vLrweWisi/4Iycr8bpvBZJJvBbN5kLcJeq7onT92NMVKxGbQY9t0Zdoar1yY7FGD9Y6cMYY1KcjaiNMSbF2YjaGGNSnCVqY4xJcZaojTEmxVmiNsaYFGeJ2hhjUtz/B9pyDlD6/ZA5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "\n",
      "Start training for stock: 1332\n",
      "continuos shape: (1202, 8)  categorical shape: (1202, 4)\n",
      "Using cuda-device\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['RowId'] = np.squeeze(enc.fit_transform(df['RowId'].to_numpy().reshape(-1, 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 0.6772023439407349, 'mae': 0.8170995116233826}\n",
      "Validation metrics: {'mse': 0.3886227011680603, 'mae': 0.5153311491012573}\n",
      "Average train loss: 5.893597262911499e-05 | Average val loss: 10.068169593811035\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.40921807289123535, 'mae': 0.6279719471931458}\n",
      "Validation metrics: {'mse': 0.17472481727600098, 'mae': 0.3996795117855072}\n",
      "Average train loss: 0.05691608190536499 | Average val loss: 6.371827602386475\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 1.0780712366104126, 'mae': 1.0291229486465454}\n",
      "Validation metrics: {'mse': 0.4304582476615906, 'mae': 0.5890771150588989}\n",
      "Average train loss: 0.012457995116710663 | Average val loss: 1.4605029821395874\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.9080454707145691, 'mae': 0.9379175901412964}\n",
      "Validation metrics: {'mse': 0.7473036646842957, 'mae': 0.7839784622192383}\n",
      "Average train loss: 0.04290973842144012 | Average val loss: 3.6788156032562256\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.9968421459197998, 'mae': 0.9860526919364929}\n",
      "Validation metrics: {'mse': 0.46143123507499695, 'mae': 0.6711134314537048}\n",
      "Average train loss: 0.04206870496273041 | Average val loss: 2.1974310874938965\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.7812356352806091, 'mae': 0.8728069067001343}\n",
      "Validation metrics: {'mse': 0.595827043056488, 'mae': 0.7039772272109985}\n",
      "Average train loss: 0.04609169363975525 | Average val loss: 1.3893678188323975\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 1.8342198133468628, 'mae': 1.3463581800460815}\n",
      "Validation metrics: {'mse': 3.802035093307495, 'mae': 1.740815281867981}\n",
      "Average train loss: 0.02603543996810913 | Average val loss: 1.3833112716674805\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 1.0645909309387207, 'mae': 1.0209035873413086}\n",
      "Validation metrics: {'mse': 13.737114906311035, 'mae': 3.3042705059051514}\n",
      "Average train loss: 0.07457609176635742 | Average val loss: 4.708884239196777\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.027279047295451164, 'mae': 0.14740169048309326}\n",
      "Validation metrics: {'mse': 3.0784547328948975, 'mae': 1.5716056823730469}\n",
      "Average train loss: 0.26790361404418944 | Average val loss: 1.085147738456726\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.014098557643592358, 'mae': 0.10511140525341034}\n",
      "Validation metrics: {'mse': 0.17080062627792358, 'mae': 0.3390316665172577}\n",
      "Average train loss: 0.05820279717445374 | Average val loss: 0.06636557728052139\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.05083772540092468, 'mae': 0.21807651221752167}\n",
      "Validation metrics: {'mse': 0.505998432636261, 'mae': 0.6360127329826355}\n",
      "Average train loss: 0.004575813189148903 | Average val loss: 0.1740732491016388\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.034694112837314606, 'mae': 0.17418013513088226}\n",
      "Validation metrics: {'mse': 0.904703676700592, 'mae': 0.8180732727050781}\n",
      "Average train loss: 0.008813582360744476 | Average val loss: 0.30851033329963684\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks = train_df['SecuritiesCode'].unique()\n",
    "count = 0\n",
    "for s in stocks:\n",
    "    print(f'Start training for stock: {s}')\n",
    "    train_loader, val_dataloader = None, None\n",
    "    if count > 5:\n",
    "        break\n",
    "    train_dataloader, val_dataloader = dataloader_by_stock(train_df, s)\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    trainer = Trainer(model, lr=1.3e-7)\n",
    "    trainer.fit_epochs(\n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        use_cyclic_lr=True, \n",
    "        x_cat=True, \n",
    "        epochs=20\n",
    "    )\n",
    "    print('#' * 20)\n",
    "    print()\n",
    "    count += 1\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
