{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "# pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_train_data\n",
    ")\n",
    "from metrics import calc_spread_return_sharpe\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, True, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.version.cuda), torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the unique security codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique adjustment factor: [ 1.          0.5         5.          0.33333333  0.83333333  0.25\n",
      "  0.90909091  0.1        10.          0.2         0.95238095  2.\n",
      "  0.14285714  0.66666667  0.86956522  0.76923077  0.8         4.\n",
      " 20.        ]\n",
      "Date\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "2017-01-04    1.0\n",
      "             ... \n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "2021-12-03    1.0\n",
      "Name: AdjustmentFactor, Length: 2332531, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowId</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1332</td>\n",
       "      <td>1332</td>\n",
       "      <td>568.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2798500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.012324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1333</td>\n",
       "      <td>1333</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>3140.0</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>270800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1376</td>\n",
       "      <td>1376</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>1510.0</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>11300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.011053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>20170104_1377</td>\n",
       "      <td>1377</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3350.0</td>\n",
       "      <td>3270.0</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>150800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    RowId  SecuritiesCode    Open    High     Low   Close  \\\n",
       "Date                                                                        \n",
       "2017-01-04  20170104_1301            1301  2734.0  2755.0  2730.0  2742.0   \n",
       "2017-01-04  20170104_1332            1332   568.0   576.0   563.0   571.0   \n",
       "2017-01-04  20170104_1333            1333  3150.0  3210.0  3140.0  3210.0   \n",
       "2017-01-04  20170104_1376            1376  1510.0  1550.0  1510.0  1550.0   \n",
       "2017-01-04  20170104_1377            1377  3270.0  3350.0  3270.0  3330.0   \n",
       "\n",
       "             Volume  AdjustmentFactor  ExpectedDividend  SupervisionFlag  \\\n",
       "Date                                                                       \n",
       "2017-01-04    31400               1.0               NaN            False   \n",
       "2017-01-04  2798500               1.0               NaN            False   \n",
       "2017-01-04   270800               1.0               NaN            False   \n",
       "2017-01-04    11300               1.0               NaN            False   \n",
       "2017-01-04   150800               1.0               NaN            False   \n",
       "\n",
       "              Target  \n",
       "Date                  \n",
       "2017-01-04  0.000730  \n",
       "2017-01-04  0.012324  \n",
       "2017-01-04  0.006154  \n",
       "2017-01-04  0.011053  \n",
       "2017-01-04  0.003026  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = get_train_data()\n",
    "print('Unique adjustment factor:', train_df['AdjustmentFactor'].unique())\n",
    "print(train_df['AdjustmentFactor'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT_FEATURES: 4\n",
      "NO_EMBEDDING: 2000\n",
      "NeuralNetwork(\n",
      "  (embedding): Embedding(2000, 200)\n",
      "  (embedding_to_hidden): Linear(in_features=200, out_features=512, bias=True)\n",
      "  (embedding_output): Linear(in_features=512, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=1, out_features=512, bias=True)\n",
      "  (hidden_layer): Linear(in_features=516, out_features=516, bias=True)\n",
      "  (output_layer): Linear(in_features=516, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (stacks): ModuleList(\n",
      "    (0): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): NeuralStack(\n",
      "      (stacks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer1): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer2): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer3): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer4): Linear(in_features=516, out_features=516, bias=True)\n",
      "          (layer5): Linear(in_features=516, out_features=516, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=516, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=516, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "TS_IN_FEATURES = 1\n",
    "\n",
    "CAT_FEATURES = 4 #cat.shape[1]\n",
    "\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 200\n",
    "NO_EMBEDDING = 2000 #2 * len(df_train_cat)\n",
    "print('NO_EMBEDDING:', NO_EMBEDDING)\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    in_features=TS_IN_FEATURES, \n",
    "    units=512,\n",
    "    out_features=1, \n",
    "    categorical_dim=CAT_FEATURES,\n",
    "    no_embedding=NO_EMBEDDING, \n",
    "    emb_dim=EMBEDDING_DIM,\n",
    "    n_blocks=8,\n",
    "    n_stacks=4,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop throug each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for stock: 1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['RowId'] = np.squeeze(enc.fit_transform(df['RowId'].to_numpy().reshape(-1, 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuos shape: (1202, 8)  categorical shape: (1202, 4)\n",
      "Using cuda-device\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\tokyo\\lib\\site-packages\\torch\\autograd\\__init__.py:173: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Copy.cpp:239.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 0.7835385203361511, 'mae': 0.8770266771316528}\n",
      "Validation metrics: {'mse': 0.6656020879745483, 'mae': 0.8103013634681702}\n",
      "Average train loss: 0.0016818512231111526 | Average val loss: 0.6152496337890625\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.006663627456873655, 'mae': 0.07127516716718674}\n",
      "Validation metrics: {'mse': 0.024318397045135498, 'mae': 0.1397445648908615}\n",
      "Average train loss: 0.03750130534172058 | Average val loss: 0.018111422657966614\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.013690302148461342, 'mae': 0.10239383578300476}\n",
      "Validation metrics: {'mse': 0.006778358016163111, 'mae': 0.06737348437309265}\n",
      "Average train loss: 0.0015950685366988183 | Average val loss: 0.0060709691606462\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.010560489259660244, 'mae': 0.09066782891750336}\n",
      "Validation metrics: {'mse': 0.002519862959161401, 'mae': 0.038744743913412094}\n",
      "Average train loss: 0.0006841718684881925 | Average val loss: 0.0028549355920404196\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.004950038623064756, 'mae': 0.05845348909497261}\n",
      "Validation metrics: {'mse': 0.0018075413536280394, 'mae': 0.033077988773584366}\n",
      "Average train loss: 0.0004056419711560011 | Average val loss: 0.0021967878565192223\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.0028835099656134844, 'mae': 0.04439973086118698}\n",
      "Validation metrics: {'mse': 0.0015757405199110508, 'mae': 0.030849717557430267}\n",
      "Average train loss: 0.00023611686192452906 | Average val loss: 0.001786376815289259\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 0.0022400026209652424, 'mae': 0.034326497465372086}\n",
      "Validation metrics: {'mse': 0.0013301209546625614, 'mae': 0.029385443776845932}\n",
      "Average train loss: 0.0002537003252655268 | Average val loss: 0.0015871119685471058\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 0.002089347690343857, 'mae': 0.034191325306892395}\n",
      "Validation metrics: {'mse': 0.0012862399453297257, 'mae': 0.028772132471203804}\n",
      "Average train loss: 0.00015465623000636696 | Average val loss: 0.0014152585063129663\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.002278632717207074, 'mae': 0.038519132882356644}\n",
      "Validation metrics: {'mse': 0.0010681754210963845, 'mae': 0.027074074372649193}\n",
      "Average train loss: 0.00014340094057843089 | Average val loss: 0.0012681704247370362\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.0018136658472940326, 'mae': 0.03535495698451996}\n",
      "Validation metrics: {'mse': 0.0009305627318099141, 'mae': 0.02538209594786167}\n",
      "Average train loss: 0.00011081550037488342 | Average val loss: 0.0011364228557795286\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.0018614408327266574, 'mae': 0.03514805808663368}\n",
      "Validation metrics: {'mse': 0.0009723870316520333, 'mae': 0.025754345580935478}\n",
      "Average train loss: 9.568192181177437e-05 | Average val loss: 0.001431116252206266\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.0018653756706044078, 'mae': 0.03484330326318741}\n",
      "Validation metrics: {'mse': 0.0007333969115279615, 'mae': 0.02244236320257187}\n",
      "Average train loss: 8.477289811708033e-05 | Average val loss: 0.000927669636439532\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "Train metrics: {'mse': 0.0016621507238596678, 'mae': 0.03137737512588501}\n",
      "Validation metrics: {'mse': 0.0007431200356222689, 'mae': 0.02113344520330429}\n",
      "Average train loss: 6.790995830669999e-05 | Average val loss: 0.0006332263583317399\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "Train metrics: {'mse': 0.0018227784894406796, 'mae': 0.03540995717048645}\n",
      "Validation metrics: {'mse': 0.0008847034187056124, 'mae': 0.025141527876257896}\n",
      "Average train loss: 8.907468873076141e-05 | Average val loss: 0.0013066537212580442\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "Train metrics: {'mse': 0.0014138339320197701, 'mae': 0.029286138713359833}\n",
      "Validation metrics: {'mse': 0.0006840170244686306, 'mae': 0.021224534139037132}\n",
      "Average train loss: 8.435816271230578e-05 | Average val loss: 0.0006569088436663151\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "Train metrics: {'mse': 0.0023934098426252604, 'mae': 0.04314866662025452}\n",
      "Validation metrics: {'mse': 0.0005620503798127174, 'mae': 0.017652763053774834}\n",
      "Average train loss: 5.560615682043135e-05 | Average val loss: 0.0006877274136058986\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "Train metrics: {'mse': 0.001441198750399053, 'mae': 0.03040693700313568}\n",
      "Validation metrics: {'mse': 0.0006804629811085761, 'mae': 0.02150023728609085}\n",
      "Average train loss: 0.00010125084081664681 | Average val loss: 0.0009293406619690359\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "Train metrics: {'mse': 0.00291289109736681, 'mae': 0.04470888525247574}\n",
      "Validation metrics: {'mse': 0.00038824640796519816, 'mae': 0.015006810426712036}\n",
      "Average train loss: 6.387552712112665e-05 | Average val loss: 0.0007024275837466121\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "Train metrics: {'mse': 0.0034220744855701923, 'mae': 0.046629875898361206}\n",
      "Validation metrics: {'mse': 0.0005446340655907989, 'mae': 0.01743713952600956}\n",
      "Average train loss: 0.00012880917638540267 | Average val loss: 0.0008985525346361101\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "Train metrics: {'mse': 0.0021008916664868593, 'mae': 0.03605331853032112}\n",
      "Validation metrics: {'mse': 0.0008832141757011414, 'mae': 0.0242733396589756}\n",
      "Average train loss: 0.00014949520118534565 | Average val loss: 0.0019014813005924225\n",
      ".................... End of epoch 19 ....................\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "\n",
      "Start training for stock: 1332\n",
      "continuos shape: (1202, 8)  categorical shape: (1202, 4)\n",
      "Using cuda-device\n",
      "Epoch: <<< 0 >>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\Documents\\TokyoStockEx\\notebooks\\..\\preprocessing\\preprocess.py:116: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cat['RowId'] = np.squeeze(enc.fit_transform(df['RowId'].to_numpy().reshape(-1, 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'mse': 4.880335807800293, 'mae': 2.1944546699523926}\n",
      "Validation metrics: {'mse': 0.04329133778810501, 'mae': 0.16386349499225616}\n",
      "Average train loss: 0.00011917666997760535 | Average val loss: 2.0027971267700195\n",
      ".................... End of epoch 0 ....................\n",
      "Epoch: <<< 1 >>>\n",
      "Train metrics: {'mse': 0.1984812617301941, 'mae': 0.43210911750793457}\n",
      "Validation metrics: {'mse': 0.0021837956737726927, 'mae': 0.03999742120504379}\n",
      "Average train loss: 0.023031039535999297 | Average val loss: 0.25122690200805664\n",
      ".................... End of epoch 1 ....................\n",
      "Epoch: <<< 2 >>>\n",
      "Train metrics: {'mse': 0.01536281406879425, 'mae': 0.08801434934139252}\n",
      "Validation metrics: {'mse': 0.004426088649779558, 'mae': 0.05007527768611908}\n",
      "Average train loss: 0.0030472550541162493 | Average val loss: 0.028434976935386658\n",
      ".................... End of epoch 2 ....................\n",
      "Epoch: <<< 3 >>>\n",
      "Train metrics: {'mse': 0.010788090527057648, 'mae': 0.07448536902666092}\n",
      "Validation metrics: {'mse': 0.001153641496784985, 'mae': 0.024767279624938965}\n",
      "Average train loss: 0.0024640152230858805 | Average val loss: 0.011425768956542015\n",
      ".................... End of epoch 3 ....................\n",
      "Epoch: <<< 4 >>>\n",
      "Train metrics: {'mse': 0.004687678534537554, 'mae': 0.05147341638803482}\n",
      "Validation metrics: {'mse': 0.0006435802206397057, 'mae': 0.01909114606678486}\n",
      "Average train loss: 0.00034363714512437583 | Average val loss: 0.0045170774683356285\n",
      ".................... End of epoch 4 ....................\n",
      "Epoch: <<< 5 >>>\n",
      "Train metrics: {'mse': 0.0038886861875653267, 'mae': 0.046993106603622437}\n",
      "Validation metrics: {'mse': 0.0004609804891515523, 'mae': 0.015621223486959934}\n",
      "Average train loss: 0.000138468062505126 | Average val loss: 0.0013889549300074577\n",
      ".................... End of epoch 5 ....................\n",
      "Epoch: <<< 6 >>>\n",
      "Train metrics: {'mse': 0.0035876773763448, 'mae': 0.04906929284334183}\n",
      "Validation metrics: {'mse': 0.00044191614142619073, 'mae': 0.014836341142654419}\n",
      "Average train loss: 7.025732775218785e-05 | Average val loss: 0.001504192128777504\n",
      ".................... End of epoch 6 ....................\n",
      "Epoch: <<< 7 >>>\n",
      "Train metrics: {'mse': 0.003080925205722451, 'mae': 0.0472339503467083}\n",
      "Validation metrics: {'mse': 0.0004240032867528498, 'mae': 0.014492825604975224}\n",
      "Average train loss: 7.094243192113936e-05 | Average val loss: 0.006010945420712233\n",
      ".................... End of epoch 7 ....................\n",
      "Epoch: <<< 8 >>>\n",
      "Train metrics: {'mse': 0.007307976949959993, 'mae': 0.06814860552549362}\n",
      "Validation metrics: {'mse': 0.0007068327395245433, 'mae': 0.019999008625745773}\n",
      "Average train loss: 7.581026875413954e-05 | Average val loss: 0.020778633654117584\n",
      ".................... End of epoch 8 ....................\n",
      "Epoch: <<< 9 >>>\n",
      "Train metrics: {'mse': 0.004888870753347874, 'mae': 0.055033497512340546}\n",
      "Validation metrics: {'mse': 0.00037741631967946887, 'mae': 0.014310095459222794}\n",
      "Average train loss: 0.00017963850405067205 | Average val loss: 0.00729468185454607\n",
      ".................... End of epoch 9 ....................\n",
      "Epoch: <<< 10 >>>\n",
      "Train metrics: {'mse': 0.004946164321154356, 'mae': 0.05674386024475098}\n",
      "Validation metrics: {'mse': 0.00038727608625777066, 'mae': 0.013732566498219967}\n",
      "Average train loss: 6.732424371875822e-05 | Average val loss: 0.010831352323293686\n",
      ".................... End of epoch 10 ....................\n",
      "Epoch: <<< 11 >>>\n",
      "Train metrics: {'mse': 0.005936068948358297, 'mae': 0.0637965053319931}\n",
      "Validation metrics: {'mse': 0.00038887446862645447, 'mae': 0.01409111823886633}\n",
      "Average train loss: 6.754845380783082e-05 | Average val loss: 0.01193220540881157\n",
      ".................... End of epoch 11 ....................\n",
      "Epoch: <<< 12 >>>\n",
      "Train metrics: {'mse': 0.004416015464812517, 'mae': 0.051199670881032944}\n",
      "Validation metrics: {'mse': 0.00039354086038656533, 'mae': 0.01475913543254137}\n",
      "Average train loss: 8.437384967692196e-05 | Average val loss: 0.00590088777244091\n",
      ".................... End of epoch 12 ....................\n",
      "Epoch: <<< 13 >>>\n",
      "Train metrics: {'mse': 0.0025666311848908663, 'mae': 0.03937586769461632}\n",
      "Validation metrics: {'mse': 0.0005353260785341263, 'mae': 0.018624775111675262}\n",
      "Average train loss: 4.8834178596735e-05 | Average val loss: 0.0014652200043201447\n",
      ".................... End of epoch 13 ....................\n",
      "Epoch: <<< 14 >>>\n",
      "Train metrics: {'mse': 0.0025147530250251293, 'mae': 0.03946981951594353}\n",
      "Validation metrics: {'mse': 0.0003648762940429151, 'mae': 0.013514862395823002}\n",
      "Average train loss: 7.235044613480568e-05 | Average val loss: 0.002681317273527384\n",
      ".................... End of epoch 14 ....................\n",
      "Epoch: <<< 15 >>>\n",
      "Train metrics: {'mse': 0.0027522293385118246, 'mae': 0.04210001230239868}\n",
      "Validation metrics: {'mse': 0.000832125311717391, 'mae': 0.023396288976073265}\n",
      "Average train loss: 5.4324441589415076e-05 | Average val loss: 0.008131710812449455\n",
      ".................... End of epoch 15 ....................\n",
      "Epoch: <<< 16 >>>\n",
      "Train metrics: {'mse': 0.003345072502270341, 'mae': 0.04812471196055412}\n",
      "Validation metrics: {'mse': 0.000536394480150193, 'mae': 0.017282111570239067}\n",
      "Average train loss: 0.0001019623363390565 | Average val loss: 0.008970492519438267\n",
      ".................... End of epoch 16 ....................\n",
      "Epoch: <<< 17 >>>\n",
      "Train metrics: {'mse': 0.003874816931784153, 'mae': 0.050741616636514664}\n",
      "Validation metrics: {'mse': 0.00037907916703261435, 'mae': 0.014048262499272823}\n",
      "Average train loss: 5.96509431488812e-05 | Average val loss: 0.010798717848956585\n",
      ".................... End of epoch 17 ....................\n",
      "Epoch: <<< 18 >>>\n",
      "Train metrics: {'mse': 0.006398789118975401, 'mae': 0.06183263659477234}\n",
      "Validation metrics: {'mse': 0.0003968343953602016, 'mae': 0.014497359283268452}\n",
      "Average train loss: 6.371272611431778e-05 | Average val loss: 0.01693720743060112\n",
      ".................... End of epoch 18 ....................\n",
      "Epoch: <<< 19 >>>\n",
      "Train metrics: {'mse': 0.007013031747192144, 'mae': 0.07084496319293976}\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks = train_df['SecuritiesCode'].unique()\n",
    "count = 0\n",
    "for s in stocks:\n",
    "    print(f'Start training for stock: {s}')\n",
    "    train_loader, val_dataloader = None, None\n",
    "    if count > 5:\n",
    "        break\n",
    "    train_dataloader, val_dataloader = dataloader_by_stock(train_df, s)\n",
    "\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    trainer = Trainer(model, optimizer_name='adam', lr=1.3e-4)\n",
    "    trainer.fit_epochs(\n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        use_cyclic_lr=True, \n",
    "        x_cat=True, \n",
    "        epochs=20\n",
    "    )\n",
    "    print('#' * 20)\n",
    "    print()\n",
    "    count += 1\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
