{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilbe\\anaconda3\\envs\\tokyo\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchmetrics as TM\n",
    "# pl.utilities.seed.seed_everything(seed=42)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys, os\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'preprocessing')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'metrics')\n",
    "sys.path.append(source_path)\n",
    "source_path = os.path.join(os.getcwd(), os.pardir, 'predict')\n",
    "sys.path.append(source_path)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dl import NeuralNetwork, Trainer\n",
    "from preprocess import (\n",
    "    show_df, \n",
    "    date_features, \n",
    "    preprocess, \n",
    "    ToTorch, \n",
    "    get_loader, \n",
    "    ts_split,\n",
    "    cont_cat_split,\n",
    "    dataloader_by_stock,\n",
    "    get_data,\n",
    "    dataloader_test_by_stock\n",
    ")\n",
    "# from metrics import calc_spread_return_sharpe\n",
    "print(torch.__version__)\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dl import plot_loss\n",
    "\n",
    "\n",
    "from predict import run_pred_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, True, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.version.cuda), torch.cuda.is_available(), torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Data and train a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the unique security codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2017-01-04                 0             6             8          0   \n",
      "2017-01-05                 0             6             8          0   \n",
      "2017-01-06                 0             6             8          0   \n",
      "2017-01-10                 0             6             8          0   \n",
      "2017-01-11                 0             6             8          0   \n",
      "2017-01-12                 0             6             8          0   \n",
      "2017-01-13                 0             6             8          0   \n",
      "2017-01-16                 0             6             8          0   \n",
      "2017-01-17                 0             6             8          0   \n",
      "2017-01-18                 0             6             8          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2017-01-04          3.365911e+10            1301  20170104_1301  2734.0   \n",
      "2017-01-05          3.365911e+10            1301  20170105_1301  2743.0   \n",
      "2017-01-06          3.365911e+10            1301  20170106_1301  2734.0   \n",
      "2017-01-10          3.365911e+10            1301  20170110_1301  2745.0   \n",
      "2017-01-11          3.365911e+10            1301  20170111_1301  2748.0   \n",
      "2017-01-12          3.365911e+10            1301  20170112_1301  2745.0   \n",
      "2017-01-13          3.365911e+10            1301  20170113_1301  2707.0   \n",
      "2017-01-16          3.365911e+10            1301  20170116_1301  2725.0   \n",
      "2017-01-17          3.365911e+10            1301  20170117_1301  2702.0   \n",
      "2017-01-18          3.365911e+10            1301  20170118_1301  2689.0   \n",
      "\n",
      "              High     Low   Close  Volume  AdjustmentFactor  \\\n",
      "Date                                                           \n",
      "2017-01-04  2755.0  2730.0  2742.0   31400               1.0   \n",
      "2017-01-05  2747.0  2735.0  2738.0   17900               1.0   \n",
      "2017-01-06  2744.0  2720.0  2740.0   19900               1.0   \n",
      "2017-01-10  2754.0  2735.0  2748.0   24200               1.0   \n",
      "2017-01-11  2752.0  2737.0  2745.0    9300               1.0   \n",
      "2017-01-12  2747.0  2703.0  2731.0   28700               1.0   \n",
      "2017-01-13  2730.0  2707.0  2722.0   19400               1.0   \n",
      "2017-01-16  2725.0  2696.0  2704.0   20100               1.0   \n",
      "2017-01-17  2704.0  2682.0  2686.0   18400               1.0   \n",
      "2017-01-18  2695.0  2681.0  2694.0   12100               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag    Target  \n",
      "Date                                                     \n",
      "2017-01-04               NaN            False  0.000730  \n",
      "2017-01-05               NaN            False  0.002920  \n",
      "2017-01-06               NaN            False -0.001092  \n",
      "2017-01-10               NaN            False -0.005100  \n",
      "2017-01-11               NaN            False -0.003295  \n",
      "2017-01-12               NaN            False -0.006613  \n",
      "2017-01-13               NaN            False -0.006657  \n",
      "2017-01-16               NaN            False  0.002978  \n",
      "2017-01-17               NaN            False  0.001856  \n",
      "2017-01-18               NaN            False  0.014079  \n",
      "Date\n",
      "2017-01-04    1.0\n",
      "2017-01-05    1.0\n",
      "2017-01-06    1.0\n",
      "2017-01-10    1.0\n",
      "2017-01-11    1.0\n",
      "             ... \n",
      "2021-11-29    1.0\n",
      "2021-11-30    1.0\n",
      "2021-12-01    1.0\n",
      "2021-12-02    1.0\n",
      "2021-12-03    1.0\n",
      "Name: AdjustmentFactor, Length: 2332531, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section/Products</th>\n",
       "      <th>33SectorName</th>\n",
       "      <th>17SectorName</th>\n",
       "      <th>Universe0</th>\n",
       "      <th>MarketCapitalization</th>\n",
       "      <th>SecuritiesCode</th>\n",
       "      <th>RowId</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>AdjustmentFactor</th>\n",
       "      <th>ExpectedDividend</th>\n",
       "      <th>SupervisionFlag</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.365911e+10</td>\n",
       "      <td>1301</td>\n",
       "      <td>20170104_1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2755.0</td>\n",
       "      <td>2730.0</td>\n",
       "      <td>2742.0</td>\n",
       "      <td>31400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.365911e+10</td>\n",
       "      <td>1301</td>\n",
       "      <td>20170105_1301</td>\n",
       "      <td>2743.0</td>\n",
       "      <td>2747.0</td>\n",
       "      <td>2735.0</td>\n",
       "      <td>2738.0</td>\n",
       "      <td>17900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.365911e+10</td>\n",
       "      <td>1301</td>\n",
       "      <td>20170106_1301</td>\n",
       "      <td>2734.0</td>\n",
       "      <td>2744.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>19900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.365911e+10</td>\n",
       "      <td>1301</td>\n",
       "      <td>20170110_1301</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>2754.0</td>\n",
       "      <td>2735.0</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>24200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.005100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.365911e+10</td>\n",
       "      <td>1301</td>\n",
       "      <td>20170111_1301</td>\n",
       "      <td>2748.0</td>\n",
       "      <td>2752.0</td>\n",
       "      <td>2737.0</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>9300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.003295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
       "Date                                                                  \n",
       "2017-01-04                 0             6             8          0   \n",
       "2017-01-05                 0             6             8          0   \n",
       "2017-01-06                 0             6             8          0   \n",
       "2017-01-10                 0             6             8          0   \n",
       "2017-01-11                 0             6             8          0   \n",
       "\n",
       "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
       "Date                                                                      \n",
       "2017-01-04          3.365911e+10            1301  20170104_1301  2734.0   \n",
       "2017-01-05          3.365911e+10            1301  20170105_1301  2743.0   \n",
       "2017-01-06          3.365911e+10            1301  20170106_1301  2734.0   \n",
       "2017-01-10          3.365911e+10            1301  20170110_1301  2745.0   \n",
       "2017-01-11          3.365911e+10            1301  20170111_1301  2748.0   \n",
       "\n",
       "              High     Low   Close  Volume  AdjustmentFactor  \\\n",
       "Date                                                           \n",
       "2017-01-04  2755.0  2730.0  2742.0   31400               1.0   \n",
       "2017-01-05  2747.0  2735.0  2738.0   17900               1.0   \n",
       "2017-01-06  2744.0  2720.0  2740.0   19900               1.0   \n",
       "2017-01-10  2754.0  2735.0  2748.0   24200               1.0   \n",
       "2017-01-11  2752.0  2737.0  2745.0    9300               1.0   \n",
       "\n",
       "            ExpectedDividend  SupervisionFlag    Target  \n",
       "Date                                                     \n",
       "2017-01-04               NaN            False  0.000730  \n",
       "2017-01-05               NaN            False  0.002920  \n",
       "2017-01-06               NaN            False -0.001092  \n",
       "2017-01-10               NaN            False -0.005100  \n",
       "2017-01-11               NaN            False -0.003295  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2332531 entries, 2017-01-04 to 2021-12-03\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   Section/Products      int64  \n",
      " 1   33SectorName          int64  \n",
      " 2   17SectorName          int64  \n",
      " 3   Universe0             int64  \n",
      " 4   MarketCapitalization  float64\n",
      " 5   SecuritiesCode        int64  \n",
      " 6   RowId                 object \n",
      " 7   Open                  float64\n",
      " 8   High                  float64\n",
      " 9   Low                   float64\n",
      " 10  Close                 float64\n",
      " 11  Volume                int64  \n",
      " 12  AdjustmentFactor      float64\n",
      " 13  ExpectedDividend      float64\n",
      " 14  SupervisionFlag       bool   \n",
      " 15  Target                float64\n",
      "dtypes: bool(1), float64(8), int64(6), object(1)\n",
      "memory usage: 287.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = get_data()\n",
    "# print('Unique adjustment factor:', train_df['AdjustmentFactor'].unique())\n",
    "print(train_df['AdjustmentFactor'])\n",
    "display(train_df.head())\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args and constants\n",
    "* Adding financials wes cumbersome maybe not worth now to add that data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "CAT_FEATURES: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "SUBTRACT:\n",
    "*) 3 FROM CONTINUOUS COLS BECAUSE OF POOLING\n",
    "*) 1 FROM CAT_FEATURES TO MAKE MATRICES MATCH AFTER TORCH.CAT\n",
    "\"\"\"\n",
    "CONT_COLS=['Close', 'Open', 'High', 'Low', 'MarketCapitalization',         \n",
    "           # 'NetSales', 'EquityToAssetRatio', 'TotalAssets', 'Profit', \n",
    "           # 'OperatingProfit', 'EarningsPerShare', 'Equity', \n",
    "           # 'BookValuePerShare', 'ResultDividendPerShare1stQuarter', \n",
    "           # 'ResultDividendPerShare2ndQuarter', 'ResultDividendPerShare3rdQuarter',\n",
    "           # 'ResultDividendPerShareFiscalYearEnd', 'ResultDividendPerShareAnnual'\n",
    "          ]\n",
    "TS_IN_FEATURES = len(CONT_COLS)\n",
    "print(TS_IN_FEATURES)\n",
    "CAT_FEATURES = 4 + 4 - 1 # TEXT_COLS = ['Section/Products', '33SectorName', '17SectorName', 'Universe0']\n",
    "print('CAT_FEATURES:', CAT_FEATURES)\n",
    "EMBEDDING_DIM = 300\n",
    "NO_EMBEDDING = 2000 #2 * len(df_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    model = None\n",
    "    model = NeuralNetwork(\n",
    "        in_features=TS_IN_FEATURES - 3, \n",
    "        units=128,\n",
    "        out_features=1, \n",
    "        categorical_dim=CAT_FEATURES,\n",
    "        no_embedding=NO_EMBEDDING, \n",
    "        emb_dim=EMBEDDING_DIM,\n",
    "        n_blocks=4,\n",
    "        n_stacks=1,\n",
    "        dropout=0.3,\n",
    "        pooling_sizes=3\n",
    "    )\n",
    "\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop throug each stock\n",
    "Create Trainer only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2021-12-06          3.365911e+10            1301  20211206_1301  2982.0   \n",
      "2021-12-07          3.365911e+10            1301  20211207_1301  2998.0   \n",
      "2021-12-06          1.696496e+11            1332  20211206_1332   592.0   \n",
      "2021-12-07          1.696496e+11            1332  20211207_1332   569.0   \n",
      "2021-12-06          1.266399e+11            1333  20211206_1333  2368.0   \n",
      "2021-12-07          1.266399e+11            1333  20211207_1333  2382.0   \n",
      "2021-12-06          4.773320e+10            1375  20211206_1375  1230.0   \n",
      "2021-12-07          4.773320e+10            1375  20211207_1375  1227.0   \n",
      "2021-12-06          1.770603e+10            1376  20211206_1376  1339.0   \n",
      "2021-12-07          1.770603e+10            1376  20211207_1376  1374.0   \n",
      "\n",
      "              High     Low   Close   Volume  AdjustmentFactor  \\\n",
      "Date                                                            \n",
      "2021-12-06  2982.0  2965.0  2971.0     8900               1.0   \n",
      "2021-12-07  3065.0  2990.0  3065.0    19100               1.0   \n",
      "2021-12-06   599.0   588.0   589.0  1360800               1.0   \n",
      "2021-12-07   569.0   535.0   556.0  6449200               1.0   \n",
      "2021-12-06  2388.0  2360.0  2377.0   125900               1.0   \n",
      "2021-12-07  2417.0  2371.0  2409.0   127300               1.0   \n",
      "2021-12-06  1239.0  1224.0  1224.0    81100               1.0   \n",
      "2021-12-07  1266.0  1227.0  1264.0   128600               1.0   \n",
      "2021-12-06  1372.0  1339.0  1351.0     6200               1.0   \n",
      "2021-12-07  1395.0  1366.0  1395.0     5800               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag  \n",
      "Date                                           \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n"
     ]
    }
   ],
   "source": [
    "FOLDER = 'example_test_files'\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "df = get_data(folder=FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (embedding_layer): Embedding(2000, 300)\n",
      "  (embedding_to_hidden): Linear(in_features=300, out_features=128, bias=True)\n",
      "  (embedding_output): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (cont_input): Linear(in_features=2, out_features=128, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (pooling_layer): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=True)\n",
      "  (stacks): ModuleList(\n",
      "    (0): NeuralStack(\n",
      "      (blocks): ModuleList(\n",
      "        (0): NeuralBlock(\n",
      "          (resnet_block): ModuleList(\n",
      "            (0): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (fwr_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (output): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (backcast_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (back_cast): Linear(in_features=135, out_features=135, bias=True)\n",
      "        )\n",
      "        (1): NeuralBlock(\n",
      "          (resnet_block): ModuleList(\n",
      "            (0): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (fwr_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (output): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (backcast_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (back_cast): Linear(in_features=135, out_features=135, bias=True)\n",
      "        )\n",
      "        (2): NeuralBlock(\n",
      "          (resnet_block): ModuleList(\n",
      "            (0): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (fwr_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (output): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (backcast_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (back_cast): Linear(in_features=135, out_features=135, bias=True)\n",
      "        )\n",
      "        (3): NeuralBlock(\n",
      "          (resnet_block): ModuleList(\n",
      "            (0): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (1): FFResNetBlock(\n",
      "              (layers): ModuleList(\n",
      "                (0): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (1): Linear(in_features=135, out_features=135, bias=True)\n",
      "                (2): Linear(in_features=135, out_features=135, bias=True)\n",
      "              )\n",
      "              (layer_norm): LayerNorm((135,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "          )\n",
      "          (fwr_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (output): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (backcast_layer): Linear(in_features=135, out_features=135, bias=True)\n",
      "          (back_cast): Linear(in_features=135, out_features=135, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (output_layers): ModuleList(\n",
      "        (0): Linear(in_features=135, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=135, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=135, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=135, out_features=1, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Using cuda-device\n",
      "Stock-iteratation: 0\n",
      "Start training for stock: 1301\n",
      "continuos shape: (1202, 11)  categorical shape: (1202, 7)\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([174, 7])\n",
      "x_cat after embedding: torch.Size([174, 7, 300])\n",
      "x_cat after fft2: torch.Size([174, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([174, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([174, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([174, 5])\n",
      "x.shape after pooling: torch.Size([174, 2])\n",
      "x.shape after first cont layer: torch.Size([174, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([174, 7])\n",
      "x_cat.squeeze().shape: torch.Size([174, 7])\n",
      "x.shape after torch.cat: torch.Size([174, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([3, 7])\n",
      "x_cat after embedding: torch.Size([3, 7, 300])\n",
      "x_cat after fft2: torch.Size([3, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([3, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([3, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([3, 5])\n",
      "x.shape after pooling: torch.Size([3, 2])\n",
      "x.shape after first cont layer: torch.Size([3, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([3, 7])\n",
      "x_cat.squeeze().shape: torch.Size([3, 7])\n",
      "x.shape after torch.cat: torch.Size([3, 135])\n",
      "\n",
      "                    Average train loss: 5.6723486632108686e-05 | \n",
      "                    Train-Mae: 0.051420584321022034 |\n",
      "\n",
      "                    Average val loss: 0.0005823116516694427|\n",
      "                    Val-Mae: 0.019676530733704567\n",
      "                    \n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([174, 7])\n",
      "x_cat after embedding: torch.Size([174, 7, 300])\n",
      "x_cat after fft2: torch.Size([174, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([174, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([174, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([174, 5])\n",
      "x.shape after pooling: torch.Size([174, 2])\n",
      "x.shape after first cont layer: torch.Size([174, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([174, 7])\n",
      "x_cat.squeeze().shape: torch.Size([174, 7])\n",
      "x.shape after torch.cat: torch.Size([174, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([3, 7])\n",
      "x_cat after embedding: torch.Size([3, 7, 300])\n",
      "x_cat after fft2: torch.Size([3, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([3, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([3, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([3, 5])\n",
      "x.shape after pooling: torch.Size([3, 2])\n",
      "x.shape after first cont layer: torch.Size([3, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([3, 7])\n",
      "x_cat.squeeze().shape: torch.Size([3, 7])\n",
      "x.shape after torch.cat: torch.Size([3, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([174, 7])\n",
      "x_cat after embedding: torch.Size([174, 7, 300])\n",
      "x_cat after fft2: torch.Size([174, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([174, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([174, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([174, 5])\n",
      "x.shape after pooling: torch.Size([174, 2])\n",
      "x.shape after first cont layer: torch.Size([174, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([174, 7])\n",
      "x_cat.squeeze().shape: torch.Size([174, 7])\n",
      "x.shape after torch.cat: torch.Size([174, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([3, 7])\n",
      "x_cat after embedding: torch.Size([3, 7, 300])\n",
      "x_cat after fft2: torch.Size([3, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([3, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([3, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([3, 5])\n",
      "x.shape after pooling: torch.Size([3, 2])\n",
      "x.shape after first cont layer: torch.Size([3, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([3, 7])\n",
      "x_cat.squeeze().shape: torch.Size([3, 7])\n",
      "x.shape after torch.cat: torch.Size([3, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([174, 7])\n",
      "x_cat after embedding: torch.Size([174, 7, 300])\n",
      "x_cat after fft2: torch.Size([174, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([174, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([174, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([174, 5])\n",
      "x.shape after pooling: torch.Size([174, 2])\n",
      "x.shape after first cont layer: torch.Size([174, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([174, 7])\n",
      "x_cat.squeeze().shape: torch.Size([174, 7])\n",
      "x.shape after torch.cat: torch.Size([174, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([3, 7])\n",
      "x_cat after embedding: torch.Size([3, 7, 300])\n",
      "x_cat after fft2: torch.Size([3, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([3, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([3, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([3, 5])\n",
      "x.shape after pooling: torch.Size([3, 2])\n",
      "x.shape after first cont layer: torch.Size([3, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([3, 7])\n",
      "x_cat.squeeze().shape: torch.Size([3, 7])\n",
      "x.shape after torch.cat: torch.Size([3, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([512, 7])\n",
      "x_cat after embedding: torch.Size([512, 7, 300])\n",
      "x_cat after fft2: torch.Size([512, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([512, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([512, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([512, 5])\n",
      "x.shape after pooling: torch.Size([512, 2])\n",
      "x.shape after first cont layer: torch.Size([512, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([512, 7])\n",
      "x_cat.squeeze().shape: torch.Size([512, 7])\n",
      "x.shape after torch.cat: torch.Size([512, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([174, 7])\n",
      "x_cat after embedding: torch.Size([174, 7, 300])\n",
      "x_cat after fft2: torch.Size([174, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([174, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([174, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([174, 5])\n",
      "x.shape after pooling: torch.Size([174, 2])\n",
      "x.shape after first cont layer: torch.Size([174, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([174, 7])\n",
      "x_cat.squeeze().shape: torch.Size([174, 7])\n",
      "x.shape after torch.cat: torch.Size([174, 135])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([3, 7])\n",
      "x_cat after embedding: torch.Size([3, 7, 300])\n",
      "x_cat after fft2: torch.Size([3, 7, 300])\n",
      "x_cat after relu + linear: torch.Size([3, 7, 128])\n",
      "Shape of x_cat before cat: torch.Size([3, 7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([3, 5])\n",
      "x.shape after pooling: torch.Size([3, 2])\n",
      "x.shape after first cont layer: torch.Size([3, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([3, 7])\n",
      "x_cat.squeeze().shape: torch.Size([3, 7])\n",
      "x.shape after torch.cat: torch.Size([3, 135])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "\n",
      "continuos shape: (2, 10)  categorical shape: (2, 7)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_cat_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:77\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_cat_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stocks = train_df['SecuritiesCode'].unique()\n",
    "count = 0\n",
    "BATCH_SIZE = 512\n",
    "weight_decay = 0.1\n",
    "EPOCHS = 5\n",
    "\n",
    "scaler_dict = {}\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    optimizer_name='rmsprop', \n",
    "    lr=1.3333e-5, \n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "train_loss_list = []\n",
    "train_mae_list = []\n",
    "valid_loss_list = []\n",
    "valid_mae_list = []\n",
    "\n",
    "for no_stock, stock in enumerate(stocks[: 5]):\n",
    "    # try:\n",
    "    train_loader, val_dataloader = None, None\n",
    "\n",
    "    print(f'Stock-iteratation: {no_stock}')\n",
    "    print(f'Start training for stock: {stock}')\n",
    "\n",
    "    train_dataloader, val_dataloader = dataloader_by_stock(\n",
    "        train_df, \n",
    "        stock, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        continous_cols=CONT_COLS,\n",
    "        return_scaler=False\n",
    "    )\n",
    "    # if count > 1:\n",
    "    #     EPOCHS = 15\n",
    "    train_loss, train_mae, val_loss, val_mae = trainer.fit_epochs(\n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        use_cyclic_lr=True, \n",
    "        x_cat=True, \n",
    "        epochs=EPOCHS\n",
    "    )\n",
    "    plot_loss(train_loss, val_loss, f'Train-loss: {stock}', f'Valid-loss: {stock}')\n",
    "    plot_loss(train_mae, val_mae, f'Train-mae: {stock}', f'Valid-mae: {stock}')\n",
    "    # train_loss_list.extend(train_loss)\n",
    "    # train_mae_list.extend(train_mae)\n",
    "    # valid_loss_list.extend(val_loss)\n",
    "    # valid_mae_list.extend(val_mae)\n",
    "    # scaler_dict[stock] = scaler\n",
    "    print('#' * 20)\n",
    "    print()\n",
    "    count += 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #######################################\n",
    "    Add prediction code to see if it works\n",
    "    ########################################\n",
    "    \"\"\"\n",
    "    test_dataloader = dataloader_test_by_stock(\n",
    "        df, \n",
    "        stock, \n",
    "        # transformer=transformer,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        continous_cols=CONT_COLS,\n",
    "        target_col=None\n",
    "    )\n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        trainer.model.to('cpu')\n",
    "        x_con_test = data['num_features'].to(\"cpu\")\n",
    "        x_cat_test = data['cat_features'].to('cpu')\n",
    "        x_cat_test.view((x_cat_test.size(0), -1))\n",
    "        print('x.shape:', x_con_test.shape)\n",
    "        print('x_cat.shape:', x_cat_test.t().shape)\n",
    "        pred = model(x_con_test, x_cat_test)\n",
    "        print('pred:', pred)\n",
    "        print()\n",
    "        \"\"\"\n",
    "        ##############################################################################\n",
    "        \"\"\"\n",
    "    print(f'| Prediction code in training loop: ')\n",
    "    # except Exception as e:\n",
    "    #     print(f'Training loop: {e}')\n",
    "    \n",
    "torch.save(model.state_dict(), './trained_model.pt')\n",
    "with open('scaler_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dl import plot_loss\n",
    "# plt.plot(train_loss_list)\n",
    "# plt.title('Train loss');\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(valid_loss_list)\n",
    "# plt.title('Valid loss')\n",
    "# plt.show()\n",
    "\n",
    "# plot_loss(train_loss_list, valid_loss_list, 'Train-loss', 'Valid-loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df.head(10):\n",
      "            Section/Products  33SectorName  17SectorName  Universe0  \\\n",
      "Date                                                                  \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "2021-12-06                 0             6             8          0   \n",
      "2021-12-07                 0             6             8          0   \n",
      "\n",
      "            MarketCapitalization  SecuritiesCode          RowId    Open  \\\n",
      "Date                                                                      \n",
      "2021-12-06          3.365911e+10            1301  20211206_1301  2982.0   \n",
      "2021-12-07          3.365911e+10            1301  20211207_1301  2998.0   \n",
      "2021-12-06          1.696496e+11            1332  20211206_1332   592.0   \n",
      "2021-12-07          1.696496e+11            1332  20211207_1332   569.0   \n",
      "2021-12-06          1.266399e+11            1333  20211206_1333  2368.0   \n",
      "2021-12-07          1.266399e+11            1333  20211207_1333  2382.0   \n",
      "2021-12-06          4.773320e+10            1375  20211206_1375  1230.0   \n",
      "2021-12-07          4.773320e+10            1375  20211207_1375  1227.0   \n",
      "2021-12-06          1.770603e+10            1376  20211206_1376  1339.0   \n",
      "2021-12-07          1.770603e+10            1376  20211207_1376  1374.0   \n",
      "\n",
      "              High     Low   Close   Volume  AdjustmentFactor  \\\n",
      "Date                                                            \n",
      "2021-12-06  2982.0  2965.0  2971.0     8900               1.0   \n",
      "2021-12-07  3065.0  2990.0  3065.0    19100               1.0   \n",
      "2021-12-06   599.0   588.0   589.0  1360800               1.0   \n",
      "2021-12-07   569.0   535.0   556.0  6449200               1.0   \n",
      "2021-12-06  2388.0  2360.0  2377.0   125900               1.0   \n",
      "2021-12-07  2417.0  2371.0  2409.0   127300               1.0   \n",
      "2021-12-06  1239.0  1224.0  1224.0    81100               1.0   \n",
      "2021-12-07  1266.0  1227.0  1264.0   128600               1.0   \n",
      "2021-12-06  1372.0  1339.0  1351.0     6200               1.0   \n",
      "2021-12-07  1395.0  1366.0  1395.0     5800               1.0   \n",
      "\n",
      "            ExpectedDividend  SupervisionFlag  \n",
      "Date                                           \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n",
      "2021-12-06               NaN            False  \n",
      "2021-12-07               NaN            False  \n"
     ]
    }
   ],
   "source": [
    "FOLDER = 'example_test_files'\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "df = get_data(folder=FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run prediction for stock: 1301\n",
      "continuos shape: (2, 10)  categorical shape: (2, 7)\n",
      "x.shape: torch.Size([1, 5])\n",
      "x_cat.shape: torch.Size([7, 1])\n",
      "\n",
      "x_cat.shape before embedding: torch.Size([1, 7])\n",
      "x_cat after embedding: torch.Size([1, 7, 300])\n",
      "x_cat after fft2: torch.Size([7, 300])\n",
      "x_cat after relu + linear: torch.Size([7, 128])\n",
      "Shape of x_cat before cat: torch.Size([7, 1])\n",
      "...\n",
      "x.shape after fft2: torch.Size([1, 5])\n",
      "x.shape after pooling: torch.Size([1, 2])\n",
      "x.shape after first cont layer: torch.Size([1, 128])\n",
      "x_cat.view((x_cat.size(0), -1)).shape: torch.Size([7, 1])\n",
      "x_cat.squeeze().shape: torch.Size([7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 7 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx.shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_con_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_cat.shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_cat_test\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 22\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_con_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cat_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred:\u001b[39m\u001b[38;5;124m'\u001b[39m, pred)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tokyo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Documents\\TokyoStockEx\\notebooks\\..\\src\\dl.py:288\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x, x_cat)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_cat.view((x_cat.size(0), -1)).shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_cat\u001b[38;5;241m.\u001b[39mview((x_cat\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_cat.squeeze().shape:\u001b[39m\u001b[38;5;124m'\u001b[39m, x_cat\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 288\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx.shape after torch.cat:\u001b[39m\u001b[38;5;124m'\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    290\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 7 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for stock in stocks:\n",
    "    # teast_dataloader = None\n",
    "    # if count > 500:\n",
    "    #     break\n",
    "    # try:\n",
    "    print(f'Run prediction for stock: {stock}')\n",
    "    # transformer = scaler_dict[stock]\n",
    "    test_dataloader = dataloader_test_by_stock(\n",
    "        df, \n",
    "        stock, \n",
    "        # transformer=transformer,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        continous_cols=CONT_COLS,\n",
    "        target_col=None\n",
    "    )\n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        model.to('cpu')\n",
    "        x_con_test = data['num_features'].to(\"cpu\")\n",
    "        x_cat_test = data['cat_features'].to('cpu')\n",
    "        print('x.shape:', x_con_test.shape)\n",
    "        print('x_cat.shape:', x_cat_test.t().shape)\n",
    "        pred = model(x_con_test, x_cat_test)\n",
    "        print('pred:', pred)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "\n",
    "for stock in stocks:\n",
    "    # teast_dataloader = None\n",
    "    # if count > 500:\n",
    "    #     break\n",
    "    # try:\n",
    "    print(f'Run prediction for stock: {stock}')\n",
    "    # transformer = scaler_dict[stock]\n",
    "    test_dataloader = dataloader_test_by_stock(\n",
    "        df, \n",
    "        stock, \n",
    "        # transformer=transformer,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        continous_cols=CONT_COLS,\n",
    "        target_col=None\n",
    "    )\n",
    "    pred_list = run_pred_step(test_dataloader, model, x_cat=True, target=False)\n",
    "    df_pred = pd.DataFrame(pred_list, index=[stock])\n",
    "    pred_df = pd.concat([pred_df, df_pred])#.pivot()\n",
    "    print('pred_df')\n",
    "    print(pred_df[:5])\n",
    "    # pred_df[stock] = pred_list\n",
    "    print()\n",
    "    count += 1\n",
    "#     except Exception as e:\n",
    "#         print(f'Exception {e}')\n",
    "        \n",
    "\n",
    "# pred_df = pd.DataFrame.from_dict(pred_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
